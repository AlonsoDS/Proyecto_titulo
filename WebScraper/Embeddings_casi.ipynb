{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d821477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# file: notebooks/train_per_context_embeddings.ipynb (single cell version for brevity)\n",
    "# ========================= Imports & config =========================\n",
    "import os, json, time, pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Embedding shape & train knobs\n",
    "EMB_DIM   = 12\n",
    "HIDDEN    = 32\n",
    "# QUICK DIAL-DOWN (put near your hyperparams)\n",
    "EPOCHS = 2        # was 6–12\n",
    "BATCH_SZ = 512    # larger batches reduce steps\n",
    "LR = 2e-3         # a tad higher to still move in 1 epoch\n",
    "NEG_K = 1         # was 5–10, cheaper negatives\n",
    "HIDDEN = 16       # smaller model\n",
    "EMB_DIM = 8       # smaller output\n",
    "\n",
    "# Shards you listed (under Graph_data/)\n",
    "ROOT = Path(\"Graph_data\")\n",
    "GENERAL_SHARDS = [\n",
    "    'shard_20250823_193931_1555433697-1539080245.pkl',\n",
    "    'shard_20250823_195306_2853468746-2862582048.pkl',\n",
    "    'shard_20250823_212915_1575719893-1579917449.pkl',\n",
    "    'shard_20250823_224953_1586671181-1586639873.pkl',\n",
    "    'shard_20250824_001026_1584809495-1548097259.pkl',\n",
    "]\n",
    "METRO_SHARDS = [\n",
    "    'METROSHARD_20250825_211657_1555433697-2854216564.pkl',\n",
    "    'METROSHARD_20250826_091005_1553843137-1548097259.pkl',\n",
    "]\n",
    "BUS_SHARDS = [\n",
    "    'BUSSHARD_20250826_122800_1555433697-1584388845.pkl',\n",
    "    'BUSSHARD_20250826_153430_2862820058-1548097259.pkl',\n",
    "]\n",
    "\n",
    "CLASSES = [\n",
    "    'sport_and_leisure','medical','education_prim','veterinary',\n",
    "    'food_and_drink_stores','arts_and_entertainment','food_and_drink',\n",
    "    'park_like','security','religion','education_sup'\n",
    "]\n",
    "ALL_CONTEXTS = CLASSES + ['metro','bus']\n",
    "\n",
    "OUT_CSV = \"apartment_embeddings_per_context_no_coords.csv\"\n",
    "\n",
    "# ========================= Load helpers =========================\n",
    "def load_pickle(p: Path):\n",
    "    with open(p, \"rb\") as f: return pickle.load(f)\n",
    "\n",
    "def load_general_items_for_class(ctx: str) -> List[Tuple[int, Data]]:\n",
    "    \"\"\"Return [(apt_id, Data)] for a single general class context.\"\"\"\n",
    "    items: List[Tuple[int, Data]] = []\n",
    "    for name in GENERAL_SHARDS:\n",
    "        p = ROOT / name\n",
    "        if not p.exists(): \n",
    "            print(f\"[warn] missing general shard {p}\"); \n",
    "            continue\n",
    "        part = load_pickle(p)  # dict[apt_id] -> dict[class]->Data or None\n",
    "        for aid, gdict in part.items():\n",
    "            g = gdict.get(ctx)\n",
    "            if isinstance(g, Data):\n",
    "                items.append((int(aid), g))\n",
    "    return items\n",
    "\n",
    "def load_metro_items() -> List[Tuple[int, Data]]:\n",
    "    items: List[Tuple[int, Data]] = []\n",
    "    for name in METRO_SHARDS:\n",
    "        p = ROOT / name\n",
    "        if not p.exists(): \n",
    "            print(f\"[warn] missing metro shard {p}\")\n",
    "            continue\n",
    "        part = load_pickle(p)  # dict[apt_id] -> Data\n",
    "        for aid, g in part.items():\n",
    "            if isinstance(g, Data):\n",
    "                items.append((int(aid), g))\n",
    "    return items\n",
    "\n",
    "def load_bus_items() -> List[Tuple[int, Data]]:\n",
    "    items: List[Tuple[int, Data]] = []\n",
    "    for name in BUS_SHARDS:\n",
    "        p = ROOT / name\n",
    "        if not p.exists(): \n",
    "            print(f\"[warn] missing bus shard {p}\")\n",
    "            continue\n",
    "        part = load_pickle(p)  # dict[apt_id] -> Data\n",
    "        for aid, g in part.items():\n",
    "            if isinstance(g, Data):\n",
    "                items.append((int(aid), g))\n",
    "    return items\n",
    "\n",
    "# ========================= Dataset (no coords; +distance scalar) =========================\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def add_distance_scalar(g: Data) -> Data:\n",
    "    \"\"\"Append 1-d feature: copy edge weight to POI node; apt node stays 0.\"\"\"\n",
    "    n = g.num_nodes\n",
    "    dist_feat = torch.zeros((n, 1), dtype=g.x.dtype)\n",
    "    if g.edge_attr is not None and g.edge_index is not None:\n",
    "        _, dst = g.edge_index\n",
    "        w = g.edge_attr.view(-1)\n",
    "        dist_feat[dst] = w.unsqueeze(1)\n",
    "    g.x = torch.cat([g.x, dist_feat], dim=1)\n",
    "    return g\n",
    "\n",
    "def common_feat_dim(items: List[Tuple[int, Data]]) -> int:\n",
    "    if not items: return 0\n",
    "    return max(g.x.size(1) for _, g in items)\n",
    "\n",
    "class StarDataset(Dataset):\n",
    "    def __init__(self, items: List[Tuple[int, Data]], base_f: int):\n",
    "        self.items = items\n",
    "        self.base_f = base_f  # COMMON_F per context (before +1 distance)\n",
    "        self.input_dim = base_f + 1\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i: int) -> Data:\n",
    "        aid, g = self.items[i]\n",
    "        # pad to base_f\n",
    "        if g.x.size(1) < self.base_f:\n",
    "            pad_w = self.base_f - g.x.size(1)\n",
    "            pad = torch.zeros((g.num_nodes, pad_w), dtype=g.x.dtype)\n",
    "            g = Data(x=torch.cat([g.x, pad], dim=1),\n",
    "                     edge_index=g.edge_index, edge_attr=g.edge_attr)\n",
    "        # add distance scalar\n",
    "        g = add_distance_scalar(g)  # +1\n",
    "        # enforce exactly input_dim\n",
    "        if g.x.size(1) < self.input_dim:\n",
    "            pad = torch.zeros((g.num_nodes, self.input_dim - g.x.size(1)), dtype=g.x.dtype)\n",
    "            g.x = torch.cat([g.x, pad], dim=1)\n",
    "        elif g.x.size(1) > self.input_dim:\n",
    "            g.x = g.x[:, :self.input_dim]\n",
    "        # meta: apt index via feature[0] == 1.0\n",
    "        apt_mask = (g.x[:, 0] > 0.5)\n",
    "        g.apt_idx = int(torch.nonzero(apt_mask, as_tuple=False)[0].item()) if apt_mask.any() else 0\n",
    "        g.apt_id  = int(aid)\n",
    "        return g\n",
    "\n",
    "# ========================= Model (GraphConv + aux heads) =========================\n",
    "class TinyGraphConv(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_dim, hidden)\n",
    "        self.conv2 = GraphConv(hidden, out_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.W = nn.Linear(out_dim, out_dim, bias=False)  # bilinear for edges\n",
    "        self.head_deg   = nn.Linear(out_dim, 1)\n",
    "        self.head_meanw = nn.Linear(out_dim, 1)\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        x, ei = data.x, data.edge_index\n",
    "        ew = data.edge_attr.view(-1) if data.edge_attr is not None else None\n",
    "        h = self.conv1(x, ei, edge_weight=ew)\n",
    "        h = self.act(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h, ei, edge_weight=ew)\n",
    "        return h\n",
    "\n",
    "    def score(self, h_src: torch.Tensor, h_dst: torch.Tensor) -> torch.Tensor:\n",
    "        return (self.W(h_src) * h_dst).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c41925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= Train one context =========================\n",
    "def edge_weights_for_training(g: Data) -> torch.Tensor:\n",
    "    \"\"\"Return edge weights in [0,1]: general already in [0,1]; metro/bus might be meters → 1/(1+dist).\"\"\"\n",
    "    w = g.edge_attr.view(-1)\n",
    "    if (w > 1.0).any():\n",
    "        w = 1.0 / (1.0 + torch.clamp(w, min=0.0))\n",
    "    return torch.clamp(w, 0.0, 1.0)\n",
    "\n",
    "def train_context(items: List[Tuple[int, Data]], context_name: str) -> Tuple[TinyGraphConv, StarDataset]:\n",
    "    if not items:\n",
    "        print(f\"[{context_name}] no graphs; skipping.\")\n",
    "        return None, None\n",
    "    base_f = common_feat_dim(items)\n",
    "    ds = StarDataset(items, base_f)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SZ, shuffle=True)\n",
    "    model = TinyGraphConv(ds.input_dim, HIDDEN, EMB_DIM).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    def train_epoch() -> float:\n",
    "        model.train()\n",
    "        tot, cnt = 0.0, 0\n",
    "        for big in dl:\n",
    "            big = big.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            H = model(big)\n",
    "            src, dst = big.edge_index\n",
    "\n",
    "            # apartment global indices\n",
    "            num_g = big.ptr.numel() - 1\n",
    "            apt_global = []\n",
    "            for i in range(num_g):\n",
    "                base = int(big.ptr[i].item())\n",
    "                aidx = int(big.apt_idx[i].item())\n",
    "                apt_global.append(base + aidx)\n",
    "            apt_global = torch.tensor(apt_global, device=big.x.device, dtype=src.dtype)\n",
    "\n",
    "            # edges whose src is that apartment\n",
    "            mask = (src.view(-1,1) == apt_global.view(1,-1)).any(dim=1)\n",
    "            if not mask.any(): \n",
    "                continue\n",
    "            src_pos = src[mask]; dst_pos = dst[mask]\n",
    "            targets_all = edge_weights_for_training(big)\n",
    "            targets_pos = targets_all[mask]\n",
    "\n",
    "            # pos loss\n",
    "            preds_pos = torch.sigmoid(model.score(H[src_pos], H[dst_pos]))\n",
    "            loss_pos = F.mse_loss(preds_pos, targets_pos)\n",
    "\n",
    "            # negatives per graph\n",
    "            neg_src_list, neg_dst_list = [], []\n",
    "            for i in range(num_g):\n",
    "                base = int(big.ptr[i].item()); end = int(big.ptr[i+1].item())\n",
    "                a_gi = base + int(big.apt_idx[i].item())\n",
    "                true_dsts = set(dst_pos[(src_pos == a_gi)].tolist())\n",
    "                cands = [j for j in range(base, end) if j != a_gi and j not in true_dsts]\n",
    "                if not cands: continue\n",
    "                pick = np.random.choice(cands, size=min(NEG_K, len(cands)), replace=False)\n",
    "                neg_src_list += [a_gi]*len(pick)\n",
    "                neg_dst_list += [int(x) for x in pick]\n",
    "            if neg_src_list:\n",
    "                neg_src = torch.tensor(neg_src_list, device=big.x.device, dtype=src.dtype)\n",
    "                neg_dst = torch.tensor(neg_dst_list, device=big.x.device, dtype=dst.dtype)\n",
    "                preds_neg = torch.sigmoid(model.score(H[neg_src], H[neg_dst]))\n",
    "                loss_neg = F.mse_loss(preds_neg, torch.zeros_like(preds_neg))\n",
    "            else:\n",
    "                loss_neg = torch.tensor(0.0, device=big.x.device)\n",
    "\n",
    "            # aux graph-level targets from apt embedding\n",
    "            deg_t, meanw_t = [], []\n",
    "            for i in range(num_g):\n",
    "                base = int(big.ptr[i].item())\n",
    "                a_gi = base + int(big.apt_idx[i].item())\n",
    "                sel = (src_pos == a_gi)\n",
    "                deg_i = int(sel.sum().item()); deg_t.append(deg_i)\n",
    "                meanw_t.append(float(targets_pos[sel].mean().item()) if deg_i>0 else 0.0)\n",
    "            deg_t   = torch.tensor(deg_t, device=big.x.device, dtype=torch.float).view(-1,1)\n",
    "            meanw_t = torch.tensor(meanw_t, device=big.x.device, dtype=torch.float).view(-1,1)\n",
    "            deg_tn  = torch.log1p(deg_t)/4.0\n",
    "            apt_h   = H[apt_global]\n",
    "            loss_deg   = F.mse_loss(model.head_deg(apt_h), deg_tn)\n",
    "            loss_meanw = F.mse_loss(torch.sigmoid(model.head_meanw(apt_h)), meanw_t)\n",
    "\n",
    "            loss = loss_pos + 0.5*loss_neg + 0.2*loss_deg + 0.2*loss_meanw\n",
    "            loss.backward(); opt.step()\n",
    "            tot += float(loss.item()); cnt += 1\n",
    "        return tot/max(cnt,1)\n",
    "\n",
    "    print(f\"[{context_name}] training on {len(ds)} graphs; input_dim={ds.input_dim}\")\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        t0 = time.time()\n",
    "        los = train_epoch()\n",
    "        print(f\"[{context_name}] epoch {ep:02d}  loss={los:.6f}  ({time.time()-t0:.1f}s)\")\n",
    "    return model, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fbcc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[collect] sport_and_leisure: 25123 graphs\n",
      "[collect] medical: 25087 graphs\n",
      "[collect] education_prim: 24519 graphs\n",
      "[collect] veterinary: 22982 graphs\n",
      "[collect] food_and_drink_stores: 24694 graphs\n",
      "[collect] arts_and_entertainment: 25007 graphs\n",
      "[collect] food_and_drink: 24205 graphs\n",
      "[collect] park_like: 24275 graphs\n",
      "[collect] security: 24564 graphs\n",
      "[collect] religion: 21291 graphs\n",
      "[collect] education_sup: 24581 graphs\n",
      "[collect] metro: 16752 graphs\n",
      "[collect] bus:   24175 graphs\n",
      "Total distinct apartments across contexts: 25211\n",
      "[sport_and_leisure] training on 25123 graphs; input_dim=5\n",
      "[sport_and_leisure] epoch 01  loss=0.128077  (29.5s)\n",
      "[sport_and_leisure] epoch 02  loss=0.019926  (27.5s)\n",
      "[sport_and_leisure] epoch 03  loss=0.018856  (27.3s)\n",
      "[sport_and_leisure] epoch 04  loss=0.018185  (30.2s)\n",
      "[sport_and_leisure] epoch 05  loss=0.017456  (27.6s)\n",
      "[sport_and_leisure] epoch 06  loss=0.016883  (27.6s)\n",
      "[medical] training on 25087 graphs; input_dim=5\n",
      "[medical] epoch 01  loss=0.067843  (24.2s)\n",
      "[medical] epoch 02  loss=0.013791  (29.5s)\n",
      "[medical] epoch 03  loss=0.012749  (27.2s)\n",
      "[medical] epoch 04  loss=0.011995  (27.2s)\n",
      "[medical] epoch 05  loss=0.011483  (27.2s)\n",
      "[medical] epoch 06  loss=0.011128  (27.2s)\n",
      "[education_prim] training on 24519 graphs; input_dim=5\n",
      "[education_prim] epoch 01  loss=0.065767  (25.8s)\n",
      "[education_prim] epoch 02  loss=0.010660  (26.1s)\n",
      "[education_prim] epoch 03  loss=0.009985  (28.2s)\n",
      "[education_prim] epoch 04  loss=0.009457  (32.0s)\n",
      "[education_prim] epoch 05  loss=0.009108  (32.3s)\n",
      "[education_prim] epoch 06  loss=0.008808  (32.2s)\n",
      "[veterinary] training on 22982 graphs; input_dim=5\n",
      "[veterinary] epoch 01  loss=0.044205  (29.6s)\n",
      "[veterinary] epoch 02  loss=0.011581  (30.0s)\n",
      "[veterinary] epoch 03  loss=0.010975  (29.8s)\n",
      "[veterinary] epoch 04  loss=0.010502  (29.7s)\n",
      "[veterinary] epoch 05  loss=0.010087  (29.6s)\n",
      "[veterinary] epoch 06  loss=0.009845  (29.8s)\n",
      "[food_and_drink_stores] training on 24694 graphs; input_dim=5\n",
      "[food_and_drink_stores] epoch 01  loss=0.076687  (32.9s)\n",
      "[food_and_drink_stores] epoch 02  loss=0.015088  (32.7s)\n",
      "[food_and_drink_stores] epoch 03  loss=0.014093  (32.8s)\n",
      "[food_and_drink_stores] epoch 04  loss=0.013643  (33.1s)\n",
      "[food_and_drink_stores] epoch 05  loss=0.013290  (33.5s)\n",
      "[food_and_drink_stores] epoch 06  loss=0.012967  (33.0s)\n",
      "[arts_and_entertainment] training on 25007 graphs; input_dim=5\n",
      "[arts_and_entertainment] epoch 01  loss=0.090099  (33.6s)\n",
      "[arts_and_entertainment] epoch 02  loss=0.024711  (26.8s)\n",
      "[arts_and_entertainment] epoch 03  loss=0.023639  (25.9s)\n",
      "[arts_and_entertainment] epoch 04  loss=0.022887  (27.3s)\n",
      "[arts_and_entertainment] epoch 05  loss=0.022251  (27.3s)\n",
      "[arts_and_entertainment] epoch 06  loss=0.021826  (27.5s)\n",
      "[food_and_drink] training on 24205 graphs; input_dim=5\n",
      "[food_and_drink] epoch 01  loss=0.093013  (34.6s)\n",
      "[food_and_drink] epoch 02  loss=0.021903  (34.3s)\n",
      "[food_and_drink] epoch 03  loss=0.020792  (34.5s)\n",
      "[food_and_drink] epoch 04  loss=0.020072  (34.3s)\n",
      "[food_and_drink] epoch 05  loss=0.019581  (34.3s)\n",
      "[food_and_drink] epoch 06  loss=0.019267  (27.1s)\n",
      "[park_like] training on 24275 graphs; input_dim=5\n",
      "[park_like] epoch 01  loss=0.071114  (33.4s)\n",
      "[park_like] epoch 02  loss=0.012234  (36.1s)\n",
      "[park_like] epoch 03  loss=0.011150  (33.3s)\n",
      "[park_like] epoch 04  loss=0.010479  (33.7s)\n",
      "[park_like] epoch 05  loss=0.010081  (34.0s)\n",
      "[park_like] epoch 06  loss=0.009809  (34.2s)\n",
      "[security] training on 24564 graphs; input_dim=5\n",
      "[security] epoch 01  loss=0.038188  (33.7s)\n",
      "[security] epoch 02  loss=0.013957  (34.2s)\n",
      "[security] epoch 03  loss=0.013234  (34.6s)\n",
      "[security] epoch 04  loss=0.012797  (34.2s)\n",
      "[security] epoch 05  loss=0.012471  (34.3s)\n",
      "[security] epoch 06  loss=0.012228  (34.4s)\n",
      "[religion] training on 21291 graphs; input_dim=5\n",
      "[religion] epoch 01  loss=0.078888  (29.0s)\n",
      "[religion] epoch 02  loss=0.013489  (29.4s)\n",
      "[religion] epoch 03  loss=0.012502  (29.4s)\n",
      "[religion] epoch 04  loss=0.011990  (29.3s)\n",
      "[religion] epoch 05  loss=0.011409  (29.8s)\n",
      "[religion] epoch 06  loss=0.010973  (29.5s)\n",
      "[education_sup] training on 24581 graphs; input_dim=5\n",
      "[education_sup] epoch 01  loss=0.091186  (32.6s)\n",
      "[education_sup] epoch 02  loss=0.037843  (27.8s)\n",
      "[education_sup] epoch 03  loss=0.036998  (27.6s)\n",
      "[education_sup] epoch 04  loss=0.036341  (27.7s)\n",
      "[education_sup] epoch 05  loss=0.035529  (27.6s)\n",
      "[education_sup] epoch 06  loss=0.035174  (27.8s)\n",
      "[metro] training on 16752 graphs; input_dim=10\n",
      "[metro] epoch 01  loss=0.062678  (22.8s)\n",
      "[metro] epoch 02  loss=0.024015  (22.4s)\n",
      "[metro] epoch 03  loss=0.008564  (22.6s)\n",
      "[metro] epoch 04  loss=0.004306  (22.9s)\n",
      "[metro] epoch 05  loss=0.003390  (22.9s)\n",
      "[metro] epoch 06  loss=0.003091  (18.3s)\n",
      "[bus] training on 24175 graphs; input_dim=3\n",
      "[bus] epoch 01  loss=0.039373  (20.5s)\n",
      "[bus] epoch 02  loss=0.007598  (25.9s)\n",
      "[bus] epoch 03  loss=0.004999  (25.3s)\n",
      "[bus] epoch 04  loss=0.004462  (25.3s)\n",
      "[bus] epoch 05  loss=0.004302  (25.1s)\n",
      "[bus] epoch 06  loss=0.004152  (25.6s)\n",
      "Saved: apartment_embeddings_per_context_no_coords.csv | shape: (25211, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emb_sport_and_leisure</th>\n",
       "      <th>emb_medical</th>\n",
       "      <th>emb_education_prim</th>\n",
       "      <th>emb_veterinary</th>\n",
       "      <th>emb_food_and_drink_stores</th>\n",
       "      <th>emb_arts_and_entertainment</th>\n",
       "      <th>emb_food_and_drink</th>\n",
       "      <th>emb_park_like</th>\n",
       "      <th>emb_security</th>\n",
       "      <th>emb_religion</th>\n",
       "      <th>emb_education_sup</th>\n",
       "      <th>emb_metro</th>\n",
       "      <th>emb_bus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1359204515</td>\n",
       "      <td>[0.5447400808334351, -0.8694881200790405, 0.97...</td>\n",
       "      <td>[0.9175235033035278, 0.24008315801620483, 0.54...</td>\n",
       "      <td>[-0.2462320327758789, -0.24796371161937714, -0...</td>\n",
       "      <td>[0.5069181323051453, 0.23975862562656403, 0.73...</td>\n",
       "      <td>[0.39807450771331787, 0.5578294396400452, -0.2...</td>\n",
       "      <td>[-0.34782326221466064, -0.3198614716529846, -0...</td>\n",
       "      <td>[-0.809662938117981, 0.24182315170764923, -0.7...</td>\n",
       "      <td>[-0.31603437662124634, -0.06535714864730835, 0...</td>\n",
       "      <td>[-0.03100641816854477, -0.22747787833213806, -...</td>\n",
       "      <td>[-0.524695098400116, 0.09304139018058777, -0.2...</td>\n",
       "      <td>[-0.7214534282684326, -0.43536949157714844, -0...</td>\n",
       "      <td>[-0.6309113502502441, 0.600777268409729, 0.978...</td>\n",
       "      <td>[1.7241809368133545, -0.9379951357841492, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366496843</td>\n",
       "      <td>[0.5447400808334351, -0.8694881200790405, 0.97...</td>\n",
       "      <td>[0.9175235033035278, 0.24008315801620483, 0.54...</td>\n",
       "      <td>[-0.2462320327758789, -0.24796371161937714, -0...</td>\n",
       "      <td>[0.5069181323051453, 0.23975862562656403, 0.73...</td>\n",
       "      <td>[0.39807450771331787, 0.5578294396400452, -0.2...</td>\n",
       "      <td>[-0.34782326221466064, -0.3198614716529846, -0...</td>\n",
       "      <td>[-0.809662938117981, 0.24182315170764923, -0.7...</td>\n",
       "      <td>[-0.31603437662124634, -0.06535713374614716, 0...</td>\n",
       "      <td>[-0.03100641816854477, -0.22747787833213806, -...</td>\n",
       "      <td>[-0.524695098400116, 0.09304139763116837, -0.2...</td>\n",
       "      <td>[-0.7214534282684326, -0.43536949157714844, -0...</td>\n",
       "      <td>[-0.6309113502502441, 0.600777268409729, 0.978...</td>\n",
       "      <td>[1.7241809368133545, -0.9379951357841492, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367599797</td>\n",
       "      <td>[0.5447400808334351, -0.8694881200790405, 0.97...</td>\n",
       "      <td>[0.9175235033035278, 0.24008315801620483, 0.54...</td>\n",
       "      <td>[-0.2462320327758789, -0.24796371161937714, -0...</td>\n",
       "      <td>[0.5069181323051453, 0.23975862562656403, 0.73...</td>\n",
       "      <td>[0.39807450771331787, 0.5578294396400452, -0.2...</td>\n",
       "      <td>[-0.34782326221466064, -0.3198614716529846, -0...</td>\n",
       "      <td>[-0.809662938117981, 0.24182315170764923, -0.7...</td>\n",
       "      <td>[-0.31603437662124634, -0.06535714864730835, 0...</td>\n",
       "      <td>[-0.03100641816854477, -0.22747787833213806, -...</td>\n",
       "      <td>[-0.524695098400116, 0.09304139763116837, -0.2...</td>\n",
       "      <td>[-0.7214534282684326, -0.43536949157714844, -0...</td>\n",
       "      <td>[-0.6309113502502441, 0.600777268409729, 0.978...</td>\n",
       "      <td>[1.7241809368133545, -0.9379951357841492, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391886163</td>\n",
       "      <td>[0.5447400808334351, -0.8694881200790405, 0.97...</td>\n",
       "      <td>[0.9175235033035278, 0.24008315801620483, 0.54...</td>\n",
       "      <td>[-0.2462320327758789, -0.24796371161937714, -0...</td>\n",
       "      <td>[0.5069181323051453, 0.23975862562656403, 0.73...</td>\n",
       "      <td>[0.39807450771331787, 0.5578294396400452, -0.2...</td>\n",
       "      <td>[-0.34782326221466064, -0.3198614716529846, -0...</td>\n",
       "      <td>[-0.809662938117981, 0.24182315170764923, -0.7...</td>\n",
       "      <td>[-0.31603437662124634, -0.06535713374614716, 0...</td>\n",
       "      <td>[-0.03100641816854477, -0.22747787833213806, -...</td>\n",
       "      <td>[-0.524695098400116, 0.09304139763116837, -0.2...</td>\n",
       "      <td>[-0.7214534282684326, -0.43536949157714844, -0...</td>\n",
       "      <td>[-0.6309113502502441, 0.600777268409729, 0.978...</td>\n",
       "      <td>[1.7241809368133545, -0.9379951357841492, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1408157926</td>\n",
       "      <td>[0.5447400808334351, -0.8694881200790405, 0.97...</td>\n",
       "      <td>[0.9175235033035278, 0.24008315801620483, 0.54...</td>\n",
       "      <td>[-0.2462320327758789, -0.24796371161937714, -0...</td>\n",
       "      <td>[0.5069181323051453, 0.23975862562656403, 0.73...</td>\n",
       "      <td>[0.39807450771331787, 0.5578294396400452, -0.2...</td>\n",
       "      <td>[-0.34782326221466064, -0.3198614716529846, -0...</td>\n",
       "      <td>[-0.809662938117981, 0.24182315170764923, -0.7...</td>\n",
       "      <td>[-0.31603437662124634, -0.06535714864730835, 0...</td>\n",
       "      <td>[-0.03100641816854477, -0.22747787833213806, -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.7214534282684326, -0.43536949157714844, -0...</td>\n",
       "      <td>[-0.6309113502502441, 0.600777268409729, 0.978...</td>\n",
       "      <td>[1.7241809368133545, -0.9379951357841492, -0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                              emb_sport_and_leisure  \\\n",
       "0  1359204515  [0.5447400808334351, -0.8694881200790405, 0.97...   \n",
       "1  1366496843  [0.5447400808334351, -0.8694881200790405, 0.97...   \n",
       "2  1367599797  [0.5447400808334351, -0.8694881200790405, 0.97...   \n",
       "3  1391886163  [0.5447400808334351, -0.8694881200790405, 0.97...   \n",
       "4  1408157926  [0.5447400808334351, -0.8694881200790405, 0.97...   \n",
       "\n",
       "                                         emb_medical  \\\n",
       "0  [0.9175235033035278, 0.24008315801620483, 0.54...   \n",
       "1  [0.9175235033035278, 0.24008315801620483, 0.54...   \n",
       "2  [0.9175235033035278, 0.24008315801620483, 0.54...   \n",
       "3  [0.9175235033035278, 0.24008315801620483, 0.54...   \n",
       "4  [0.9175235033035278, 0.24008315801620483, 0.54...   \n",
       "\n",
       "                                  emb_education_prim  \\\n",
       "0  [-0.2462320327758789, -0.24796371161937714, -0...   \n",
       "1  [-0.2462320327758789, -0.24796371161937714, -0...   \n",
       "2  [-0.2462320327758789, -0.24796371161937714, -0...   \n",
       "3  [-0.2462320327758789, -0.24796371161937714, -0...   \n",
       "4  [-0.2462320327758789, -0.24796371161937714, -0...   \n",
       "\n",
       "                                      emb_veterinary  \\\n",
       "0  [0.5069181323051453, 0.23975862562656403, 0.73...   \n",
       "1  [0.5069181323051453, 0.23975862562656403, 0.73...   \n",
       "2  [0.5069181323051453, 0.23975862562656403, 0.73...   \n",
       "3  [0.5069181323051453, 0.23975862562656403, 0.73...   \n",
       "4  [0.5069181323051453, 0.23975862562656403, 0.73...   \n",
       "\n",
       "                           emb_food_and_drink_stores  \\\n",
       "0  [0.39807450771331787, 0.5578294396400452, -0.2...   \n",
       "1  [0.39807450771331787, 0.5578294396400452, -0.2...   \n",
       "2  [0.39807450771331787, 0.5578294396400452, -0.2...   \n",
       "3  [0.39807450771331787, 0.5578294396400452, -0.2...   \n",
       "4  [0.39807450771331787, 0.5578294396400452, -0.2...   \n",
       "\n",
       "                          emb_arts_and_entertainment  \\\n",
       "0  [-0.34782326221466064, -0.3198614716529846, -0...   \n",
       "1  [-0.34782326221466064, -0.3198614716529846, -0...   \n",
       "2  [-0.34782326221466064, -0.3198614716529846, -0...   \n",
       "3  [-0.34782326221466064, -0.3198614716529846, -0...   \n",
       "4  [-0.34782326221466064, -0.3198614716529846, -0...   \n",
       "\n",
       "                                  emb_food_and_drink  \\\n",
       "0  [-0.809662938117981, 0.24182315170764923, -0.7...   \n",
       "1  [-0.809662938117981, 0.24182315170764923, -0.7...   \n",
       "2  [-0.809662938117981, 0.24182315170764923, -0.7...   \n",
       "3  [-0.809662938117981, 0.24182315170764923, -0.7...   \n",
       "4  [-0.809662938117981, 0.24182315170764923, -0.7...   \n",
       "\n",
       "                                       emb_park_like  \\\n",
       "0  [-0.31603437662124634, -0.06535714864730835, 0...   \n",
       "1  [-0.31603437662124634, -0.06535713374614716, 0...   \n",
       "2  [-0.31603437662124634, -0.06535714864730835, 0...   \n",
       "3  [-0.31603437662124634, -0.06535713374614716, 0...   \n",
       "4  [-0.31603437662124634, -0.06535714864730835, 0...   \n",
       "\n",
       "                                        emb_security  \\\n",
       "0  [-0.03100641816854477, -0.22747787833213806, -...   \n",
       "1  [-0.03100641816854477, -0.22747787833213806, -...   \n",
       "2  [-0.03100641816854477, -0.22747787833213806, -...   \n",
       "3  [-0.03100641816854477, -0.22747787833213806, -...   \n",
       "4  [-0.03100641816854477, -0.22747787833213806, -...   \n",
       "\n",
       "                                        emb_religion  \\\n",
       "0  [-0.524695098400116, 0.09304139018058777, -0.2...   \n",
       "1  [-0.524695098400116, 0.09304139763116837, -0.2...   \n",
       "2  [-0.524695098400116, 0.09304139763116837, -0.2...   \n",
       "3  [-0.524695098400116, 0.09304139763116837, -0.2...   \n",
       "4                                               None   \n",
       "\n",
       "                                   emb_education_sup  \\\n",
       "0  [-0.7214534282684326, -0.43536949157714844, -0...   \n",
       "1  [-0.7214534282684326, -0.43536949157714844, -0...   \n",
       "2  [-0.7214534282684326, -0.43536949157714844, -0...   \n",
       "3  [-0.7214534282684326, -0.43536949157714844, -0...   \n",
       "4  [-0.7214534282684326, -0.43536949157714844, -0...   \n",
       "\n",
       "                                           emb_metro  \\\n",
       "0  [-0.6309113502502441, 0.600777268409729, 0.978...   \n",
       "1  [-0.6309113502502441, 0.600777268409729, 0.978...   \n",
       "2  [-0.6309113502502441, 0.600777268409729, 0.978...   \n",
       "3  [-0.6309113502502441, 0.600777268409729, 0.978...   \n",
       "4  [-0.6309113502502441, 0.600777268409729, 0.978...   \n",
       "\n",
       "                                             emb_bus  \n",
       "0  [1.7241809368133545, -0.9379951357841492, -0.6...  \n",
       "1  [1.7241809368133545, -0.9379951357841492, -0.6...  \n",
       "2  [1.7241809368133545, -0.9379951357841492, -0.6...  \n",
       "3  [1.7241809368133545, -0.9379951357841492, -0.6...  \n",
       "4  [1.7241809368133545, -0.9379951357841492, -0.6...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def embed_graph(model: TinyGraphConv, g: Data, input_dim: int) -> np.ndarray:\n",
    "    # ensure input_dim\n",
    "    if g.x.size(1) < input_dim:\n",
    "        pad = torch.zeros((g.num_nodes, input_dim - g.x.size(1)), dtype=g.x.dtype)\n",
    "        g.x = torch.cat([g.x, pad], dim=1)\n",
    "    elif g.x.size(1) > input_dim:\n",
    "        g.x = g.x[:, :input_dim]\n",
    "    g = g.to(DEVICE)\n",
    "    H = model(g)\n",
    "    # apartment index\n",
    "    apt_mask = (g.x[:, 0] > 0.5)\n",
    "    aidx = int(torch.nonzero(apt_mask, as_tuple=False)[0].item()) if apt_mask.any() else 0\n",
    "    return H[aidx].cpu().numpy()\n",
    "\n",
    "# ========================= Run per context & build CSV =========================\n",
    "def train_and_embed_all() -> pd.DataFrame:\n",
    "    # collect items per context\n",
    "    per_ctx_items: Dict[str, List[Tuple[int, Data]]] = {}\n",
    "    for cls in CLASSES:\n",
    "        per_ctx_items[cls] = load_general_items_for_class(cls)\n",
    "        print(f\"[collect] {cls}: {len(per_ctx_items[cls])} graphs\")\n",
    "    per_ctx_items['metro'] = load_metro_items(); print(f\"[collect] metro: {len(per_ctx_items['metro'])} graphs\")\n",
    "    per_ctx_items['bus']   = load_bus_items();   print(f\"[collect] bus:   {len(per_ctx_items['bus'])} graphs\")\n",
    "\n",
    "    # union of all apartment IDs present anywhere\n",
    "    all_ids: Set[int] = set()\n",
    "    for ctx, items in per_ctx_items.items():\n",
    "        all_ids |= set(aid for aid,_ in items)\n",
    "    all_ids = sorted(all_ids)\n",
    "    print(\"Total distinct apartments across contexts:\", len(all_ids))\n",
    "\n",
    "    # For each context: train separate model; then embed all apartments for that context\n",
    "    ctx_embeddings: Dict[str, Dict[int, Optional[List[float]]]] = {}\n",
    "    for ctx in ALL_CONTEXTS:\n",
    "        items = per_ctx_items.get(ctx, [])\n",
    "        if not items:\n",
    "            print(f\"[{ctx}] no items; skipping\")\n",
    "            ctx_embeddings[ctx] = {aid: None for aid in all_ids}\n",
    "            continue\n",
    "\n",
    "        # Determine base_f for this context (for inference too)\n",
    "        base_f = common_feat_dim(items)\n",
    "        input_dim = base_f + 1  # + distance scalar\n",
    "        model, ds = train_context(items, ctx)\n",
    "        if model is None:  # no graphs at all\n",
    "            ctx_embeddings[ctx] = {aid: None for aid in all_ids}\n",
    "            continue\n",
    "\n",
    "        # map apt->graph for fast lookup\n",
    "        by_id: Dict[int, Data] = {aid: g for aid, g in items}\n",
    "\n",
    "        # embed\n",
    "        model.eval()\n",
    "        emb_map: Dict[int, Optional[List[float]]] = {}\n",
    "        for aid in all_ids:\n",
    "            g = by_id.get(aid)\n",
    "            if g is None:\n",
    "                emb_map[aid] = None\n",
    "            else:\n",
    "                # build the same input pipeline used in training: pad->+distance\n",
    "                if g.x.size(1) < base_f:\n",
    "                    pad = torch.zeros((g.num_nodes, base_f - g.x.size(1)), dtype=g.x.dtype)\n",
    "                    g = Data(x=torch.cat([g.x, pad], dim=1), edge_index=g.edge_index, edge_attr=g.edge_attr)\n",
    "                g = add_distance_scalar(g)\n",
    "                vec = embed_graph(model, g, input_dim)\n",
    "                emb_map[aid] = [float(x) for x in vec.tolist()]\n",
    "        ctx_embeddings[ctx] = emb_map\n",
    "\n",
    "    # Build CSV\n",
    "    rows = []\n",
    "    for aid in all_ids:\n",
    "        row = {'id': aid}\n",
    "        for ctx in ALL_CONTEXTS:\n",
    "            v = ctx_embeddings[ctx].get(aid)\n",
    "            row[f\"emb_{ctx}\"] = None if v is None else json.dumps(v)\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(\"Saved:\", OUT_CSV, \"| shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "df_out = train_and_embed_all()\n",
    "df_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19522f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940def0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a06e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[collect] sport_and_leisure: 25123 graphs\n",
      "[collect] medical: 25087 graphs\n",
      "[collect] education_prim: 24519 graphs\n",
      "[collect] veterinary: 22982 graphs\n",
      "[collect] food_and_drink_stores: 24694 graphs\n",
      "[collect] arts_and_entertainment: 25007 graphs\n",
      "[collect] food_and_drink: 24205 graphs\n",
      "[collect] park_like: 24275 graphs\n",
      "[collect] security: 24564 graphs\n",
      "[collect] religion: 21291 graphs\n",
      "[collect] education_sup: 24581 graphs\n",
      "[collect] metro: 16752 | bus: 24175\n",
      "Total distinct apartments: 25211\n",
      "Saved: apartment_embeddings_per_context_FAST.csv | shape: (25211, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emb_sport_and_leisure</th>\n",
       "      <th>emb_medical</th>\n",
       "      <th>emb_education_prim</th>\n",
       "      <th>emb_veterinary</th>\n",
       "      <th>emb_food_and_drink_stores</th>\n",
       "      <th>emb_arts_and_entertainment</th>\n",
       "      <th>emb_food_and_drink</th>\n",
       "      <th>emb_park_like</th>\n",
       "      <th>emb_security</th>\n",
       "      <th>emb_religion</th>\n",
       "      <th>emb_education_sup</th>\n",
       "      <th>emb_metro</th>\n",
       "      <th>emb_bus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1359204515</td>\n",
       "      <td>[60.0, 16.075674057006836, 6.5722761154174805,...</td>\n",
       "      <td>[38.0, 15.997368812561035, 9.423164367675781, ...</td>\n",
       "      <td>[13.0, 3.977703809738159, 1.8542356491088867, ...</td>\n",
       "      <td>[6.0, 2.277141571044922, 1.3051209449768066, 0...</td>\n",
       "      <td>[27.0, 9.532333374023438, 4.8009796142578125, ...</td>\n",
       "      <td>[14.0, 5.213222026824951, 2.8603620529174805, ...</td>\n",
       "      <td>[41.0, 11.050660133361816, 5.310342311859131, ...</td>\n",
       "      <td>[3.0, 1.726252555847168, 0.9990460276603699, 0...</td>\n",
       "      <td>[6.0, 1.7289631366729736, 1.121602177619934, 0...</td>\n",
       "      <td>[3.0, 0.8515275120735168, 0.3497370481491089, ...</td>\n",
       "      <td>[9.0, 3.1892800331115723, 1.4277830123901367, ...</td>\n",
       "      <td>[1.0, 0.002815012587234378, 7.924295459815767e...</td>\n",
       "      <td>[10.0, 0.03267307206988335, 0.0001179291430162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366496843</td>\n",
       "      <td>[12.0, 5.705898284912109, 3.5092594623565674, ...</td>\n",
       "      <td>[22.0, 9.402782440185547, 5.164984226226807, 3...</td>\n",
       "      <td>[9.0, 3.0975704193115234, 1.4777079820632935, ...</td>\n",
       "      <td>[8.0, 2.286616325378418, 0.9103704690933228, 0...</td>\n",
       "      <td>[14.0, 6.050302982330322, 3.726116895675659, 2...</td>\n",
       "      <td>[18.0, 5.941456317901611, 2.87703275680542, 1....</td>\n",
       "      <td>[16.0, 7.021714687347412, 4.83206844329834, 3....</td>\n",
       "      <td>[6.0, 2.8207437992095947, 1.765191674232483, 1...</td>\n",
       "      <td>[5.0, 3.2117748260498047, 2.646604061126709, 2...</td>\n",
       "      <td>[5.0, 1.2922619581222534, 0.6314557194709778, ...</td>\n",
       "      <td>[28.0, 3.475991725921631, 0.8413114547729492, ...</td>\n",
       "      <td>[4.0, 0.007331489585340023, 1.392192643834278e...</td>\n",
       "      <td>[11.0, 0.062020767480134964, 0.000560429005417...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367599797</td>\n",
       "      <td>[78.0, 26.780254364013672, 13.415040969848633,...</td>\n",
       "      <td>[41.0, 12.142561912536621, 5.951859474182129, ...</td>\n",
       "      <td>[11.0, 4.3323211669921875, 2.161160469055176, ...</td>\n",
       "      <td>[7.0, 2.1093690395355225, 0.9442524313926697, ...</td>\n",
       "      <td>[23.0, 6.6719489097595215, 2.913447618484497, ...</td>\n",
       "      <td>[30.0, 9.518875122070312, 4.2043681144714355, ...</td>\n",
       "      <td>[25.0, 7.744740009307861, 3.39424204826355, 1....</td>\n",
       "      <td>[2.0, 0.5252547264099121, 0.23184120655059814,...</td>\n",
       "      <td>[11.0, 4.0218987464904785, 2.126202344894409, ...</td>\n",
       "      <td>[4.0, 2.0272626876831055, 1.0776073932647705, ...</td>\n",
       "      <td>[100.0, 25.64299964904785, 9.471589088439941, ...</td>\n",
       "      <td>[3.0, 0.004855748265981674, 8.05325817054836e-...</td>\n",
       "      <td>[12.0, 0.0572342574596405, 0.00030509982025250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391886163</td>\n",
       "      <td>[11.0, 5.413773536682129, 3.2894861698150635, ...</td>\n",
       "      <td>[23.0, 8.883554458618164, 4.721118450164795, 2...</td>\n",
       "      <td>[10.0, 3.3879919052124023, 1.6319491863250732,...</td>\n",
       "      <td>[8.0, 1.9532856941223145, 0.6671395897865295, ...</td>\n",
       "      <td>[13.0, 5.776050090789795, 3.2777152061462402, ...</td>\n",
       "      <td>[17.0, 6.013828277587891, 2.922703742980957, 1...</td>\n",
       "      <td>[16.0, 6.098169803619385, 3.082339286804199, 1...</td>\n",
       "      <td>[7.0, 2.3664896488189697, 1.018655776977539, 0...</td>\n",
       "      <td>[5.0, 3.004030704498291, 2.287025213241577, 1....</td>\n",
       "      <td>[8.0, 2.3232483863830566, 0.9722421765327454, ...</td>\n",
       "      <td>[35.0, 4.483249664306641, 0.968339204788208, 0...</td>\n",
       "      <td>[3.0, 0.005734436679631472, 1.103953763958998e...</td>\n",
       "      <td>[9.0, 0.043397918343544006, 0.0002502724819350...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1408157926</td>\n",
       "      <td>[33.0, 8.578935623168945, 2.700268268585205, 0...</td>\n",
       "      <td>[18.0, 6.049106121063232, 2.7733232975006104, ...</td>\n",
       "      <td>[6.0, 2.608611822128296, 1.2793641090393066, 0...</td>\n",
       "      <td>[7.0, 2.411283254623413, 1.3507696390151978, 0...</td>\n",
       "      <td>[11.0, 2.56019926071167, 0.9970377683639526, 0...</td>\n",
       "      <td>[15.0, 6.22273063659668, 3.067983388900757, 1....</td>\n",
       "      <td>[19.0, 4.564805507659912, 2.0996875762939453, ...</td>\n",
       "      <td>[3.0, 1.3252400159835815, 0.6238857507705688, ...</td>\n",
       "      <td>[7.0, 2.4722888469696045, 1.1537070274353027, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4.0, 2.344971179962158, 1.6418575048446655, 1...</td>\n",
       "      <td>[1.0, 0.0015795428771525621, 2.49495565185498e...</td>\n",
       "      <td>[6.0, 0.09124578535556793, 0.00285489996895194...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                              emb_sport_and_leisure  \\\n",
       "0  1359204515  [60.0, 16.075674057006836, 6.5722761154174805,...   \n",
       "1  1366496843  [12.0, 5.705898284912109, 3.5092594623565674, ...   \n",
       "2  1367599797  [78.0, 26.780254364013672, 13.415040969848633,...   \n",
       "3  1391886163  [11.0, 5.413773536682129, 3.2894861698150635, ...   \n",
       "4  1408157926  [33.0, 8.578935623168945, 2.700268268585205, 0...   \n",
       "\n",
       "                                         emb_medical  \\\n",
       "0  [38.0, 15.997368812561035, 9.423164367675781, ...   \n",
       "1  [22.0, 9.402782440185547, 5.164984226226807, 3...   \n",
       "2  [41.0, 12.142561912536621, 5.951859474182129, ...   \n",
       "3  [23.0, 8.883554458618164, 4.721118450164795, 2...   \n",
       "4  [18.0, 6.049106121063232, 2.7733232975006104, ...   \n",
       "\n",
       "                                  emb_education_prim  \\\n",
       "0  [13.0, 3.977703809738159, 1.8542356491088867, ...   \n",
       "1  [9.0, 3.0975704193115234, 1.4777079820632935, ...   \n",
       "2  [11.0, 4.3323211669921875, 2.161160469055176, ...   \n",
       "3  [10.0, 3.3879919052124023, 1.6319491863250732,...   \n",
       "4  [6.0, 2.608611822128296, 1.2793641090393066, 0...   \n",
       "\n",
       "                                      emb_veterinary  \\\n",
       "0  [6.0, 2.277141571044922, 1.3051209449768066, 0...   \n",
       "1  [8.0, 2.286616325378418, 0.9103704690933228, 0...   \n",
       "2  [7.0, 2.1093690395355225, 0.9442524313926697, ...   \n",
       "3  [8.0, 1.9532856941223145, 0.6671395897865295, ...   \n",
       "4  [7.0, 2.411283254623413, 1.3507696390151978, 0...   \n",
       "\n",
       "                           emb_food_and_drink_stores  \\\n",
       "0  [27.0, 9.532333374023438, 4.8009796142578125, ...   \n",
       "1  [14.0, 6.050302982330322, 3.726116895675659, 2...   \n",
       "2  [23.0, 6.6719489097595215, 2.913447618484497, ...   \n",
       "3  [13.0, 5.776050090789795, 3.2777152061462402, ...   \n",
       "4  [11.0, 2.56019926071167, 0.9970377683639526, 0...   \n",
       "\n",
       "                          emb_arts_and_entertainment  \\\n",
       "0  [14.0, 5.213222026824951, 2.8603620529174805, ...   \n",
       "1  [18.0, 5.941456317901611, 2.87703275680542, 1....   \n",
       "2  [30.0, 9.518875122070312, 4.2043681144714355, ...   \n",
       "3  [17.0, 6.013828277587891, 2.922703742980957, 1...   \n",
       "4  [15.0, 6.22273063659668, 3.067983388900757, 1....   \n",
       "\n",
       "                                  emb_food_and_drink  \\\n",
       "0  [41.0, 11.050660133361816, 5.310342311859131, ...   \n",
       "1  [16.0, 7.021714687347412, 4.83206844329834, 3....   \n",
       "2  [25.0, 7.744740009307861, 3.39424204826355, 1....   \n",
       "3  [16.0, 6.098169803619385, 3.082339286804199, 1...   \n",
       "4  [19.0, 4.564805507659912, 2.0996875762939453, ...   \n",
       "\n",
       "                                       emb_park_like  \\\n",
       "0  [3.0, 1.726252555847168, 0.9990460276603699, 0...   \n",
       "1  [6.0, 2.8207437992095947, 1.765191674232483, 1...   \n",
       "2  [2.0, 0.5252547264099121, 0.23184120655059814,...   \n",
       "3  [7.0, 2.3664896488189697, 1.018655776977539, 0...   \n",
       "4  [3.0, 1.3252400159835815, 0.6238857507705688, ...   \n",
       "\n",
       "                                        emb_security  \\\n",
       "0  [6.0, 1.7289631366729736, 1.121602177619934, 0...   \n",
       "1  [5.0, 3.2117748260498047, 2.646604061126709, 2...   \n",
       "2  [11.0, 4.0218987464904785, 2.126202344894409, ...   \n",
       "3  [5.0, 3.004030704498291, 2.287025213241577, 1....   \n",
       "4  [7.0, 2.4722888469696045, 1.1537070274353027, ...   \n",
       "\n",
       "                                        emb_religion  \\\n",
       "0  [3.0, 0.8515275120735168, 0.3497370481491089, ...   \n",
       "1  [5.0, 1.2922619581222534, 0.6314557194709778, ...   \n",
       "2  [4.0, 2.0272626876831055, 1.0776073932647705, ...   \n",
       "3  [8.0, 2.3232483863830566, 0.9722421765327454, ...   \n",
       "4                                               None   \n",
       "\n",
       "                                   emb_education_sup  \\\n",
       "0  [9.0, 3.1892800331115723, 1.4277830123901367, ...   \n",
       "1  [28.0, 3.475991725921631, 0.8413114547729492, ...   \n",
       "2  [100.0, 25.64299964904785, 9.471589088439941, ...   \n",
       "3  [35.0, 4.483249664306641, 0.968339204788208, 0...   \n",
       "4  [4.0, 2.344971179962158, 1.6418575048446655, 1...   \n",
       "\n",
       "                                           emb_metro  \\\n",
       "0  [1.0, 0.002815012587234378, 7.924295459815767e...   \n",
       "1  [4.0, 0.007331489585340023, 1.392192643834278e...   \n",
       "2  [3.0, 0.004855748265981674, 8.05325817054836e-...   \n",
       "3  [3.0, 0.005734436679631472, 1.103953763958998e...   \n",
       "4  [1.0, 0.0015795428771525621, 2.49495565185498e...   \n",
       "\n",
       "                                             emb_bus  \n",
       "0  [10.0, 0.03267307206988335, 0.0001179291430162...  \n",
       "1  [11.0, 0.062020767480134964, 0.000560429005417...  \n",
       "2  [12.0, 0.0572342574596405, 0.00030509982025250...  \n",
       "3  [9.0, 0.043397918343544006, 0.0002502724819350...  \n",
       "4  [6.0, 0.09124578535556793, 0.00285489996895194...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_from_graph(g: Data) -> Optional[torch.Tensor]:\n",
    "    if g is None or g.edge_attr is None or g.edge_attr.numel() == 0:\n",
    "        return None\n",
    "    w = g.edge_attr.view(-1).clone()\n",
    "    # If looks like meters, squash to [0,1]\n",
    "    if (w > 1.0).any():\n",
    "        w = 1.0 / (1.0 + torch.clamp(w, min=0.0))\n",
    "    return torch.clamp(w, 0.0, 1.0)\n",
    "\n",
    "def star_stats_12d(w: torch.Tensor) -> np.ndarray:\n",
    "    # w in [0,1], shape [E]\n",
    "    E = float(w.numel())\n",
    "    if E == 0:\n",
    "        return np.full(12, np.nan, dtype=np.float32)\n",
    "\n",
    "    s1  = w.sum()\n",
    "    s2  = (w**2).sum()\n",
    "    s3  = (w**3).sum()\n",
    "    mean = float(s1 / E)\n",
    "    var  = float(s2 / E - mean**2)\n",
    "    std  = float(np.sqrt(max(var, 0.0)))\n",
    "    w_np = w.cpu().numpy()\n",
    "    w_sorted = np.sort(w_np)[::-1]  # desc by proximity\n",
    "    top1 = float(w_sorted[0])\n",
    "    top3_mean = float(w_sorted[:min(3, w_sorted.size)].mean())\n",
    "    tail = float((w_np > 0.75).mean())  # share of very close POIs\n",
    "    mn = float(w_np.min()); mx = float(w_np.max())\n",
    "    # two coarse bins\n",
    "    bin1 = float(((w_np > 0.0) & (w_np <= 0.5)).mean())\n",
    "    bin2 = float((w_np > 0.5).mean())\n",
    "\n",
    "    vec = np.array([\n",
    "        E, s1, s2, s3, mean, std, mn, mx, top1, top3_mean, tail, bin2\n",
    "    ], dtype=np.float32)\n",
    "    return vec\n",
    "\n",
    "def build_baseline_embeddings_csv(\n",
    "    general_shards, metro_shards, bus_shards, root: Path, out_csv: str\n",
    ") -> pd.DataFrame:\n",
    "    # Gather items just like before\n",
    "    from collections import defaultdict\n",
    "    def load_general_items_for_class(ctx: str):\n",
    "        items = []\n",
    "        for name in general_shards:\n",
    "            p = root / name\n",
    "            if not p.exists(): continue\n",
    "            part = load_pickle(p)\n",
    "            for aid, gdict in part.items():\n",
    "                g = gdict.get(ctx)\n",
    "                if isinstance(g, Data):\n",
    "                    items.append((int(aid), g))\n",
    "        return items\n",
    "\n",
    "    def load_simple(shard_list):\n",
    "        items = []\n",
    "        for name in shard_list:\n",
    "            p = root / name\n",
    "            if not p.exists(): continue\n",
    "            part = load_pickle(p)  # dict[apt_id] -> Data or None\n",
    "            for aid, g in part.items():\n",
    "                if isinstance(g, Data):\n",
    "                    items.append((int(aid), g))\n",
    "        return items\n",
    "\n",
    "    CLASSES = [\n",
    "        'sport_and_leisure','medical','education_prim','veterinary',\n",
    "        'food_and_drink_stores','arts_and_entertainment','food_and_drink',\n",
    "        'park_like','security','religion','education_sup'\n",
    "    ]\n",
    "    ALL_CTX = CLASSES + ['metro','bus']\n",
    "\n",
    "    per_ctx = {}\n",
    "    for ctx in CLASSES:\n",
    "        per_ctx[ctx] = load_general_items_for_class(ctx)\n",
    "        print(f\"[collect] {ctx}: {len(per_ctx[ctx])} graphs\")\n",
    "    per_ctx['metro'] = load_simple(metro_shards)\n",
    "    per_ctx['bus']   = load_simple(bus_shards)\n",
    "    print(f\"[collect] metro: {len(per_ctx['metro'])} | bus: {len(per_ctx['bus'])}\")\n",
    "\n",
    "    all_ids = set()\n",
    "    for ctx, items in per_ctx.items():\n",
    "        all_ids |= {aid for aid, _ in items}\n",
    "    all_ids = sorted(all_ids)\n",
    "    print(\"Total distinct apartments:\", len(all_ids))\n",
    "\n",
    "    # Build fast embeddings\n",
    "    ctx_embs = {ctx: {} for ctx in ALL_CTX}\n",
    "    for ctx in ALL_CTX:\n",
    "        items = dict(per_ctx.get(ctx, []))  # apt_id -> Data\n",
    "        for aid in all_ids:\n",
    "            g = items.get(aid)\n",
    "            if g is None:\n",
    "                ctx_embs[ctx][aid] = None\n",
    "            else:\n",
    "                w = weights_from_graph(g)\n",
    "                if w is None:\n",
    "                    ctx_embs[ctx][aid] = None\n",
    "                else:\n",
    "                    vec = star_stats_12d(w)\n",
    "                    # JSON string for CSV; keep None if no graph\n",
    "                    ctx_embs[ctx][aid] = json.dumps([float(x) for x in vec.tolist()])\n",
    "\n",
    "    # Assemble CSV\n",
    "    rows = []\n",
    "    for aid in all_ids:\n",
    "        row = {'id': aid}\n",
    "        for ctx in ALL_CTX:\n",
    "            row[f\"emb_{ctx}\"] = ctx_embs[ctx][aid]  # None or JSON\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv, \"| shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# ---- run it\n",
    "df_fast = build_baseline_embeddings_csv(\n",
    "    GENERAL_SHARDS, METRO_SHARDS, BUS_SHARDS, ROOT,\n",
    "    out_csv=\"apartment_embeddings_per_context_FAST.csv\"\n",
    ")\n",
    "df_fast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad811eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
