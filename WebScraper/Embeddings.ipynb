{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740140fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, time, pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b109987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script: Export one (apartment × POI class) subgraph from Neo4j\n",
    "to a PyTorch Geometric Data object.\n",
    "\n",
    "Steps:\n",
    "1. Query apartment + POI nodes and edges from Neo4j.\n",
    "2. Build node feature matrix (x), edge_index, edge_attr.\n",
    "3. Package into torch_geometric.data.Data.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Config ---------------- #\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "DATABASE = \"neo4jads\"\n",
    "\n",
    "# Radii per category (meters)\n",
    "RADII = {\"CERCA_DE_CAT1\": 600.0, \"CERCA_DE_CAT2\": 1200.0, \"CERCA_DE_CAT3\": 2400.0}\n",
    "\n",
    "# Example\n",
    "TEST_APT_ID = 1548097259        # <-- replace with real id from your df\n",
    "TEST_CLASS = \"medical\"    # one of the 11 classes\n",
    "\n",
    "# ---------------- Cypher Queries ---------------- #\n",
    "NODE_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})\n",
    "RETURN elementId(d) AS id, 'Departamento' AS label,\n",
    "       d.id AS apt_id, d.latitude AS lat, d.longitude AS lon, null AS cat\n",
    "UNION\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "RETURN elementId(p) AS id, 'POI' AS label,\n",
    "       null AS apt_id, null AS lat, null AS lon, p.cat AS cat\n",
    "\"\"\"\n",
    "\n",
    "REL_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "WITH elementId(d) AS source, elementId(p) AS target, type(r) AS t, r.distancia_metros AS dist\n",
    "WITH source, target,\n",
    "  CASE t\n",
    "    WHEN 'CERCA_DE_CAT1' THEN CASE WHEN 1.0 - dist / $r_cat1 > 0.001 THEN 1.0 - dist / $r_cat1 ELSE 0.001 END\n",
    "    WHEN 'CERCA_DE_CAT2' THEN CASE WHEN 1.0 - dist / $r_cat2 > 0.001 THEN 1.0 - dist / $r_cat2 ELSE 0.001 END\n",
    "    ELSE CASE WHEN 1.0 - dist / $r_cat3 > 0.001 THEN 1.0 - dist / $r_cat3 ELSE 0.001 END\n",
    "  END AS weight\n",
    "RETURN source, target, weight\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Export Function ---------------- #\n",
    "def export_apartment_class_graph(apt_id: int, class_name: str) -> Data:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    with driver.session(database=DATABASE) as session:\n",
    "        \n",
    "        # --- Nodes\n",
    "        nodes = session.run(\n",
    "            NODE_QUERY,\n",
    "            {\"apt_id\": apt_id, \"class\": class_name}\n",
    "        ).data()\n",
    "        if not nodes:\n",
    "            print(f\"No nodes found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        node_df = pd.DataFrame(nodes)\n",
    "        \n",
    "        # Map neo4j ids -> local indices\n",
    "        id_map = {nid: i for i, nid in enumerate(node_df[\"id\"].tolist())}\n",
    "        \n",
    "        # --- Edges\n",
    "        edges = session.run(\n",
    "            REL_QUERY,\n",
    "            {\n",
    "                \"apt_id\": apt_id, \"class\": class_name,\n",
    "                \"r_cat1\": RADII[\"CERCA_DE_CAT1\"],\n",
    "                \"r_cat2\": RADII[\"CERCA_DE_CAT2\"],\n",
    "                \"r_cat3\": RADII[\"CERCA_DE_CAT3\"],\n",
    "            }\n",
    "        ).data()\n",
    "        if not edges:\n",
    "            print(f\"No edges found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        edge_df = pd.DataFrame(edges)\n",
    "        \n",
    "        # Remap to local indices\n",
    "        edge_index = torch.tensor([\n",
    "            [id_map[s] for s in edge_df[\"source\"]],\n",
    "            [id_map[t] for t in edge_df[\"target\"]],\n",
    "        ], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_df[\"weight\"].values, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # --- Node features\n",
    "        # Apartment node = mark explicitly\n",
    "        feats = []\n",
    "        for _, row in node_df.iterrows():\n",
    "            if row[\"label\"] == \"Departamento\":\n",
    "                feats.append([1.0, 0.0, 0.0, 0.0])  # [is_apartment, cat1, cat2, cat3]\n",
    "            else:\n",
    "                onehot = [0.0, 0.0, 0.0, 0.0]\n",
    "                if row[\"cat\"] is not None:\n",
    "                    try:\n",
    "                        idx = int(row[\"cat\"])\n",
    "                        if 0 <= idx < len(onehot):\n",
    "                            onehot[idx] = 1.0\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass  # skip if cat is invalid\n",
    "                feats.append(onehot)\n",
    "        x = torch.tensor(np.array(feats), dtype=torch.float)\n",
    "        \n",
    "        # Build Data object\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            apt_id=apt_id,\n",
    "            poi_class=class_name\n",
    "        )\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9a2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deptos = pd.read_csv('Datasets/dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1fca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Test ---------------- #\n",
    "CLASSES = [\n",
    "    'sport_and_leisure',\n",
    "    'medical',\n",
    "    'education_prim',\n",
    "    'veterinary',\n",
    "    'food_and_drink_stores',\n",
    "    'arts_and_entertainment',\n",
    "    'food_and_drink',\n",
    "    'park_like',\n",
    "    'security',\n",
    "    'religion',\n",
    "    'education_sup'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5941af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 apartments in this batch (remaining after this: 25205)\n",
      "\n",
      "[1/10] Apartment ID=1548097259\n",
      "Done apt 1548097259 in 28.55 sec (progress: 1/25215)\n",
      "\n",
      "[2/10] Apartment ID=2732119230\n",
      "Done apt 2732119230 in 27.99 sec (progress: 2/25215)\n",
      "\n",
      "[3/10] Apartment ID=1592811585\n",
      "Done apt 1592811585 in 27.90 sec (progress: 3/25215)\n",
      "\n",
      "[4/10] Apartment ID=1536666991\n",
      "No edges found for apartment 1536666991, class education_prim\n",
      "Done apt 1536666991 in 28.19 sec (progress: 4/25215)\n",
      "\n",
      "[5/10] Apartment ID=2803401906\n",
      "Done apt 2803401906 in 27.93 sec (progress: 5/25215)\n",
      "\n",
      "[6/10] Apartment ID=1543740023\n",
      "Done apt 1543740023 in 28.07 sec (progress: 6/25215)\n",
      "\n",
      "[7/10] Apartment ID=1521489447\n",
      "No edges found for apartment 1521489447, class religion\n",
      "Done apt 1521489447 in 28.70 sec (progress: 7/25215)\n",
      "\n",
      "[8/10] Apartment ID=1588684845\n",
      "Done apt 1588684845 in 28.49 sec (progress: 8/25215)\n",
      "\n",
      "[9/10] Apartment ID=2849646914\n",
      "No edges found for apartment 2849646914, class security\n",
      "No edges found for apartment 2849646914, class religion\n",
      "Done apt 2849646914 in 28.47 sec (progress: 9/25215)\n",
      "\n",
      "[10/10] Apartment ID=1518864795\n",
      "Done apt 1518864795 in 28.82 sec (progress: 10/25215)\n",
      "✅ Batch completed and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "OUTPUT_FILE = \"apartment_graphs.pkl\"\n",
    "BATCH_SIZE = 10   # change this number freely\n",
    "\n",
    "# Load progress if exists\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"rb\") as f:\n",
    "        all_graphs = pickle.load(f)\n",
    "    done_ids = set(all_graphs.keys())\n",
    "    print(f\"Resuming: {len(done_ids)} apartments already done.\")\n",
    "else:\n",
    "    all_graphs = {}\n",
    "    done_ids = set()\n",
    "\n",
    "# All apartments\n",
    "apt_ids = df_deptos[\"id\"].tolist()\n",
    "pending_ids = [i for i in apt_ids if i not in done_ids]\n",
    "\n",
    "# Limit to one batch\n",
    "batch_ids = pending_ids[:BATCH_SIZE]\n",
    "print(f\"Processing {len(batch_ids)} apartments in this batch \"\n",
    "      f\"(remaining after this: {len(pending_ids)-len(batch_ids)})\")\n",
    "\n",
    "for idx, apt_id in enumerate(batch_ids, 1):\n",
    "    print(f\"\\n[{idx}/{len(batch_ids)}] Apartment ID={apt_id}\")\n",
    "    start = time.time()\n",
    "\n",
    "    graphs = {}\n",
    "    for cls in CLASSES:\n",
    "        g = export_apartment_class_graph(apt_id, cls)\n",
    "        graphs[cls] = g  # can be None for now\n",
    "\n",
    "    all_graphs[apt_id] = graphs\n",
    "\n",
    "    # Save progress after each apartment\n",
    "    with open(OUTPUT_FILE, \"wb\") as f:\n",
    "        pickle.dump(all_graphs, f)\n",
    "\n",
    "    print(f\"Done apt {apt_id} in {time.time()-start:.2f} sec \"\n",
    "          f\"(progress: {len(all_graphs)}/{len(apt_ids)})\")\n",
    "\n",
    "print(\"✅ Batch completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3716950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 apartments\n",
      "Some apartment IDs: [1548097259, 2732119230, 1592811585]\n",
      "\n",
      "Apartment 1548097259:\n",
      "  sport_and_leisure: Data(x=torch.Size([90, 4]), edge_index=torch.Size([2, 89]), edge_attr=torch.Size([89, 1]))\n",
      "  medical: Data(x=torch.Size([32, 4]), edge_index=torch.Size([2, 31]), edge_attr=torch.Size([31, 1]))\n",
      "  education_prim: Data(x=torch.Size([9, 4]), edge_index=torch.Size([2, 8]), edge_attr=torch.Size([8, 1]))\n",
      "  veterinary: Data(x=torch.Size([2, 4]), edge_index=torch.Size([2, 1]), edge_attr=torch.Size([1, 1]))\n",
      "  food_and_drink_stores: Data(x=torch.Size([13, 4]), edge_index=torch.Size([2, 12]), edge_attr=torch.Size([12, 1]))\n",
      "  arts_and_entertainment: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  food_and_drink: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  park_like: Data(x=torch.Size([7, 4]), edge_index=torch.Size([2, 6]), edge_attr=torch.Size([6, 1]))\n",
      "  security: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n",
      "  religion: Data(x=torch.Size([4, 4]), edge_index=torch.Size([2, 3]), edge_attr=torch.Size([3, 1]))\n",
      "  education_sup: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    graphs = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(graphs)} apartments\")\n",
    "\n",
    "# Print first 3 keys (apartment IDs)\n",
    "print(\"Some apartment IDs:\", list(graphs.keys())[:3])\n",
    "\n",
    "# Inspect one apartment\n",
    "apt_id = list(graphs.keys())[0]\n",
    "apt_data = graphs[apt_id]\n",
    "\n",
    "print(f\"\\nApartment {apt_id}:\")\n",
    "for cls, data in apt_data.items():\n",
    "    if data is None:\n",
    "        print(f\"  {cls}: None (no POIs)\")\n",
    "    else:\n",
    "        print(f\"  {cls}: Data(x={data.x.shape}, edge_index={data.edge_index.shape}, edge_attr={data.edge_attr.shape})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab6275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment 1548097259 embeddings:\n",
      "sport_and_leisure [-0.18648088  0.5579107  -0.4131222   0.27406204 -0.35570735  0.40606898\n",
      "  0.14326589 -0.5241446 ]\n",
      "medical [-0.20881331  0.31410986 -0.40781352  0.36022988 -0.28139758  0.50777537\n",
      "  0.04728226 -0.36782062]\n",
      "education_prim [-0.34600687  0.42414403 -0.4898538   0.15145272 -0.4337186   0.6039778\n",
      "  0.08607332 -0.5473764 ]\n",
      "veterinary [-0.27915993  0.22826114 -0.191151    0.27866125 -0.18302271  0.27510607\n",
      "  0.21248034 -0.57624197]\n",
      "food_and_drink_stores [-0.27390623  0.4828838  -0.44862312  0.20662722 -0.39463884  0.5065929\n",
      "  0.11644609 -0.5412748 ]\n",
      "arts_and_entertainment [-0.17523065  0.2991605  -0.37270257  0.40328738 -0.24081656  0.4592786\n",
      "  0.05530962 -0.3462455 ]\n",
      "food_and_drink [-0.32072455  0.48084846 -0.51296467  0.15983051 -0.4509474   0.6042404\n",
      "  0.08255335 -0.5402578 ]\n",
      "park_like [-0.34960094  0.40333438 -0.4733036   0.15413487 -0.42034778  0.59179056\n",
      "  0.09157699 -0.5501465 ]\n",
      "security [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n",
      "religion [-0.36173084  0.33310184 -0.4174466   0.1631871  -0.3752213   0.5506586\n",
      "  0.11015184 -0.5594954 ]\n",
      "education_sup [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "# ---------------- Load the pickle file ---------------- #\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    apartment_graphs = pickle.load(f)\n",
    "\n",
    "# ---------------- Small GNN model ---------------- #\n",
    "class SimpleGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        # Two-layer GraphSAGE\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        if batch is None:\n",
    "            # Single graph → make batch of zeros\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long)\n",
    "        return global_mean_pool(x, batch)  # → one vector per graph\n",
    "\n",
    "\n",
    "# ---------------- Pick one apartment ---------------- #\n",
    "apt_id = next(iter(apartment_graphs.keys()))  # just the first apartment\n",
    "graphs = apartment_graphs[apt_id]\n",
    "\n",
    "# Feature dimension (4 in your case: is_apartment, cat1, cat2, cat3)\n",
    "in_channels = graphs[next(iter(graphs))].x.shape[1]\n",
    "model = SimpleGraphSAGE(in_channels, hidden_channels=16, out_channels=8)\n",
    "\n",
    "# ---------------- Compute embeddings ---------------- #\n",
    "embeddings = {}\n",
    "for cls, g in graphs.items():\n",
    "    if g is None:\n",
    "        embeddings[cls] = None\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            emb = model(g.x, g.edge_index)\n",
    "            embeddings[cls] = emb.squeeze().numpy()  # shape (out_channels,)\n",
    "\n",
    "# ---------------- Inspect ---------------- #\n",
    "print(f\"Apartment {apt_id} embeddings:\")\n",
    "for cls, emb in embeddings.items():\n",
    "    print(cls, None if emb is None else emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba6c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing apartment id: 1548097259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('gds.graph.project.cypher' has been replaced by 'gds.graph.project Cypher projection as an aggregation function')} {position: line: 2, column: 1, offset: 1} for query: '\\nCALL gds.graph.project.cypher(\\n  $graph_name,\\n  $node_query,\\n  $rel_query,\\n  {\\n    parameters: {apt_id:$apt_id, class:$class, r_cat1:$r_cat1, r_cat2:$r_cat2, r_cat3:$r_cat3}\\n  }\\n)\\nYIELD graphName, nodeCount, relationshipCount\\nRETURN graphName, nodeCount, relationshipCount\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected: g_test_1548097259_medical with 32 nodes and 31 rels\n",
      "Apartment 1548097259 got embedding of dim 4\n"
     ]
    }
   ],
   "source": [
    "# file: notebooks/test_single_embedding.ipynb\n",
    "\"\"\"\n",
    "Test script: Generate **one embedding** for **one apartment + one POI class** using Neo4j GDS FastRP.\n",
    "- Uses `df` dataframe (with column \"id\") for apartment IDs.\n",
    "- Writes embedding back to the apartment node as a property (e.g., `medicalContextEmbedding`).\n",
    "\"\"\"\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# ------------------- Config ------------------- #\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "DATABASE = \"neo4jads\"\n",
    "\n",
    "EMBEDDING_DIM = 4\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Radii per category (meters)\n",
    "RADII = {\"CERCA_DE_CAT1\": 600.0, \"CERCA_DE_CAT2\": 1200.0, \"CERCA_DE_CAT3\": 2400.0}\n",
    "\n",
    "# Example: test one class\n",
    "TEST_CLASS = \"medical\"\n",
    "PROP_NAME = \"medical_ContextEmbedding\"\n",
    "\n",
    "# ------------------- Cypher ------------------- #\n",
    "# Debug-friendly: add RETURNs to check matches\n",
    "NODE_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})\n",
    "RETURN id(d) AS id, labels(d) AS labels\n",
    "UNION\n",
    "MATCH (d:Departamento {id:$apt_id})-[:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "RETURN id(p) AS id, labels(p) AS labels\n",
    "\"\"\"\n",
    "\n",
    "REL_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "WITH id(d) AS source, id(p) AS target, type(r) AS t, r.distancia_metros AS dist\n",
    "WITH source, target,\n",
    "  CASE t\n",
    "    WHEN 'CERCA_DE_CAT1' THEN CASE WHEN (1.0 - dist / $r_cat1) < 0.0 THEN 0.0 ELSE (1.0 - dist / $r_cat1) END\n",
    "    WHEN 'CERCA_DE_CAT2' THEN CASE WHEN (1.0 - dist / $r_cat2) < 0.0 THEN 0.0 ELSE (1.0 - dist / $r_cat2) END\n",
    "    ELSE CASE WHEN (1.0 - dist / $r_cat3) < 0.0 THEN 0.0 ELSE (1.0 - dist / $r_cat3) END\n",
    "  END AS weight\n",
    "RETURN source, target, weight\n",
    "\"\"\"\n",
    "\n",
    "DROP_GRAPH = \"CALL gds.graph.exists($graph_name) YIELD exists WITH exists WHERE exists CALL gds.graph.drop($graph_name) YIELD graphName RETURN graphName\"\n",
    "\n",
    "PROJECT_GRAPH = \"\"\"\n",
    "CALL gds.graph.project.cypher(\n",
    "  $graph_name,\n",
    "  $node_query,\n",
    "  $rel_query,\n",
    "  {\n",
    "    parameters: {apt_id:$apt_id, class:$class, r_cat1:$r_cat1, r_cat2:$r_cat2, r_cat3:$r_cat3}\n",
    "  }\n",
    ")\n",
    "YIELD graphName, nodeCount, relationshipCount\n",
    "RETURN graphName, nodeCount, relationshipCount\n",
    "\"\"\"\n",
    "\n",
    "FASTRP_STREAM = \"\"\"\n",
    "CALL gds.fastRP.stream($graph_name, {\n",
    "  embeddingDimension: $dim,\n",
    "  randomSeed: $seed,\n",
    "  relationshipWeightProperty: 'weight'\n",
    "})\n",
    "YIELD nodeId, embedding\n",
    "WITH gds.util.asNode(nodeId) AS n, embedding\n",
    "WHERE n:Departamento\n",
    "SET n[$prop_name] = embedding\n",
    "RETURN n.id AS apartment_id, size(embedding) AS dim\n",
    "\"\"\"\n",
    "\n",
    "# ------------------- Test Run ------------------- #\n",
    "\n",
    "def run_single_embedding(apt_id: str, class_name: str, prop_name: str):\n",
    "    graph_name = f\"g_test_{apt_id}_{class_name}\"\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    with driver.session(database=DATABASE) as session:\n",
    "        # Clean old graph if exists\n",
    "        session.run(DROP_GRAPH, {\"graph_name\": graph_name}).consume()\n",
    "\n",
    "        # Project graph\n",
    "        try:\n",
    "            proj = session.run(\n",
    "                PROJECT_GRAPH,\n",
    "                {\n",
    "                    \"graph_name\": graph_name,\n",
    "                    \"node_query\": NODE_QUERY,\n",
    "                    \"rel_query\": REL_QUERY,\n",
    "                    \"apt_id\": apt_id,\n",
    "                    \"class\": class_name,\n",
    "                    \"r_cat1\": RADII[\"CERCA_DE_CAT1\"],\n",
    "                    \"r_cat2\": RADII[\"CERCA_DE_CAT2\"],\n",
    "                    \"r_cat3\": RADII[\"CERCA_DE_CAT3\"],\n",
    "                },\n",
    "            ).single()\n",
    "        except Exception as e:\n",
    "            print(f\"Projection failed for apt {apt_id}, class {class_name}: {e}\")\n",
    "            return\n",
    "\n",
    "        if proj is None:\n",
    "            print(f\"No nodes found for apartment {apt_id} and class {class_name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Projected: {proj['graphName']} with {proj['nodeCount']} nodes and {proj['relationshipCount']} rels\")\n",
    "\n",
    "        # Run FastRP stream and write embedding\n",
    "        result = session.run(\n",
    "            FASTRP_STREAM,\n",
    "            {\n",
    "                \"graph_name\": graph_name,\n",
    "                \"dim\": EMBEDDING_DIM,\n",
    "                \"seed\": RANDOM_SEED,\n",
    "                \"prop_name\": prop_name,\n",
    "            },\n",
    "        ).single()\n",
    "        if result:\n",
    "            print(f\"Apartment {result['apartment_id']} got embedding of dim {result['dim']}\")\n",
    "\n",
    "        # Drop the graph\n",
    "        session.run(DROP_GRAPH, {\"graph_name\": graph_name}).consume()\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "# ------------------- Example Execution ------------------- #\n",
    "# Pick one apartment ID from df\n",
    "test_apartment_id = int(df.loc[0, \"id\"])\n",
    "print(f\"Testing apartment id: {test_apartment_id}\")\n",
    "run_single_embedding(test_apartment_id, TEST_CLASS, PROP_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea50fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781e6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
