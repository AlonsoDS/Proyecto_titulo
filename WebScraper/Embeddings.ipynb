{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740140fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, time, pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b109987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script: Export one (apartment × POI class) subgraph from Neo4j\n",
    "to a PyTorch Geometric Data object.\n",
    "\n",
    "Steps:\n",
    "1. Query apartment + POI nodes and edges from Neo4j.\n",
    "2. Build node feature matrix (x), edge_index, edge_attr.\n",
    "3. Package into torch_geometric.data.Data.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Config ---------------- #\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "DATABASE = \"neo4jads\"\n",
    "\n",
    "# Radii per category (meters)\n",
    "RADII = {\"CERCA_DE_CAT1\": 600.0, \"CERCA_DE_CAT2\": 1200.0, \"CERCA_DE_CAT3\": 2400.0}\n",
    "\n",
    "# Example\n",
    "TEST_APT_ID = 1548097259        # <-- replace with real id from your df\n",
    "TEST_CLASS = \"medical\"    # one of the 11 classes\n",
    "\n",
    "# ---------------- Cypher Queries ---------------- #\n",
    "NODE_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})\n",
    "RETURN elementId(d) AS id, 'Departamento' AS label,\n",
    "       d.id AS apt_id, d.latitude AS lat, d.longitude AS lon, null AS cat\n",
    "UNION\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "RETURN elementId(p) AS id, 'POI' AS label,\n",
    "       null AS apt_id, null AS lat, null AS lon, p.cat AS cat\n",
    "\"\"\"\n",
    "\n",
    "REL_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "WITH elementId(d) AS source, elementId(p) AS target, type(r) AS t, r.distancia_metros AS dist\n",
    "WITH source, target,\n",
    "  CASE t\n",
    "    WHEN 'CERCA_DE_CAT1' THEN CASE WHEN 1.0 - dist / $r_cat1 > 0.001 THEN 1.0 - dist / $r_cat1 ELSE 0.001 END\n",
    "    WHEN 'CERCA_DE_CAT2' THEN CASE WHEN 1.0 - dist / $r_cat2 > 0.001 THEN 1.0 - dist / $r_cat2 ELSE 0.001 END\n",
    "    ELSE CASE WHEN 1.0 - dist / $r_cat3 > 0.001 THEN 1.0 - dist / $r_cat3 ELSE 0.001 END\n",
    "  END AS weight\n",
    "RETURN source, target, weight\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Export Function ---------------- #\n",
    "def export_apartment_class_graph(apt_id: int, class_name: str) -> Data:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    with driver.session(database=DATABASE) as session:\n",
    "        \n",
    "        # --- Nodes\n",
    "        nodes = session.run(\n",
    "            NODE_QUERY,\n",
    "            {\"apt_id\": apt_id, \"class\": class_name}\n",
    "        ).data()\n",
    "        if not nodes:\n",
    "            print(f\"No nodes found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        node_df = pd.DataFrame(nodes)\n",
    "        \n",
    "        # Map neo4j ids -> local indices\n",
    "        id_map = {nid: i for i, nid in enumerate(node_df[\"id\"].tolist())}\n",
    "        \n",
    "        # --- Edges\n",
    "        edges = session.run(\n",
    "            REL_QUERY,\n",
    "            {\n",
    "                \"apt_id\": apt_id, \"class\": class_name,\n",
    "                \"r_cat1\": RADII[\"CERCA_DE_CAT1\"],\n",
    "                \"r_cat2\": RADII[\"CERCA_DE_CAT2\"],\n",
    "                \"r_cat3\": RADII[\"CERCA_DE_CAT3\"],\n",
    "            }\n",
    "        ).data()\n",
    "        if not edges:\n",
    "            print(f\"No edges found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        edge_df = pd.DataFrame(edges)\n",
    "        \n",
    "        # Remap to local indices\n",
    "        edge_index = torch.tensor([\n",
    "            [id_map[s] for s in edge_df[\"source\"]],\n",
    "            [id_map[t] for t in edge_df[\"target\"]],\n",
    "        ], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_df[\"weight\"].values, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # --- Node features\n",
    "        # Apartment node = mark explicitly\n",
    "        feats = []\n",
    "        for _, row in node_df.iterrows():\n",
    "            if row[\"label\"] == \"Departamento\":\n",
    "                feats.append([1.0, 0.0, 0.0, 0.0])  # [is_apartment, cat1, cat2, cat3]\n",
    "            else:\n",
    "                onehot = [0.0, 0.0, 0.0, 0.0]\n",
    "                if row[\"cat\"] is not None:\n",
    "                    try:\n",
    "                        idx = int(row[\"cat\"])\n",
    "                        if 0 <= idx < len(onehot):\n",
    "                            onehot[idx] = 1.0\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass  # skip if cat is invalid\n",
    "                feats.append(onehot)\n",
    "        x = torch.tensor(np.array(feats), dtype=torch.float)\n",
    "        \n",
    "        # Build Data object\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            apt_id=apt_id,\n",
    "            poi_class=class_name\n",
    "        )\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9a2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deptos = pd.read_csv('Datasets/dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1fca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Test ---------------- #\n",
    "CLASSES = [\n",
    "    'sport_and_leisure',\n",
    "    'medical',\n",
    "    'education_prim',\n",
    "    'veterinary',\n",
    "    'food_and_drink_stores',\n",
    "    'arts_and_entertainment',\n",
    "    'food_and_drink',\n",
    "    'park_like',\n",
    "    'security',\n",
    "    'religion',\n",
    "    'education_sup'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5941af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: 4810 apartments already done.\n",
      "Processing 100 apartments in this batch (remaining after this: 20305)\n",
      "\n",
      "[1/100] Apartment ID=2807806402\n",
      "Done apt 2807806402 in 39.79 sec (progress: 4811/25215)\n",
      "\n",
      "[2/100] Apartment ID=1571492613\n",
      "Done apt 1571492613 in 39.57 sec (progress: 4812/25215)\n",
      "\n",
      "[3/100] Apartment ID=2803722742\n",
      "Done apt 2803722742 in 39.87 sec (progress: 4813/25215)\n",
      "\n",
      "[4/100] Apartment ID=2863686322\n",
      "Done apt 2863686322 in 39.84 sec (progress: 4814/25215)\n",
      "\n",
      "[5/100] Apartment ID=2857003382\n",
      "Done apt 2857003382 in 40.18 sec (progress: 4815/25215)\n",
      "\n",
      "[6/100] Apartment ID=2856965500\n",
      "Done apt 2856965500 in 39.56 sec (progress: 4816/25215)\n",
      "\n",
      "[7/100] Apartment ID=2834769252\n",
      "Done apt 2834769252 in 39.78 sec (progress: 4817/25215)\n",
      "\n",
      "[8/100] Apartment ID=2834717554\n",
      "Done apt 2834717554 in 39.16 sec (progress: 4818/25215)\n",
      "\n",
      "[9/100] Apartment ID=1590264475\n",
      "Done apt 1590264475 in 39.04 sec (progress: 4819/25215)\n",
      "\n",
      "[10/100] Apartment ID=1571546745\n",
      "Done apt 1571546745 in 39.74 sec (progress: 4820/25215)\n",
      "\n",
      "[11/100] Apartment ID=2839543840\n",
      "Done apt 2839543840 in 38.38 sec (progress: 4821/25215)\n",
      "\n",
      "[12/100] Apartment ID=2807359110\n",
      "Done apt 2807359110 in 38.25 sec (progress: 4822/25215)\n",
      "\n",
      "[13/100] Apartment ID=2830725340\n",
      "Done apt 2830725340 in 38.50 sec (progress: 4823/25215)\n",
      "\n",
      "[14/100] Apartment ID=2839556934\n",
      "Done apt 2839556934 in 38.04 sec (progress: 4824/25215)\n",
      "\n",
      "[15/100] Apartment ID=2800580730\n",
      "Done apt 2800580730 in 38.32 sec (progress: 4825/25215)\n",
      "\n",
      "[16/100] Apartment ID=2839531360\n",
      "Done apt 2839531360 in 38.48 sec (progress: 4826/25215)\n",
      "\n",
      "[17/100] Apartment ID=2823605308\n",
      "Done apt 2823605308 in 38.93 sec (progress: 4827/25215)\n",
      "\n",
      "[18/100] Apartment ID=2843367132\n",
      "Done apt 2843367132 in 39.08 sec (progress: 4828/25215)\n",
      "\n",
      "[19/100] Apartment ID=2717044544\n",
      "Done apt 2717044544 in 38.88 sec (progress: 4829/25215)\n",
      "\n",
      "[20/100] Apartment ID=2764529916\n",
      "Done apt 2764529916 in 38.22 sec (progress: 4830/25215)\n",
      "\n",
      "[21/100] Apartment ID=2853072528\n",
      "Done apt 2853072528 in 38.89 sec (progress: 4831/25215)\n",
      "\n",
      "[22/100] Apartment ID=2863180720\n",
      "Done apt 2863180720 in 38.78 sec (progress: 4832/25215)\n",
      "\n",
      "[23/100] Apartment ID=1557084641\n",
      "Done apt 1557084641 in 38.32 sec (progress: 4833/25215)\n",
      "\n",
      "[24/100] Apartment ID=2836875528\n",
      "Done apt 2836875528 in 38.66 sec (progress: 4834/25215)\n",
      "\n",
      "[25/100] Apartment ID=2717135170\n",
      "Done apt 2717135170 in 38.34 sec (progress: 4835/25215)\n",
      "\n",
      "[26/100] Apartment ID=1533761289\n",
      "Done apt 1533761289 in 38.47 sec (progress: 4836/25215)\n",
      "\n",
      "[27/100] Apartment ID=2834756582\n",
      "Done apt 2834756582 in 39.14 sec (progress: 4837/25215)\n",
      "\n",
      "[28/100] Apartment ID=2834782226\n",
      "Done apt 2834782226 in 38.87 sec (progress: 4838/25215)\n",
      "\n",
      "[29/100] Apartment ID=2830661138\n",
      "Done apt 2830661138 in 38.93 sec (progress: 4839/25215)\n",
      "\n",
      "[30/100] Apartment ID=2860572956\n",
      "Done apt 2860572956 in 39.92 sec (progress: 4840/25215)\n",
      "\n",
      "[31/100] Apartment ID=2857029714\n",
      "Done apt 2857029714 in 37.56 sec (progress: 4841/25215)\n",
      "\n",
      "[32/100] Apartment ID=1554196681\n",
      "Done apt 1554196681 in 38.03 sec (progress: 4842/25215)\n",
      "\n",
      "[33/100] Apartment ID=1575625645\n",
      "Done apt 1575625645 in 38.04 sec (progress: 4843/25215)\n",
      "\n",
      "[34/100] Apartment ID=2818345748\n",
      "Done apt 2818345748 in 37.83 sec (progress: 4844/25215)\n",
      "\n",
      "[35/100] Apartment ID=2815239490\n",
      "Done apt 2815239490 in 38.41 sec (progress: 4845/25215)\n",
      "\n",
      "[36/100] Apartment ID=1590262343\n",
      "Done apt 1590262343 in 37.78 sec (progress: 4846/25215)\n",
      "\n",
      "[37/100] Apartment ID=2839031832\n",
      "Done apt 2839031832 in 37.92 sec (progress: 4847/25215)\n",
      "\n",
      "[38/100] Apartment ID=2856087556\n",
      "Done apt 2856087556 in 40.00 sec (progress: 4848/25215)\n",
      "\n",
      "[39/100] Apartment ID=1583290383\n",
      "Done apt 1583290383 in 37.90 sec (progress: 4849/25215)\n",
      "\n",
      "[40/100] Apartment ID=1586669705\n",
      "Done apt 1586669705 in 38.93 sec (progress: 4850/25215)\n",
      "\n",
      "[41/100] Apartment ID=1585597379\n",
      "Done apt 1585597379 in 38.10 sec (progress: 4851/25215)\n",
      "\n",
      "[42/100] Apartment ID=2854285072\n",
      "Done apt 2854285072 in 37.85 sec (progress: 4852/25215)\n",
      "\n",
      "[43/100] Apartment ID=2839569394\n",
      "Done apt 2839569394 in 38.11 sec (progress: 4853/25215)\n",
      "\n",
      "[44/100] Apartment ID=1591069957\n",
      "Done apt 1591069957 in 37.96 sec (progress: 4854/25215)\n",
      "\n",
      "[45/100] Apartment ID=2864468750\n",
      "Done apt 2864468750 in 37.78 sec (progress: 4855/25215)\n",
      "\n",
      "[46/100] Apartment ID=2864453158\n",
      "Done apt 2864453158 in 37.57 sec (progress: 4856/25215)\n",
      "\n",
      "[47/100] Apartment ID=2852305420\n",
      "Done apt 2852305420 in 37.90 sec (progress: 4857/25215)\n",
      "\n",
      "[48/100] Apartment ID=1592596887\n",
      "Done apt 1592596887 in 37.86 sec (progress: 4858/25215)\n",
      "\n",
      "[49/100] Apartment ID=1592825255\n",
      "Done apt 1592825255 in 38.03 sec (progress: 4859/25215)\n",
      "\n",
      "[50/100] Apartment ID=1573074599\n",
      "Done apt 1573074599 in 37.68 sec (progress: 4860/25215)\n",
      "\n",
      "[51/100] Apartment ID=2807942388\n",
      "Done apt 2807942388 in 37.99 sec (progress: 4861/25215)\n",
      "\n",
      "[52/100] Apartment ID=1420984797\n",
      "Done apt 1420984797 in 38.92 sec (progress: 4862/25215)\n",
      "\n",
      "[53/100] Apartment ID=1588503271\n",
      "Done apt 1588503271 in 37.70 sec (progress: 4863/25215)\n",
      "\n",
      "[54/100] Apartment ID=2864352532\n",
      "Done apt 2864352532 in 37.92 sec (progress: 4864/25215)\n",
      "\n",
      "[55/100] Apartment ID=2854963228\n",
      "Done apt 2854963228 in 37.82 sec (progress: 4865/25215)\n",
      "\n",
      "[56/100] Apartment ID=2854976620\n",
      "Done apt 2854976620 in 38.07 sec (progress: 4866/25215)\n",
      "\n",
      "[57/100] Apartment ID=2854257550\n",
      "Done apt 2854257550 in 37.75 sec (progress: 4867/25215)\n",
      "\n",
      "[58/100] Apartment ID=2839485426\n",
      "Done apt 2839485426 in 37.88 sec (progress: 4868/25215)\n",
      "\n",
      "[59/100] Apartment ID=1585599511\n",
      "Done apt 1585599511 in 37.70 sec (progress: 4869/25215)\n",
      "\n",
      "[60/100] Apartment ID=1557753893\n",
      "Done apt 1557753893 in 38.00 sec (progress: 4870/25215)\n",
      "\n",
      "[61/100] Apartment ID=1573031225\n",
      "Done apt 1573031225 in 37.51 sec (progress: 4871/25215)\n",
      "\n",
      "[62/100] Apartment ID=2850944460\n",
      "Done apt 2850944460 in 38.16 sec (progress: 4872/25215)\n",
      "\n",
      "[63/100] Apartment ID=1591173965\n",
      "Done apt 1591173965 in 38.01 sec (progress: 4873/25215)\n",
      "\n",
      "[64/100] Apartment ID=1576071385\n",
      "Done apt 1576071385 in 37.76 sec (progress: 4874/25215)\n",
      "\n",
      "[65/100] Apartment ID=2825409444\n",
      "Done apt 2825409444 in 37.84 sec (progress: 4875/25215)\n",
      "\n",
      "[66/100] Apartment ID=1583438607\n",
      "Done apt 1583438607 in 39.24 sec (progress: 4876/25215)\n",
      "\n",
      "[67/100] Apartment ID=1589122821\n",
      "Done apt 1589122821 in 39.63 sec (progress: 4877/25215)\n",
      "\n",
      "[68/100] Apartment ID=2852846746\n",
      "Done apt 2852846746 in 38.42 sec (progress: 4878/25215)\n",
      "\n",
      "[69/100] Apartment ID=2834708902\n",
      "Done apt 2834708902 in 37.68 sec (progress: 4879/25215)\n",
      "\n",
      "[70/100] Apartment ID=2852936068\n",
      "Done apt 2852936068 in 37.88 sec (progress: 4880/25215)\n",
      "\n",
      "[71/100] Apartment ID=2748370002\n",
      "Done apt 2748370002 in 38.18 sec (progress: 4881/25215)\n",
      "\n",
      "[72/100] Apartment ID=1533719581\n",
      "Done apt 1533719581 in 37.70 sec (progress: 4882/25215)\n",
      "\n",
      "[73/100] Apartment ID=1564979771\n",
      "Done apt 1564979771 in 40.19 sec (progress: 4883/25215)\n",
      "\n",
      "[74/100] Apartment ID=2856088514\n",
      "Done apt 2856088514 in 38.01 sec (progress: 4884/25215)\n",
      "\n",
      "[75/100] Apartment ID=2853730974\n",
      "Done apt 2853730974 in 38.17 sec (progress: 4885/25215)\n",
      "\n",
      "[76/100] Apartment ID=2860707956\n",
      "Done apt 2860707956 in 38.88 sec (progress: 4886/25215)\n",
      "\n",
      "[77/100] Apartment ID=2853736868\n",
      "Done apt 2853736868 in 37.80 sec (progress: 4887/25215)\n",
      "\n",
      "[78/100] Apartment ID=2850760292\n",
      "Done apt 2850760292 in 37.86 sec (progress: 4888/25215)\n",
      "\n",
      "[79/100] Apartment ID=2850544862\n",
      "Done apt 2850544862 in 37.71 sec (progress: 4889/25215)\n",
      "\n",
      "[80/100] Apartment ID=2840077574\n",
      "Done apt 2840077574 in 37.58 sec (progress: 4890/25215)\n",
      "\n",
      "[81/100] Apartment ID=1546773645\n",
      "Done apt 1546773645 in 37.88 sec (progress: 4891/25215)\n",
      "\n",
      "[82/100] Apartment ID=1581030891\n",
      "Done apt 1581030891 in 38.25 sec (progress: 4892/25215)\n",
      "\n",
      "[83/100] Apartment ID=2746680510\n",
      "Done apt 2746680510 in 38.06 sec (progress: 4893/25215)\n",
      "\n",
      "[84/100] Apartment ID=1579556627\n",
      "Done apt 1579556627 in 38.95 sec (progress: 4894/25215)\n",
      "\n",
      "[85/100] Apartment ID=2853397890\n",
      "Done apt 2853397890 in 39.54 sec (progress: 4895/25215)\n",
      "\n",
      "[86/100] Apartment ID=2779521790\n",
      "Done apt 2779521790 in 39.25 sec (progress: 4896/25215)\n",
      "\n",
      "[87/100] Apartment ID=1569954187\n",
      "Done apt 1569954187 in 37.76 sec (progress: 4897/25215)\n",
      "\n",
      "[88/100] Apartment ID=2770339838\n",
      "Done apt 2770339838 in 37.54 sec (progress: 4898/25215)\n",
      "\n",
      "[89/100] Apartment ID=2848036348\n",
      "Done apt 2848036348 in 37.82 sec (progress: 4899/25215)\n",
      "\n",
      "[90/100] Apartment ID=2841745272\n",
      "Done apt 2841745272 in 38.95 sec (progress: 4900/25215)\n",
      "\n",
      "[91/100] Apartment ID=1523293705\n",
      "Done apt 1523293705 in 38.62 sec (progress: 4901/25215)\n",
      "\n",
      "[92/100] Apartment ID=2755250640\n",
      "Done apt 2755250640 in 38.03 sec (progress: 4902/25215)\n",
      "\n",
      "[93/100] Apartment ID=2789708698\n",
      "Done apt 2789708698 in 37.81 sec (progress: 4903/25215)\n",
      "\n",
      "[94/100] Apartment ID=1534505201\n",
      "Done apt 1534505201 in 38.06 sec (progress: 4904/25215)\n",
      "\n",
      "[95/100] Apartment ID=2851714934\n",
      "Done apt 2851714934 in 37.62 sec (progress: 4905/25215)\n",
      "\n",
      "[96/100] Apartment ID=2849208052\n",
      "Done apt 2849208052 in 39.77 sec (progress: 4906/25215)\n",
      "\n",
      "[97/100] Apartment ID=2755237910\n",
      "Done apt 2755237910 in 38.06 sec (progress: 4907/25215)\n",
      "\n",
      "[98/100] Apartment ID=2755135016\n",
      "Done apt 2755135016 in 37.74 sec (progress: 4908/25215)\n",
      "\n",
      "[99/100] Apartment ID=2801952612\n",
      "Done apt 2801952612 in 39.28 sec (progress: 4909/25215)\n",
      "\n",
      "[100/100] Apartment ID=2755250636\n",
      "Done apt 2755250636 in 38.12 sec (progress: 4910/25215)\n",
      "✅ Batch completed and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "OUTPUT_FILE = \"apartment_graphs.pkl\"\n",
    "BATCH_SIZE = 100   # change this number freely\n",
    "\n",
    "# Load progress if exists\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"rb\") as f:\n",
    "        all_graphs = pickle.load(f)\n",
    "    done_ids = set(all_graphs.keys())\n",
    "    print(f\"Resuming: {len(done_ids)} apartments already done.\")\n",
    "else:\n",
    "    all_graphs = {}\n",
    "    done_ids = set()\n",
    "\n",
    "# All apartments\n",
    "apt_ids = df_deptos[\"id\"].tolist()\n",
    "pending_ids = [i for i in apt_ids if i not in done_ids]\n",
    "\n",
    "# Limit to one batch\n",
    "batch_ids = pending_ids[:BATCH_SIZE]\n",
    "print(f\"Processing {len(batch_ids)} apartments in this batch \"\n",
    "      f\"(remaining after this: {len(pending_ids)-len(batch_ids)})\")\n",
    "\n",
    "for idx, apt_id in enumerate(batch_ids, 1):\n",
    "    print(f\"\\n[{idx}/{len(batch_ids)}] Apartment ID={apt_id}\")\n",
    "    start = time.time()\n",
    "\n",
    "    graphs = {}\n",
    "    for cls in CLASSES:\n",
    "        g = export_apartment_class_graph(apt_id, cls)\n",
    "        graphs[cls] = g  # can be None for now\n",
    "\n",
    "    all_graphs[apt_id] = graphs\n",
    "\n",
    "    # Save progress after each apartment\n",
    "    with open(OUTPUT_FILE, \"wb\") as f:\n",
    "        pickle.dump(all_graphs, f)\n",
    "\n",
    "    print(f\"Done apt {apt_id} in {time.time()-start:.2f} sec \"\n",
    "          f\"(progress: {len(all_graphs)}/{len(apt_ids)})\")\n",
    "\n",
    "print(\"✅ Batch completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3716950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 apartments\n",
      "Some apartment IDs: [1548097259, 2732119230, 1592811585]\n",
      "\n",
      "Apartment 1548097259:\n",
      "  sport_and_leisure: Data(x=torch.Size([90, 4]), edge_index=torch.Size([2, 89]), edge_attr=torch.Size([89, 1]))\n",
      "  medical: Data(x=torch.Size([32, 4]), edge_index=torch.Size([2, 31]), edge_attr=torch.Size([31, 1]))\n",
      "  education_prim: Data(x=torch.Size([9, 4]), edge_index=torch.Size([2, 8]), edge_attr=torch.Size([8, 1]))\n",
      "  veterinary: Data(x=torch.Size([2, 4]), edge_index=torch.Size([2, 1]), edge_attr=torch.Size([1, 1]))\n",
      "  food_and_drink_stores: Data(x=torch.Size([13, 4]), edge_index=torch.Size([2, 12]), edge_attr=torch.Size([12, 1]))\n",
      "  arts_and_entertainment: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  food_and_drink: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  park_like: Data(x=torch.Size([7, 4]), edge_index=torch.Size([2, 6]), edge_attr=torch.Size([6, 1]))\n",
      "  security: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n",
      "  religion: Data(x=torch.Size([4, 4]), edge_index=torch.Size([2, 3]), edge_attr=torch.Size([3, 1]))\n",
      "  education_sup: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    graphs = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(graphs)} apartments\")\n",
    "\n",
    "# Print first 3 keys (apartment IDs)\n",
    "print(\"Some apartment IDs:\", list(graphs.keys())[:3])\n",
    "\n",
    "# Inspect one apartment\n",
    "apt_id = list(graphs.keys())[0]\n",
    "apt_data = graphs[apt_id]\n",
    "\n",
    "print(f\"\\nApartment {apt_id}:\")\n",
    "for cls, data in apt_data.items():\n",
    "    if data is None:\n",
    "        print(f\"  {cls}: None (no POIs)\")\n",
    "    else:\n",
    "        print(f\"  {cls}: Data(x={data.x.shape}, edge_index={data.edge_index.shape}, edge_attr={data.edge_attr.shape})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab6275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment 1548097259 embeddings:\n",
      "sport_and_leisure [-0.18648088  0.5579107  -0.4131222   0.27406204 -0.35570735  0.40606898\n",
      "  0.14326589 -0.5241446 ]\n",
      "medical [-0.20881331  0.31410986 -0.40781352  0.36022988 -0.28139758  0.50777537\n",
      "  0.04728226 -0.36782062]\n",
      "education_prim [-0.34600687  0.42414403 -0.4898538   0.15145272 -0.4337186   0.6039778\n",
      "  0.08607332 -0.5473764 ]\n",
      "veterinary [-0.27915993  0.22826114 -0.191151    0.27866125 -0.18302271  0.27510607\n",
      "  0.21248034 -0.57624197]\n",
      "food_and_drink_stores [-0.27390623  0.4828838  -0.44862312  0.20662722 -0.39463884  0.5065929\n",
      "  0.11644609 -0.5412748 ]\n",
      "arts_and_entertainment [-0.17523065  0.2991605  -0.37270257  0.40328738 -0.24081656  0.4592786\n",
      "  0.05530962 -0.3462455 ]\n",
      "food_and_drink [-0.32072455  0.48084846 -0.51296467  0.15983051 -0.4509474   0.6042404\n",
      "  0.08255335 -0.5402578 ]\n",
      "park_like [-0.34960094  0.40333438 -0.4733036   0.15413487 -0.42034778  0.59179056\n",
      "  0.09157699 -0.5501465 ]\n",
      "security [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n",
      "religion [-0.36173084  0.33310184 -0.4174466   0.1631871  -0.3752213   0.5506586\n",
      "  0.11015184 -0.5594954 ]\n",
      "education_sup [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "# ---------------- Load the pickle file ---------------- #\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    apartment_graphs = pickle.load(f)\n",
    "\n",
    "# ---------------- Small GNN model ---------------- #\n",
    "class SimpleGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        # Two-layer GraphSAGE\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        if batch is None:\n",
    "            # Single graph → make batch of zeros\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long)\n",
    "        return global_mean_pool(x, batch)  # → one vector per graph\n",
    "\n",
    "\n",
    "# ---------------- Pick one apartment ---------------- #\n",
    "apt_id = next(iter(apartment_graphs.keys()))  # just the first apartment\n",
    "graphs = apartment_graphs[apt_id]\n",
    "\n",
    "# Feature dimension (4 in your case: is_apartment, cat1, cat2, cat3)\n",
    "in_channels = graphs[next(iter(graphs))].x.shape[1]\n",
    "model = SimpleGraphSAGE(in_channels, hidden_channels=16, out_channels=8)\n",
    "\n",
    "# ---------------- Compute embeddings ---------------- #\n",
    "embeddings = {}\n",
    "for cls, g in graphs.items():\n",
    "    if g is None:\n",
    "        embeddings[cls] = None\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            emb = model(g.x, g.edge_index)\n",
    "            embeddings[cls] = emb.squeeze().numpy()  # shape (out_channels,)\n",
    "\n",
    "# ---------------- Inspect ---------------- #\n",
    "print(f\"Apartment {apt_id} embeddings:\")\n",
    "for cls, emb in embeddings.items():\n",
    "    print(cls, None if emb is None else emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea50fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781e6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
