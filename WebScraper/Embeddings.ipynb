{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740140fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, time, pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b109987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script: Export one (apartment × POI class) subgraph from Neo4j\n",
    "to a PyTorch Geometric Data object.\n",
    "\n",
    "Steps:\n",
    "1. Query apartment + POI nodes and edges from Neo4j.\n",
    "2. Build node feature matrix (x), edge_index, edge_attr.\n",
    "3. Package into torch_geometric.data.Data.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Config ---------------- #\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "DATABASE = \"neo4jads\"\n",
    "\n",
    "# Radii per category (meters)\n",
    "RADII = {\"CERCA_DE_CAT1\": 600.0, \"CERCA_DE_CAT2\": 1200.0, \"CERCA_DE_CAT3\": 2400.0}\n",
    "\n",
    "# Example\n",
    "TEST_APT_ID = 1548097259        # <-- replace with real id from your df\n",
    "TEST_CLASS = \"medical\"    # one of the 11 classes\n",
    "\n",
    "# ---------------- Cypher Queries ---------------- #\n",
    "NODE_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})\n",
    "RETURN elementId(d) AS id, 'Departamento' AS label,\n",
    "       d.id AS apt_id, d.latitude AS lat, d.longitude AS lon, null AS cat\n",
    "UNION\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "RETURN elementId(p) AS id, 'POI' AS label,\n",
    "       null AS apt_id, null AS lat, null AS lon, p.cat AS cat\n",
    "\"\"\"\n",
    "\n",
    "REL_QUERY = \"\"\"\n",
    "MATCH (d:Departamento {id:$apt_id})-[r:CERCA_DE_CAT1|CERCA_DE_CAT2|CERCA_DE_CAT3]->(p:POI)\n",
    "WHERE p.class = $class\n",
    "WITH elementId(d) AS source, elementId(p) AS target, type(r) AS t, r.distancia_metros AS dist\n",
    "WITH source, target,\n",
    "  CASE t\n",
    "    WHEN 'CERCA_DE_CAT1' THEN CASE WHEN 1.0 - dist / $r_cat1 > 0.001 THEN 1.0 - dist / $r_cat1 ELSE 0.001 END\n",
    "    WHEN 'CERCA_DE_CAT2' THEN CASE WHEN 1.0 - dist / $r_cat2 > 0.001 THEN 1.0 - dist / $r_cat2 ELSE 0.001 END\n",
    "    ELSE CASE WHEN 1.0 - dist / $r_cat3 > 0.001 THEN 1.0 - dist / $r_cat3 ELSE 0.001 END\n",
    "  END AS weight\n",
    "RETURN source, target, weight\n",
    "\"\"\"\n",
    "\n",
    "# ---------------- Export Function ---------------- #\n",
    "def export_apartment_class_graph(apt_id: int, class_name: str) -> Data:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    with driver.session(database=DATABASE) as session:\n",
    "        \n",
    "        # --- Nodes\n",
    "        nodes = session.run(\n",
    "            NODE_QUERY,\n",
    "            {\"apt_id\": apt_id, \"class\": class_name}\n",
    "        ).data()\n",
    "        if not nodes:\n",
    "            print(f\"No nodes found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        node_df = pd.DataFrame(nodes)\n",
    "        \n",
    "        # Map neo4j ids -> local indices\n",
    "        id_map = {nid: i for i, nid in enumerate(node_df[\"id\"].tolist())}\n",
    "        \n",
    "        # --- Edges\n",
    "        edges = session.run(\n",
    "            REL_QUERY,\n",
    "            {\n",
    "                \"apt_id\": apt_id, \"class\": class_name,\n",
    "                \"r_cat1\": RADII[\"CERCA_DE_CAT1\"],\n",
    "                \"r_cat2\": RADII[\"CERCA_DE_CAT2\"],\n",
    "                \"r_cat3\": RADII[\"CERCA_DE_CAT3\"],\n",
    "            }\n",
    "        ).data()\n",
    "        if not edges:\n",
    "            print(f\"No edges found for apartment {apt_id}, class {class_name}\")\n",
    "            return None\n",
    "        edge_df = pd.DataFrame(edges)\n",
    "        \n",
    "        # Remap to local indices\n",
    "        edge_index = torch.tensor([\n",
    "            [id_map[s] for s in edge_df[\"source\"]],\n",
    "            [id_map[t] for t in edge_df[\"target\"]],\n",
    "        ], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_df[\"weight\"].values, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # --- Node features\n",
    "        # Apartment node = mark explicitly\n",
    "        feats = []\n",
    "        for _, row in node_df.iterrows():\n",
    "            if row[\"label\"] == \"Departamento\":\n",
    "                feats.append([1.0, 0.0, 0.0, 0.0])  # [is_apartment, cat1, cat2, cat3]\n",
    "            else:\n",
    "                onehot = [0.0, 0.0, 0.0, 0.0]\n",
    "                if row[\"cat\"] is not None:\n",
    "                    try:\n",
    "                        idx = int(row[\"cat\"])\n",
    "                        if 0 <= idx < len(onehot):\n",
    "                            onehot[idx] = 1.0\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass  # skip if cat is invalid\n",
    "                feats.append(onehot)\n",
    "        x = torch.tensor(np.array(feats), dtype=torch.float)\n",
    "        \n",
    "        # Build Data object\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            apt_id=apt_id,\n",
    "            poi_class=class_name\n",
    "        )\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9a2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deptos = pd.read_csv('Datasets/dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1fca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Test ---------------- #\n",
    "CLASSES = [\n",
    "    'sport_and_leisure',\n",
    "    'medical',\n",
    "    'education_prim',\n",
    "    'veterinary',\n",
    "    'food_and_drink_stores',\n",
    "    'arts_and_entertainment',\n",
    "    'food_and_drink',\n",
    "    'park_like',\n",
    "    'security',\n",
    "    'religion',\n",
    "    'education_sup'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5941af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: 4965 apartments already done.\n",
      "Processing 55 apartments in this batch (remaining after this: 20195)\n",
      "\n",
      "[1/55] Apartment ID=1571064251\n",
      "Done apt 1571064251 in 41.37 sec (progress: 4966/25215)\n",
      "\n",
      "[2/55] Apartment ID=2856047996\n",
      "Done apt 2856047996 in 38.88 sec (progress: 4967/25215)\n",
      "\n",
      "[3/55] Apartment ID=2778379320\n",
      "Done apt 2778379320 in 41.58 sec (progress: 4968/25215)\n",
      "\n",
      "[4/55] Apartment ID=1566347201\n",
      "Done apt 1566347201 in 38.72 sec (progress: 4969/25215)\n",
      "\n",
      "[5/55] Apartment ID=2762896868\n",
      "Done apt 2762896868 in 38.91 sec (progress: 4970/25215)\n",
      "\n",
      "[6/55] Apartment ID=1577239111\n",
      "Done apt 1577239111 in 39.54 sec (progress: 4971/25215)\n",
      "\n",
      "[7/55] Apartment ID=2753182358\n",
      "Done apt 2753182358 in 39.24 sec (progress: 4972/25215)\n",
      "\n",
      "[8/55] Apartment ID=2850947176\n",
      "Done apt 2850947176 in 39.79 sec (progress: 4973/25215)\n",
      "\n",
      "[9/55] Apartment ID=1560678789\n",
      "Done apt 1560678789 in 40.53 sec (progress: 4974/25215)\n",
      "\n",
      "[10/55] Apartment ID=2739965334\n",
      "Done apt 2739965334 in 38.75 sec (progress: 4975/25215)\n",
      "\n",
      "[11/55] Apartment ID=1554230341\n",
      "Done apt 1554230341 in 39.27 sec (progress: 4976/25215)\n",
      "\n",
      "[12/55] Apartment ID=2794696850\n",
      "Done apt 2794696850 in 38.54 sec (progress: 4977/25215)\n",
      "\n",
      "[13/55] Apartment ID=2778369026\n",
      "Done apt 2778369026 in 38.73 sec (progress: 4978/25215)\n",
      "\n",
      "[14/55] Apartment ID=1541075815\n",
      "Done apt 1541075815 in 38.14 sec (progress: 4979/25215)\n",
      "\n",
      "[15/55] Apartment ID=2762896680\n",
      "Done apt 2762896680 in 38.55 sec (progress: 4980/25215)\n",
      "\n",
      "[16/55] Apartment ID=1572935731\n",
      "Done apt 1572935731 in 37.99 sec (progress: 4981/25215)\n",
      "\n",
      "[17/55] Apartment ID=2863515474\n",
      "Done apt 2863515474 in 38.20 sec (progress: 4982/25215)\n",
      "\n",
      "[18/55] Apartment ID=2854349786\n",
      "Done apt 2854349786 in 38.33 sec (progress: 4983/25215)\n",
      "\n",
      "[19/55] Apartment ID=2846673214\n",
      "Done apt 2846673214 in 40.19 sec (progress: 4984/25215)\n",
      "\n",
      "[20/55] Apartment ID=2822357704\n",
      "Done apt 2822357704 in 37.99 sec (progress: 4985/25215)\n",
      "\n",
      "[21/55] Apartment ID=2800414158\n",
      "Done apt 2800414158 in 39.06 sec (progress: 4986/25215)\n",
      "\n",
      "[22/55] Apartment ID=1548510417\n",
      "Done apt 1548510417 in 38.49 sec (progress: 4987/25215)\n",
      "\n",
      "[23/55] Apartment ID=2827131484\n",
      "Done apt 2827131484 in 38.16 sec (progress: 4988/25215)\n",
      "\n",
      "[24/55] Apartment ID=2778415442\n",
      "Done apt 2778415442 in 38.48 sec (progress: 4989/25215)\n",
      "\n",
      "[25/55] Apartment ID=1539137147\n",
      "Done apt 1539137147 in 38.24 sec (progress: 4990/25215)\n",
      "\n",
      "[26/55] Apartment ID=2778554316\n",
      "Done apt 2778554316 in 37.83 sec (progress: 4991/25215)\n",
      "\n",
      "[27/55] Apartment ID=1584369433\n",
      "Done apt 1584369433 in 38.34 sec (progress: 4992/25215)\n",
      "\n",
      "[28/55] Apartment ID=2836600246\n",
      "Done apt 2836600246 in 37.85 sec (progress: 4993/25215)\n",
      "\n",
      "[29/55] Apartment ID=2820086372\n",
      "Done apt 2820086372 in 38.09 sec (progress: 4994/25215)\n",
      "\n",
      "[30/55] Apartment ID=2825218546\n",
      "Done apt 2825218546 in 38.13 sec (progress: 4995/25215)\n",
      "\n",
      "[31/55] Apartment ID=1544061035\n",
      "Done apt 1544061035 in 38.50 sec (progress: 4996/25215)\n",
      "\n",
      "[32/55] Apartment ID=2778492624\n",
      "Done apt 2778492624 in 38.21 sec (progress: 4997/25215)\n",
      "\n",
      "[33/55] Apartment ID=2837938300\n",
      "Done apt 2837938300 in 37.80 sec (progress: 4998/25215)\n",
      "\n",
      "[34/55] Apartment ID=1572381333\n",
      "Done apt 1572381333 in 39.06 sec (progress: 4999/25215)\n",
      "\n",
      "[35/55] Apartment ID=2833900624\n",
      "Done apt 2833900624 in 38.24 sec (progress: 5000/25215)\n",
      "\n",
      "[36/55] Apartment ID=1562101281\n",
      "Done apt 1562101281 in 37.93 sec (progress: 5001/25215)\n",
      "\n",
      "[37/55] Apartment ID=1555394991\n",
      "Done apt 1555394991 in 38.17 sec (progress: 5002/25215)\n",
      "\n",
      "[38/55] Apartment ID=1539552187\n",
      "Done apt 1539552187 in 38.39 sec (progress: 5003/25215)\n",
      "\n",
      "[39/55] Apartment ID=1546128329\n",
      "Done apt 1546128329 in 38.37 sec (progress: 5004/25215)\n",
      "\n",
      "[40/55] Apartment ID=1534730057\n",
      "Done apt 1534730057 in 37.94 sec (progress: 5005/25215)\n",
      "\n",
      "[41/55] Apartment ID=2836681954\n",
      "Done apt 2836681954 in 38.04 sec (progress: 5006/25215)\n",
      "\n",
      "[42/55] Apartment ID=1582007083\n",
      "Done apt 1582007083 in 38.22 sec (progress: 5007/25215)\n",
      "\n",
      "[43/55] Apartment ID=2832513698\n",
      "Done apt 2832513698 in 38.14 sec (progress: 5008/25215)\n",
      "\n",
      "[44/55] Apartment ID=1564878633\n",
      "Done apt 1564878633 in 38.37 sec (progress: 5009/25215)\n",
      "\n",
      "[45/55] Apartment ID=1589625569\n",
      "Done apt 1589625569 in 38.84 sec (progress: 5010/25215)\n",
      "\n",
      "[46/55] Apartment ID=2861866730\n",
      "Done apt 2861866730 in 38.28 sec (progress: 5011/25215)\n",
      "\n",
      "[47/55] Apartment ID=1583004015\n",
      "Done apt 1583004015 in 38.31 sec (progress: 5012/25215)\n",
      "\n",
      "[48/55] Apartment ID=2852912402\n",
      "Done apt 2852912402 in 38.52 sec (progress: 5013/25215)\n",
      "\n",
      "[49/55] Apartment ID=1582965661\n",
      "Done apt 1582965661 in 38.67 sec (progress: 5014/25215)\n",
      "\n",
      "[50/55] Apartment ID=1589037547\n",
      "Done apt 1589037547 in 38.09 sec (progress: 5015/25215)\n",
      "\n",
      "[51/55] Apartment ID=1576440611\n",
      "Done apt 1576440611 in 38.32 sec (progress: 5016/25215)\n",
      "\n",
      "[52/55] Apartment ID=2859608000\n",
      "Done apt 2859608000 in 38.20 sec (progress: 5017/25215)\n",
      "\n",
      "[53/55] Apartment ID=1569322917\n",
      "Done apt 1569322917 in 38.94 sec (progress: 5018/25215)\n",
      "\n",
      "[54/55] Apartment ID=2861539908\n",
      "Done apt 2861539908 in 38.27 sec (progress: 5019/25215)\n",
      "\n",
      "[55/55] Apartment ID=1578398171\n",
      "Done apt 1578398171 in 38.12 sec (progress: 5020/25215)\n",
      "✅ Batch completed and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "OUTPUT_FILE = \"apartment_graphs.pkl\"\n",
    "BATCH_SIZE = 55   # change this number freely\n",
    "\n",
    "# Load progress if exists\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"rb\") as f:\n",
    "        all_graphs = pickle.load(f)\n",
    "    done_ids = set(all_graphs.keys())\n",
    "    print(f\"Resuming: {len(done_ids)} apartments already done.\")\n",
    "else:\n",
    "    all_graphs = {}\n",
    "    done_ids = set()\n",
    "\n",
    "# All apartments\n",
    "apt_ids = df_deptos[\"id\"].tolist()\n",
    "pending_ids = [i for i in apt_ids if i not in done_ids]\n",
    "\n",
    "# Limit to one batch\n",
    "batch_ids = pending_ids[:BATCH_SIZE]\n",
    "print(f\"Processing {len(batch_ids)} apartments in this batch \"\n",
    "      f\"(remaining after this: {len(pending_ids)-len(batch_ids)})\")\n",
    "\n",
    "for idx, apt_id in enumerate(batch_ids, 1):\n",
    "    print(f\"\\n[{idx}/{len(batch_ids)}] Apartment ID={apt_id}\")\n",
    "    start = time.time()\n",
    "\n",
    "    graphs = {}\n",
    "    for cls in CLASSES:\n",
    "        g = export_apartment_class_graph(apt_id, cls)\n",
    "        graphs[cls] = g  # can be None for now\n",
    "\n",
    "    all_graphs[apt_id] = graphs\n",
    "\n",
    "    # Save progress after each apartment\n",
    "    with open(OUTPUT_FILE, \"wb\") as f:\n",
    "        pickle.dump(all_graphs, f)\n",
    "\n",
    "    print(f\"Done apt {apt_id} in {time.time()-start:.2f} sec \"\n",
    "          f\"(progress: {len(all_graphs)}/{len(apt_ids)})\")\n",
    "\n",
    "print(\"✅ Batch completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3716950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 apartments\n",
      "Some apartment IDs: [1548097259, 2732119230, 1592811585]\n",
      "\n",
      "Apartment 1548097259:\n",
      "  sport_and_leisure: Data(x=torch.Size([90, 4]), edge_index=torch.Size([2, 89]), edge_attr=torch.Size([89, 1]))\n",
      "  medical: Data(x=torch.Size([32, 4]), edge_index=torch.Size([2, 31]), edge_attr=torch.Size([31, 1]))\n",
      "  education_prim: Data(x=torch.Size([9, 4]), edge_index=torch.Size([2, 8]), edge_attr=torch.Size([8, 1]))\n",
      "  veterinary: Data(x=torch.Size([2, 4]), edge_index=torch.Size([2, 1]), edge_attr=torch.Size([1, 1]))\n",
      "  food_and_drink_stores: Data(x=torch.Size([13, 4]), edge_index=torch.Size([2, 12]), edge_attr=torch.Size([12, 1]))\n",
      "  arts_and_entertainment: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  food_and_drink: Data(x=torch.Size([26, 4]), edge_index=torch.Size([2, 25]), edge_attr=torch.Size([25, 1]))\n",
      "  park_like: Data(x=torch.Size([7, 4]), edge_index=torch.Size([2, 6]), edge_attr=torch.Size([6, 1]))\n",
      "  security: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n",
      "  religion: Data(x=torch.Size([4, 4]), edge_index=torch.Size([2, 3]), edge_attr=torch.Size([3, 1]))\n",
      "  education_sup: Data(x=torch.Size([8, 4]), edge_index=torch.Size([2, 7]), edge_attr=torch.Size([7, 1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    graphs = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(graphs)} apartments\")\n",
    "\n",
    "# Print first 3 keys (apartment IDs)\n",
    "print(\"Some apartment IDs:\", list(graphs.keys())[:3])\n",
    "\n",
    "# Inspect one apartment\n",
    "apt_id = list(graphs.keys())[0]\n",
    "apt_data = graphs[apt_id]\n",
    "\n",
    "print(f\"\\nApartment {apt_id}:\")\n",
    "for cls, data in apt_data.items():\n",
    "    if data is None:\n",
    "        print(f\"  {cls}: None (no POIs)\")\n",
    "    else:\n",
    "        print(f\"  {cls}: Data(x={data.x.shape}, edge_index={data.edge_index.shape}, edge_attr={data.edge_attr.shape})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab6275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment 1548097259 embeddings:\n",
      "sport_and_leisure [-0.18648088  0.5579107  -0.4131222   0.27406204 -0.35570735  0.40606898\n",
      "  0.14326589 -0.5241446 ]\n",
      "medical [-0.20881331  0.31410986 -0.40781352  0.36022988 -0.28139758  0.50777537\n",
      "  0.04728226 -0.36782062]\n",
      "education_prim [-0.34600687  0.42414403 -0.4898538   0.15145272 -0.4337186   0.6039778\n",
      "  0.08607332 -0.5473764 ]\n",
      "veterinary [-0.27915993  0.22826114 -0.191151    0.27866125 -0.18302271  0.27510607\n",
      "  0.21248034 -0.57624197]\n",
      "food_and_drink_stores [-0.27390623  0.4828838  -0.44862312  0.20662722 -0.39463884  0.5065929\n",
      "  0.11644609 -0.5412748 ]\n",
      "arts_and_entertainment [-0.17523065  0.2991605  -0.37270257  0.40328738 -0.24081656  0.4592786\n",
      "  0.05530962 -0.3462455 ]\n",
      "food_and_drink [-0.32072455  0.48084846 -0.51296467  0.15983051 -0.4509474   0.6042404\n",
      "  0.08255335 -0.5402578 ]\n",
      "park_like [-0.34960094  0.40333438 -0.4733036   0.15413487 -0.42034778  0.59179056\n",
      "  0.09157699 -0.5501465 ]\n",
      "security [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n",
      "religion [-0.36173084  0.33310184 -0.4174466   0.1631871  -0.3752213   0.5506586\n",
      "  0.11015184 -0.5594954 ]\n",
      "education_sup [-0.20843989  0.20837197 -0.3466561   0.4006459  -0.21471098  0.4715337\n",
      "  0.04913595 -0.33925322]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "# ---------------- Load the pickle file ---------------- #\n",
    "with open(\"apartment_graphs.pkl\", \"rb\") as f:\n",
    "    apartment_graphs = pickle.load(f)\n",
    "\n",
    "# ---------------- Small GNN model ---------------- #\n",
    "class SimpleGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        # Two-layer GraphSAGE\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        if batch is None:\n",
    "            # Single graph → make batch of zeros\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long)\n",
    "        return global_mean_pool(x, batch)  # → one vector per graph\n",
    "\n",
    "\n",
    "# ---------------- Pick one apartment ---------------- #\n",
    "apt_id = next(iter(apartment_graphs.keys()))  # just the first apartment\n",
    "graphs = apartment_graphs[apt_id]\n",
    "\n",
    "# Feature dimension (4 in your case: is_apartment, cat1, cat2, cat3)\n",
    "in_channels = graphs[next(iter(graphs))].x.shape[1]\n",
    "model = SimpleGraphSAGE(in_channels, hidden_channels=16, out_channels=8)\n",
    "\n",
    "# ---------------- Compute embeddings ---------------- #\n",
    "embeddings = {}\n",
    "for cls, g in graphs.items():\n",
    "    if g is None:\n",
    "        embeddings[cls] = None\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            emb = model(g.x, g.edge_index)\n",
    "            embeddings[cls] = emb.squeeze().numpy()  # shape (out_channels,)\n",
    "\n",
    "# ---------------- Inspect ---------------- #\n",
    "print(f\"Apartment {apt_id} embeddings:\")\n",
    "for cls, emb in embeddings.items():\n",
    "    print(cls, None if emb is None else emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea50fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781e6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_export",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
