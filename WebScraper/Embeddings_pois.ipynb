{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac31d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e22098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 POI shards under Graph_data\n",
      "✅ wrote embeddings_poi_from_shards.csv with 25215 rows. Non-nulls per class:\n",
      "  - emb_sport_and_leisure: 25123\n",
      "  - emb_medical: 25087\n",
      "  - emb_education_prim: 24519\n",
      "  - emb_veterinary: 22982\n",
      "  - emb_food_and_drink_stores: 24694\n",
      "  - emb_arts_and_entertainment: 25007\n",
      "  - emb_food_and_drink: 24205\n",
      "  - emb_park_like: 24275\n",
      "  - emb_security: 24564\n",
      "  - emb_religion: 21291\n",
      "  - emb_education_sup: 24581\n"
     ]
    }
   ],
   "source": [
    "SHARD_DIR = Path(\"Graph_data\")\n",
    "OUT_CSV   = \"embeddings_poi_from_shards.csv\"\n",
    "\n",
    "CLASSES = [\n",
    "    'sport_and_leisure','medical','education_prim','veterinary','food_and_drink_stores',\n",
    "    'arts_and_entertainment','food_and_drink','park_like','security','religion','education_sup'\n",
    "]\n",
    "\n",
    "R1, R2, R3 = 600.0, 1200.0, 2400.0\n",
    "EPS = 1e-6 #Evita divisiones por 0\n",
    "\n",
    "def as_numpy_1d(t: Optional[torch.Tensor]) -> Optional[np.ndarray]:\n",
    "    if t is None:\n",
    "        return None\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        return t.view(-1).detach().cpu().numpy()\n",
    "    return None\n",
    "\n",
    "def get_raw_meters(g) -> Optional[np.ndarray]:\n",
    "    # Prefer explicit meters field if present; else edge_attr (new shards keep meters there)\n",
    "    if hasattr(g, \"edge_attr_meters\"):\n",
    "        return as_numpy_1d(getattr(g, \"edge_attr_meters\"))\n",
    "    return as_numpy_1d(getattr(g, \"edge_attr\", None))\n",
    "\n",
    "def baseline_from_meters(d: Optional[np.ndarray]) -> Optional[list]:\n",
    "    if d is None or d.size == 0:\n",
    "        return None\n",
    "    d = d.astype(float)\n",
    "    d_sorted = np.sort(d)\n",
    "    inv = 1.0 / (d_sorted + EPS)\n",
    "    return [\n",
    "        float(d_sorted.size),            # 0 count\n",
    "        float(d_sorted.mean()),          # 1 mean\n",
    "        float(d_sorted.min()),           # 2 min\n",
    "        float(d_sorted.max()),           # 3 max\n",
    "        float(np.median(d_sorted)),      # 4 median\n",
    "        float(d_sorted.std()),           # 5 std\n",
    "        float(inv.mean()),               # 6 mean_inv\n",
    "        float(inv.max()),                # 7 max_inv\n",
    "        float(inv.sum()),                # 8 sum_inv\n",
    "        float((d_sorted <= R1).mean()),  # 9  <= 600m\n",
    "        float((d_sorted <= R2).mean()),  # 10 <= 1200m\n",
    "        float((d_sorted <= R3).mean()),  # 11 <= 2400m\n",
    "    ]\n",
    "\n",
    "# --- Gather baselines per apartment ---\n",
    "rows = {}\n",
    "shards = sorted(SHARD_DIR.glob(\"shard_*.pkl\"))\n",
    "print(f\"Found {len(shards)} POI shards under {SHARD_DIR}\")\n",
    "\n",
    "for p in shards:\n",
    "    with open(p, \"rb\") as f:\n",
    "        d = pickle.load(f)  # dict[int -> dict[class -> Data|None]]\n",
    "    for aid, per_cls in d.items():\n",
    "        if aid not in rows:\n",
    "            rows[aid] = {f\"emb_{c}\": None for c in CLASSES}\n",
    "        for cls in CLASSES:\n",
    "            g = per_cls.get(cls)\n",
    "            if g is None:\n",
    "                rows[aid][f\"emb_{cls}\"] = None\n",
    "                continue\n",
    "            meters = get_raw_meters(g)\n",
    "            rows[aid][f\"emb_{cls}\"] = baseline_from_meters(meters)\n",
    "\n",
    "# --- Build DataFrame with JSON strings per class ---\n",
    "out = []\n",
    "for aid, rec in rows.items():\n",
    "    row = {\"id\": int(aid)}\n",
    "    for cls in CLASSES:\n",
    "        key = f\"emb_{cls}\"\n",
    "        row[key] = json.dumps(rec[key]) if rec[key] is not None else None\n",
    "    out.append(row)\n",
    "\n",
    "df_poi = pd.DataFrame(out).sort_values(\"id\").reset_index(drop=True)\n",
    "df_poi.to_csv(OUT_CSV, index=False)\n",
    "non_null_counts = {c: int(df_poi[c].notna().sum()) for c in df_poi.columns if c.startswith(\"emb_\")}\n",
    "print(f\"✅ wrote {OUT_CSV} with {len(df_poi)} rows. Non-nulls per class:\")\n",
    "for k,v in non_null_counts.items():\n",
    "    print(f\"  - {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d6c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment ID: 1583341281\n",
      "\n",
      "Class: medical embedding values:\n",
      "  dim00: 31.000000 → count_pois\n",
      "  dim01: 1619.239470 → mean_distance\n",
      "  dim02: 528.707642 → min_distance\n",
      "  dim03: 2341.403320 → max_distance\n",
      "  dim04: 1808.764771 → median_distance\n",
      "  dim05: 549.732507 → std_distance\n",
      "  dim06: 0.000758 → mean_inverse_distance\n",
      "  dim07: 0.001891 → max_inverse_distance\n",
      "  dim08: 0.023494 → sum_inverse_distance\n",
      "  dim09: 0.129032 → ratio_within_near_radius\n",
      "  dim10: 0.258065 → ratio_within_mid_radius\n",
      "  dim11: 1.000000 → ratio_within_far_radius\n"
     ]
    }
   ],
   "source": [
    "import random, json\n",
    "\n",
    "# Pick a random apartment or set manually\n",
    "#apt_id = random.choice(df_poi[\"id\"].tolist())\n",
    "apt_id = 1583341281  # <- uncomment to force a specific ID\n",
    "\n",
    "cls = \"medical\"  # change to any: sport_and_leisure, education_prim, etc.\n",
    "\n",
    "row = df_poi[df_poi[\"id\"] == apt_id].iloc[0]\n",
    "val_json = row[f\"emb_{cls}\"]\n",
    "\n",
    "print(f\"Apartment ID: {apt_id}\")\n",
    "if val_json is None:\n",
    "    print(f\"No embedding for class {cls}\")\n",
    "else:\n",
    "    vals = json.loads(val_json)\n",
    "    print(f\"\\nClass: {cls} embedding values:\")\n",
    "    labels = [\n",
    "        \"count_pois\", \"mean_distance\", \"min_distance\", \"max_distance\",\n",
    "        \"median_distance\", \"std_distance\", \"mean_inverse_distance\",\n",
    "        \"max_inverse_distance\", \"sum_inverse_distance\",\n",
    "        \"ratio_within_near_radius\", \"ratio_within_mid_radius\", \"ratio_within_far_radius\"\n",
    "    ]\n",
    "    for i, (lab, v) in enumerate(zip(labels, vals)):\n",
    "        print(f\"  dim{i:02d}: {v:.6f} → {lab}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
