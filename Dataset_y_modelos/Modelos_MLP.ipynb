{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779df9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import (\n",
    "r2_score,\n",
    "mean_absolute_error,\n",
    "root_mean_squared_error,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd029f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Config ======\n",
    "SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "MAX_EPOCHS_TUNER = 200 # tuner \n",
    "EPOCHS_FINAL = 1000 # entrenamiento final con los mejores HP\n",
    "ES_PATIENCE = 50\n",
    "RLROP_PATIENCE = 15\n",
    "RLROP_FACTOR = 0.5\n",
    "MIN_LR = 1e-6\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f654f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Utilidades ======\n",
    "def build_model(hp: kt.HyperParameters) -> keras.Model:\n",
    "    n_features = X_train.shape[1]\n",
    "    inputs = keras.Input(shape=(n_features,), name=\"features\")\n",
    "\n",
    "    x = inputs\n",
    "    # Capas ocultas\n",
    "    n_layers = hp.Int(\"n_layers\", min_value=1, max_value=4, step=1)\n",
    "    for i in range(n_layers):\n",
    "        units = hp.Int(f\"units_{i}\", min_value=64, max_value=512, step=64)\n",
    "        dropout = hp.Choice(f\"dropout_{i}\", values=[0.0, 0.1, 0.2, 0.3])\n",
    "        l2 = hp.Choice(f\"l2_{i}\", values=[0.0, 1e-6, 1e-5, 1e-4])\n",
    "        x = keras.layers.Dense(units, activation=\"gelu\", kernel_regularizer=keras.regularizers.l2(l2))(x)\n",
    "        if dropout > 0:\n",
    "            x = keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(1, name=\"log_monto\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    lr = hp.Choice(\"lr\", values=[1e-3, 5e-4, 3e-4, 1e-4])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr, clipnorm=1.0), loss=\"mse\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a180bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf(seed=42):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    np.random.seed(seed); random.seed(seed); tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8246285",
   "metadata": {},
   "source": [
    "### Primer modelo MLP --> Control: Sin VCR ni coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b28a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25211.000000\n",
       "mean         8.395828\n",
       "std          0.830310\n",
       "min          5.950643\n",
       "25%          7.740664\n",
       "50%          8.242756\n",
       "75%          8.984694\n",
       "max         10.915088\n",
       "Name: log_monto, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración básica del dataset\n",
    "df_vcr_c = pd.read_csv('dataset_vcr_compact.csv')\n",
    "df_vcr_c = df_vcr_c[df_vcr_c['monto'] < 56000].copy()\n",
    "df_vcr_c['log_monto']=np.log(df_vcr_c['monto'])\n",
    "df_vcr_c['log_monto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855cb367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   monto                 25211 non-null  int64  \n",
      " 1   superficie_t          25211 non-null  float64\n",
      " 2   dormitorios           25211 non-null  int64  \n",
      " 3   dormitorios_faltante  25211 non-null  int64  \n",
      " 4   banos                 25211 non-null  int64  \n",
      " 5   banos_faltante        25211 non-null  int64  \n",
      " 6   antiguedad            25211 non-null  int64  \n",
      " 7   antiguedad_faltante   25211 non-null  int64  \n",
      " 8   Or_N                  25211 non-null  int64  \n",
      " 9   Or_S                  25211 non-null  int64  \n",
      " 10  Or_E                  25211 non-null  int64  \n",
      " 11  Or_O                  25211 non-null  int64  \n",
      " 12  Or_Faltante           25211 non-null  int64  \n",
      " 13  terraza               25211 non-null  float64\n",
      " 14  estacionamiento       25211 non-null  int64  \n",
      " 15  bodegas               25211 non-null  int64  \n",
      " 16  flag_Departamento     25211 non-null  int64  \n",
      " 17  flag_Multinivel       25211 non-null  int64  \n",
      " 18  flag_Semipiso         25211 non-null  int64  \n",
      " 19  flag_Premium          25211 non-null  int64  \n",
      " 20  flag_Monoambiente     25211 non-null  int64  \n",
      " 21  flag_Loft             25211 non-null  int64  \n",
      " 22  log_monto             25211 non-null  float64\n",
      "dtypes: float64(3), int64(20)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "#Configuración específica del modelo\n",
    "df_base =df_vcr_c.copy()\n",
    "obj_cols = df_base.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols) + [\"id\", \"latitud\", \"longitud\"]\n",
    "df_base = df_base.drop(columns=cols_to_drop)\n",
    "df_base.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "612fab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 21\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_base.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_base[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train) #(x - mean)/std. --> mean = 0, std = 1\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3356cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"mlp_v1\"\n",
    "reset_tf(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02e6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0183s vs `on_train_batch_end` time: 0.0184s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0256s vs `on_train_batch_end` time: 0.0330s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.0284s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0273s vs `on_train_batch_end` time: 0.0274s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0151s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0362s vs `on_train_batch_end` time: 0.0634s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0125s vs `on_train_batch_end` time: 0.0173s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0122s vs `on_train_batch_end` time: 0.0220s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0417s vs `on_train_batch_end` time: 0.0718s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0247s vs `on_train_batch_end` time: 0.0288s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0585s vs `on_train_batch_end` time: 0.0725s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0313s vs `on_train_batch_end` time: 0.0701s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0396s vs `on_train_batch_end` time: 0.0701s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0187s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0432s vs `on_train_batch_end` time: 0.0582s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_end` time: 0.0602s). Check your callbacks.\n",
      "Tuning terminado en 2098.28 s | trials: 1\n"
     ]
    }
   ],
   "source": [
    "# ====== Tuning ======\n",
    "callbacks_tuner = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "]\n",
    "DATASET_TAG = \"ds1\"  \n",
    "RUN_TAG = f\"{PROJECT_NAME}_{DATASET_TAG}_{int(time.time())}\"\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "    max_epochs=MAX_EPOCHS_TUNER,\n",
    "    factor=3,\n",
    "    seed=SEED,\n",
    "    directory=\"kt_logs\", \n",
    "    project_name=PROJECT_NAME,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=MAX_EPOCHS_TUNER,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_tuner,\n",
    "    verbose=0,\n",
    ")\n",
    "tuning_time = time.perf_counter() - start\n",
    "print(f\"Tuning terminado en {tuning_time:.2f} s | trials: {len(tuner.get_best_hyperparameters())}\")\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6ad5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 18ms/step - loss: 40.4771 - val_loss: 10.3470 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3.2558 - val_loss: 0.3750 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3506 - val_loss: 0.1560 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2066 - val_loss: 0.1229 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1780 - val_loss: 0.1096 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1666 - val_loss: 0.1128 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1561 - val_loss: 0.0993 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1485 - val_loss: 0.0931 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1417 - val_loss: 0.0900 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1380 - val_loss: 0.0875 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1357 - val_loss: 0.0883 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1328 - val_loss: 0.0868 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1292 - val_loss: 0.0848 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1268 - val_loss: 0.0858 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1249 - val_loss: 0.0821 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1242 - val_loss: 0.0792 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1192 - val_loss: 0.0789 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1171 - val_loss: 0.0818 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1180 - val_loss: 0.0781 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1151 - val_loss: 0.0772 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1141 - val_loss: 0.0790 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1147 - val_loss: 0.0757 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1129 - val_loss: 0.0754 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1107 - val_loss: 0.0752 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1097 - val_loss: 0.0741 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1086 - val_loss: 0.0744 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1094 - val_loss: 0.0749 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1084 - val_loss: 0.0733 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1077 - val_loss: 0.0745 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1077 - val_loss: 0.0737 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1071 - val_loss: 0.0727 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1056 - val_loss: 0.0739 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1062 - val_loss: 0.0737 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1061 - val_loss: 0.0770 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1040 - val_loss: 0.0765 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1040 - val_loss: 0.0720 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1027 - val_loss: 0.0731 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1039 - val_loss: 0.0711 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1022 - val_loss: 0.0778 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1018 - val_loss: 0.0728 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1032 - val_loss: 0.0706 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1034 - val_loss: 0.0735 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1023 - val_loss: 0.0705 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1018 - val_loss: 0.0719 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0999 - val_loss: 0.0710 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1015 - val_loss: 0.0727 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1034 - val_loss: 0.0721 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1009 - val_loss: 0.0714 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0994 - val_loss: 0.0700 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0971 - val_loss: 0.0689 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0998 - val_loss: 0.0693 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0988 - val_loss: 0.0740 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0979 - val_loss: 0.0703 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0970 - val_loss: 0.0695 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0972 - val_loss: 0.0711 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0955 - val_loss: 0.0694 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0972 - val_loss: 0.0708 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.0706 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0967 - val_loss: 0.0696 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0957 - val_loss: 0.0686 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0959 - val_loss: 0.0685 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0954 - val_loss: 0.0683 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0953 - val_loss: 0.0702 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0961 - val_loss: 0.0698 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0961 - val_loss: 0.0705 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0970 - val_loss: 0.0689 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0951 - val_loss: 0.0679 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0953 - val_loss: 0.0708 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0950 - val_loss: 0.0687 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0946 - val_loss: 0.0746 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0958 - val_loss: 0.0697 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0958 - val_loss: 0.0691 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0934 - val_loss: 0.0670 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0946 - val_loss: 0.0672 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0935 - val_loss: 0.0690 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0684 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0683 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0676 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0676 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0957 - val_loss: 0.0674 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0926 - val_loss: 0.0679 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0926 - val_loss: 0.0675 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0930 - val_loss: 0.0680 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0921 - val_loss: 0.0702 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0938 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0934 - val_loss: 0.0706 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0913 - val_loss: 0.0666 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0696 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0925 - val_loss: 0.0673 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0970 - val_loss: 0.0687 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0947 - val_loss: 0.0709 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0927 - val_loss: 0.0670 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0906 - val_loss: 0.0669 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0926 - val_loss: 0.0666 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0913 - val_loss: 0.0682 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0922 - val_loss: 0.0671 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0915 - val_loss: 0.0694 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0922 - val_loss: 0.0669 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0917 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0915 - val_loss: 0.0677 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0911 - val_loss: 0.0665 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0906 - val_loss: 0.0797 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0917 - val_loss: 0.0669 - lr: 5.0000e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0901 - val_loss: 0.0667 - lr: 5.0000e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0893 - val_loss: 0.0665 - lr: 5.0000e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0892 - val_loss: 0.0674 - lr: 5.0000e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0890 - val_loss: 0.0672 - lr: 5.0000e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0892 - val_loss: 0.0666 - lr: 5.0000e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0901 - val_loss: 0.0669 - lr: 5.0000e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0917 - val_loss: 0.0685 - lr: 5.0000e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0908 - val_loss: 0.0665 - lr: 5.0000e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0908 - val_loss: 0.0660 - lr: 5.0000e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0901 - val_loss: 0.0674 - lr: 5.0000e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0888 - val_loss: 0.0707 - lr: 5.0000e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0898 - val_loss: 0.0658 - lr: 5.0000e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.0661 - lr: 5.0000e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0906 - val_loss: 0.0687 - lr: 5.0000e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0899 - val_loss: 0.0673 - lr: 5.0000e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0888 - val_loss: 0.0676 - lr: 5.0000e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0897 - val_loss: 0.0671 - lr: 5.0000e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0903 - val_loss: 0.0665 - lr: 5.0000e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0893 - val_loss: 0.0678 - lr: 5.0000e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0894 - val_loss: 0.0664 - lr: 5.0000e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0907 - val_loss: 0.0673 - lr: 5.0000e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0898 - val_loss: 0.0676 - lr: 5.0000e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0894 - val_loss: 0.0671 - lr: 5.0000e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0883 - val_loss: 0.0658 - lr: 5.0000e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0895 - val_loss: 0.0658 - lr: 5.0000e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0883 - val_loss: 0.0663 - lr: 5.0000e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0881 - val_loss: 0.0656 - lr: 5.0000e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0893 - val_loss: 0.0662 - lr: 5.0000e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0882 - val_loss: 0.0666 - lr: 5.0000e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0883 - val_loss: 0.0664 - lr: 5.0000e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0885 - val_loss: 0.0663 - lr: 5.0000e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0883 - val_loss: 0.0684 - lr: 5.0000e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0890 - val_loss: 0.0663 - lr: 5.0000e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0885 - val_loss: 0.0674 - lr: 5.0000e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0886 - val_loss: 0.0658 - lr: 5.0000e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0880 - val_loss: 0.0658 - lr: 5.0000e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0898 - val_loss: 0.0687 - lr: 5.0000e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0878 - val_loss: 0.0666 - lr: 5.0000e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0887 - val_loss: 0.0674 - lr: 5.0000e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0894 - val_loss: 0.0665 - lr: 5.0000e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0888 - val_loss: 0.0682 - lr: 5.0000e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0874 - val_loss: 0.0659 - lr: 5.0000e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0884 - val_loss: 0.0672 - lr: 2.5000e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0879 - val_loss: 0.0654 - lr: 2.5000e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0873 - val_loss: 0.0655 - lr: 2.5000e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0888 - val_loss: 0.0665 - lr: 2.5000e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0876 - val_loss: 0.0660 - lr: 2.5000e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0866 - val_loss: 0.0654 - lr: 2.5000e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0877 - val_loss: 0.0673 - lr: 2.5000e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0871 - val_loss: 0.0662 - lr: 2.5000e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0875 - val_loss: 0.0679 - lr: 2.5000e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0875 - val_loss: 0.0657 - lr: 2.5000e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0880 - val_loss: 0.0663 - lr: 2.5000e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0876 - val_loss: 0.0654 - lr: 2.5000e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0873 - val_loss: 0.0659 - lr: 2.5000e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0873 - val_loss: 0.0680 - lr: 2.5000e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0879 - val_loss: 0.0671 - lr: 2.5000e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0883 - val_loss: 0.0658 - lr: 2.5000e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0872 - val_loss: 0.0666 - lr: 2.5000e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0867 - val_loss: 0.0667 - lr: 1.2500e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0879 - val_loss: 0.0657 - lr: 1.2500e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0875 - val_loss: 0.0656 - lr: 1.2500e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0869 - val_loss: 0.0656 - lr: 1.2500e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0878 - val_loss: 0.0654 - lr: 1.2500e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0880 - val_loss: 0.0655 - lr: 1.2500e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0870 - val_loss: 0.0655 - lr: 1.2500e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0881 - val_loss: 0.0652 - lr: 1.2500e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0870 - val_loss: 0.0669 - lr: 1.2500e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0873 - val_loss: 0.0651 - lr: 1.2500e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0860 - val_loss: 0.0655 - lr: 1.2500e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0654 - lr: 1.2500e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0873 - val_loss: 0.0658 - lr: 1.2500e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0868 - val_loss: 0.0651 - lr: 1.2500e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0870 - val_loss: 0.0659 - lr: 1.2500e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0889 - val_loss: 0.0658 - lr: 1.2500e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0871 - val_loss: 0.0664 - lr: 1.2500e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0869 - val_loss: 0.0662 - lr: 1.2500e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0858 - val_loss: 0.0652 - lr: 1.2500e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0874 - val_loss: 0.0664 - lr: 1.2500e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0874 - val_loss: 0.0651 - lr: 1.2500e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0871 - val_loss: 0.0657 - lr: 1.2500e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0671 - lr: 1.2500e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0865 - val_loss: 0.0665 - lr: 1.2500e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0872 - val_loss: 0.0658 - lr: 1.2500e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0867 - val_loss: 0.0658 - lr: 6.2500e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0864 - val_loss: 0.0653 - lr: 6.2500e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0863 - val_loss: 0.0663 - lr: 6.2500e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0860 - val_loss: 0.0659 - lr: 6.2500e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0873 - val_loss: 0.0659 - lr: 6.2500e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0870 - val_loss: 0.0655 - lr: 6.2500e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0858 - val_loss: 0.0655 - lr: 6.2500e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0859 - val_loss: 0.0653 - lr: 6.2500e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0657 - lr: 6.2500e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0875 - val_loss: 0.0654 - lr: 6.2500e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0855 - val_loss: 0.0656 - lr: 6.2500e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0655 - lr: 6.2500e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0660 - lr: 6.2500e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0857 - val_loss: 0.0655 - lr: 6.2500e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0662 - lr: 6.2500e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0873 - val_loss: 0.0657 - lr: 3.1250e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0865 - val_loss: 0.0663 - lr: 3.1250e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0870 - val_loss: 0.0656 - lr: 3.1250e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0868 - val_loss: 0.0657 - lr: 3.1250e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0862 - val_loss: 0.0654 - lr: 3.1250e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0858 - val_loss: 0.0661 - lr: 3.1250e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0862 - val_loss: 0.0655 - lr: 3.1250e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0868 - val_loss: 0.0658 - lr: 3.1250e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0857 - val_loss: 0.0656 - lr: 3.1250e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0870 - val_loss: 0.0655 - lr: 3.1250e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0868 - val_loss: 0.0656 - lr: 3.1250e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0857 - val_loss: 0.0658 - lr: 3.1250e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0869 - val_loss: 0.0657 - lr: 3.1250e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0860 - val_loss: 0.0659 - lr: 3.1250e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0860 - val_loss: 0.0657 - lr: 3.1250e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0858 - val_loss: 0.0659 - lr: 1.5625e-05\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0855 - val_loss: 0.0656 - lr: 1.5625e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0853 - val_loss: 0.0659 - lr: 1.5625e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0865 - val_loss: 0.0659 - lr: 1.5625e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0865 - val_loss: 0.0654 - lr: 1.5625e-05\n",
      "\n",
      "=== MLP (Base) ===\n",
      ">> LOG space\n",
      "Train: R^2=0.9073 | RMSE=0.2515 | MAE=0.1886\n",
      "Val  : R^2=0.9072 | RMSE=0.2552 | MAE=0.1932\n",
      "Test : R^2=0.9046 | RMSE=0.2588 | MAE=0.1951\n",
      ">> UF space (precio)\n",
      "Train: RMSE=1,946.36 | MAE=1,085.75 | MAPE=19.61%\n",
      "Val  : RMSE=2,167.17 | MAE=1,174.19 | MAPE=20.17%\n",
      "Test : RMSE=2,103.72 | MAE=1,150.57 | MAPE=20.39%\n"
     ]
    }
   ],
   "source": [
    "# ====== Entrenamiento final con mejor HP ======\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "        \"models/best_model_mlp_v1.keras\",\n",
    "        monitor=\"val_loss\", save_best_only=True\n",
    "        )\n",
    "callbacks_train = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "    ckpt_cb,\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS_FINAL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_train,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ====== Métricas ======\n",
    "def eval_all_splits(model, Xtr, ytr, Xva, yva, Xte, yte):\n",
    "    def _pred(X):\n",
    "        return np.asarray(model.predict(X, verbose=0)).reshape(-1)\n",
    "\n",
    "    ytr_pred_log = _pred(Xtr)\n",
    "    yva_pred_log = _pred(Xva)\n",
    "    yte_pred_log = _pred(Xte)\n",
    "\n",
    "    # LOG\n",
    "    r2_tr = r2_score(ytr, ytr_pred_log)\n",
    "    r2_va = r2_score(yva, yva_pred_log)\n",
    "    r2_te = r2_score(yte, yte_pred_log)\n",
    "\n",
    "    rmse_log_tr = float(np.sqrt(np.mean((ytr - ytr_pred_log) ** 2)))\n",
    "    rmse_log_va = float(np.sqrt(np.mean((yva - yva_pred_log) ** 2)))\n",
    "    rmse_log_te = float(np.sqrt(np.mean((yte - yte_pred_log) ** 2)))\n",
    "\n",
    "    mae_log_tr = mean_absolute_error(ytr, ytr_pred_log)\n",
    "    mae_log_va = mean_absolute_error(yva, yva_pred_log)\n",
    "    mae_log_te = mean_absolute_error(yte, yte_pred_log)\n",
    "\n",
    "    # UF\n",
    "    ytr_price = np.exp(ytr)\n",
    "    yva_price = np.exp(yva)\n",
    "    yte_price = np.exp(yte)\n",
    "\n",
    "    ytr_pred_price = np.exp(ytr_pred_log)\n",
    "    yva_pred_price = np.exp(yva_pred_log)\n",
    "    yte_pred_price = np.exp(yte_pred_log)\n",
    "\n",
    "    rmse_tr = root_mean_squared_error(ytr_price, ytr_pred_price)\n",
    "    rmse_va = root_mean_squared_error(yva_price, yva_pred_price)\n",
    "    rmse_te = root_mean_squared_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mae_tr  = mean_absolute_error(ytr_price, ytr_pred_price)\n",
    "    mae_va  = mean_absolute_error(yva_price, yva_pred_price)\n",
    "    mae_te  = mean_absolute_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mape_tr = float(np.mean(np.abs((ytr_price - ytr_pred_price) / np.clip(ytr_price, 1e-9, None))) * 100)\n",
    "    mape_va = float(np.mean(np.abs((yva_price - yva_pred_price) / np.clip(yva_price, 1e-9, None))) * 100)\n",
    "    mape_te = float(np.mean(np.abs((yte_price - yte_pred_price) / np.clip(yte_price, 1e-9, None))) * 100)\n",
    "\n",
    "    return {\n",
    "        \"log\": {\n",
    "            \"r2\": (r2_tr, r2_va, r2_te),\n",
    "            \"rmse\": (rmse_log_tr, rmse_log_va, rmse_log_te),\n",
    "            \"mae\": (mae_log_tr, mae_log_va, mae_log_te),\n",
    "        },\n",
    "        \"uf\": {\n",
    "            \"rmse\": (rmse_tr, rmse_va, rmse_te),\n",
    "            \"mae\": (mae_tr, mae_va, mae_te),\n",
    "            \"mape\": (mape_tr, mape_va, mape_te),\n",
    "        },\n",
    "    }\n",
    "\n",
    "metrics = eval_all_splits(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(\"\\n=== MLP (Base) ===\")\n",
    "print(\">> LOG space\")\n",
    "print(f\"Train: R^2={metrics['log']['r2'][0]:.4f} | RMSE={metrics['log']['rmse'][0]:.4f} | MAE={metrics['log']['mae'][0]:.4f}\")\n",
    "print(f\"Val  : R^2={metrics['log']['r2'][1]:.4f} | RMSE={metrics['log']['rmse'][1]:.4f} | MAE={metrics['log']['mae'][1]:.4f}\")\n",
    "print(f\"Test : R^2={metrics['log']['r2'][2]:.4f} | RMSE={metrics['log']['rmse'][2]:.4f} | MAE={metrics['log']['mae'][2]:.4f}\")\n",
    "\n",
    "print(\">> UF space (precio)\")\n",
    "print(f\"Train: RMSE={metrics['uf']['rmse'][0]:,.2f} | MAE={metrics['uf']['mae'][0]:,.2f} | MAPE={metrics['uf']['mape'][0]:.2f}%\")\n",
    "print(f\"Val  : RMSE={metrics['uf']['rmse'][1]:,.2f} | MAE={metrics['uf']['mae'][1]:,.2f} | MAPE={metrics['uf']['mape'][1]:.2f}%\")\n",
    "print(f\"Test : RMSE={metrics['uf']['rmse'][2]:,.2f} | MAE={metrics['uf']['mae'][2]:,.2f} | MAPE={metrics['uf']['mape'][2]:.2f}%\")\n",
    "\n",
    "# ====== Historial para gráficos ======\n",
    "history_mlp = {\n",
    "    \"loss\": history.history.get(\"loss\", []),\n",
    "    \"val_loss\": history.history.get(\"val_loss\", []),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3952084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: models/best_hp_mlp_v1.json\n",
      "Guardado: models/best_model_mlp_v1.keras\n",
      "Guardado: models/scaler_mlp_v1.joblib\n",
      "Guardado: models/feature_names_mlp_v1.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "with open(\"models/best_hp_mlp_v1.json\", \"w\") as f:\n",
    "    json.dump(best_hp.values, f, indent=2)\n",
    "print(\"Guardado: models/best_hp_mlp_v1.json\")\n",
    "\n",
    "model.save(\"models/best_model_mlp_v1.keras\")\n",
    "print(\"Guardado: models/best_model_mlp_v1.keras\")\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler_mlp_v1.joblib\")\n",
    "print(\"Guardado: models/scaler_mlp_v1.joblib\")\n",
    "\n",
    "feature_names = list(X_df.columns)\n",
    "with open(\"models/feature_names_mlp_v1.json\",\"w\") as f:\n",
    "    json.dump(feature_names, f, indent=2)\n",
    "print(\"Guardado: models/feature_names_mlp_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_mlp[\"loss\"], label=\"Train loss (MSE log)\")\n",
    "plt.plot(history_mlp[\"val_loss\"], label=\"Val loss (MSE log)\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP: curva de entrenamiento\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45417728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional y recomendable entre datasets)\n",
    "del tuner  # libera memoria de trials\n",
    "gc.collect()\n",
    "del model\n",
    "reset_tf(SEED) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585a172",
   "metadata": {},
   "source": [
    "### Segundo modelo MLP --> Con coordenadas, sin VCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b26d0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   monto                 25211 non-null  int64  \n",
      " 1   superficie_t          25211 non-null  float64\n",
      " 2   dormitorios           25211 non-null  int64  \n",
      " 3   dormitorios_faltante  25211 non-null  int64  \n",
      " 4   banos                 25211 non-null  int64  \n",
      " 5   banos_faltante        25211 non-null  int64  \n",
      " 6   antiguedad            25211 non-null  int64  \n",
      " 7   antiguedad_faltante   25211 non-null  int64  \n",
      " 8   Or_N                  25211 non-null  int64  \n",
      " 9   Or_S                  25211 non-null  int64  \n",
      " 10  Or_E                  25211 non-null  int64  \n",
      " 11  Or_O                  25211 non-null  int64  \n",
      " 12  Or_Faltante           25211 non-null  int64  \n",
      " 13  terraza               25211 non-null  float64\n",
      " 14  estacionamiento       25211 non-null  int64  \n",
      " 15  bodegas               25211 non-null  int64  \n",
      " 16  flag_Departamento     25211 non-null  int64  \n",
      " 17  flag_Multinivel       25211 non-null  int64  \n",
      " 18  flag_Semipiso         25211 non-null  int64  \n",
      " 19  flag_Premium          25211 non-null  int64  \n",
      " 20  flag_Monoambiente     25211 non-null  int64  \n",
      " 21  flag_Loft             25211 non-null  int64  \n",
      " 22  latitud               25211 non-null  float64\n",
      " 23  longitud              25211 non-null  float64\n",
      " 24  log_monto             25211 non-null  float64\n",
      "dtypes: float64(5), int64(20)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Configuración específica del modelo\n",
    "df_coord =df_vcr_c.copy()\n",
    "obj_cols = df_coord.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols)\n",
    "cols_to_drop.append(\"id\")\n",
    "df_coord = df_coord.drop(columns=cols_to_drop)\n",
    "df_coord.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5827904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 23\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_coord.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_coord[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da68af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"mlp_v2\"\n",
    "reset_tf(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dbef45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
      "Tuning terminado en 1843.11 s | trials: 1\n"
     ]
    }
   ],
   "source": [
    "# ====== Tuning ======\n",
    "callbacks_tuner = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "]\n",
    "DATASET_TAG = \"ds2\"  \n",
    "RUN_TAG = f\"{PROJECT_NAME}_{DATASET_TAG}_{int(time.time())}\"\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "    max_epochs=MAX_EPOCHS_TUNER,\n",
    "    factor=3,\n",
    "    seed=SEED,\n",
    "    directory=\"kt_logs\", \n",
    "    project_name=PROJECT_NAME,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=MAX_EPOCHS_TUNER,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_tuner,\n",
    "    verbose=0,\n",
    ")\n",
    "tuning_time = time.perf_counter() - start\n",
    "print(f\"Tuning terminado en {tuning_time:.2f} s | trials: {len(tuner.get_best_hyperparameters())}\")\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd29b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 23ms/step - loss: 46.3546 - val_loss: 11.1586 - lr: 3.0000e-04\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 2.9167 - val_loss: 0.1709 - lr: 3.0000e-04\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2064 - val_loss: 0.0820 - lr: 3.0000e-04\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.1625 - val_loss: 0.0718 - lr: 3.0000e-04\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1475 - val_loss: 0.0669 - lr: 3.0000e-04\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1377 - val_loss: 0.0626 - lr: 3.0000e-04\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1289 - val_loss: 0.0617 - lr: 3.0000e-04\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1256 - val_loss: 0.0619 - lr: 3.0000e-04\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.1217 - val_loss: 0.0616 - lr: 3.0000e-04\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1176 - val_loss: 0.0567 - lr: 3.0000e-04\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1129 - val_loss: 0.0548 - lr: 3.0000e-04\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1070 - val_loss: 0.0558 - lr: 3.0000e-04\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1051 - val_loss: 0.0541 - lr: 3.0000e-04\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1031 - val_loss: 0.0540 - lr: 3.0000e-04\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0985 - val_loss: 0.0524 - lr: 3.0000e-04\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0975 - val_loss: 0.0512 - lr: 3.0000e-04\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0966 - val_loss: 0.0513 - lr: 3.0000e-04\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0948 - val_loss: 0.0512 - lr: 3.0000e-04\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0919 - val_loss: 0.0527 - lr: 3.0000e-04\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0909 - val_loss: 0.0505 - lr: 3.0000e-04\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0892 - val_loss: 0.0496 - lr: 3.0000e-04\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0880 - val_loss: 0.0490 - lr: 3.0000e-04\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0867 - val_loss: 0.0485 - lr: 3.0000e-04\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0878 - val_loss: 0.0512 - lr: 3.0000e-04\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0846 - val_loss: 0.0481 - lr: 3.0000e-04\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0849 - val_loss: 0.0483 - lr: 3.0000e-04\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0833 - val_loss: 0.0505 - lr: 3.0000e-04\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0828 - val_loss: 0.0474 - lr: 3.0000e-04\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0815 - val_loss: 0.0488 - lr: 3.0000e-04\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0791 - val_loss: 0.0480 - lr: 3.0000e-04\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0810 - val_loss: 0.0476 - lr: 3.0000e-04\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0781 - val_loss: 0.0469 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0773 - val_loss: 0.0471 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0773 - val_loss: 0.0457 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0786 - val_loss: 0.0461 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0771 - val_loss: 0.0469 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0758 - val_loss: 0.0481 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0758 - val_loss: 0.0458 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0758 - val_loss: 0.0456 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0734 - val_loss: 0.0454 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0738 - val_loss: 0.0450 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0751 - val_loss: 0.0455 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0745 - val_loss: 0.0444 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0739 - val_loss: 0.0486 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0741 - val_loss: 0.0463 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0735 - val_loss: 0.0467 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0735 - val_loss: 0.0454 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0723 - val_loss: 0.0440 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.0698 - val_loss: 0.0440 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0710 - val_loss: 0.0468 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0720 - val_loss: 0.0435 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0692 - val_loss: 0.0487 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0723 - val_loss: 0.0439 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0690 - val_loss: 0.0434 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0694 - val_loss: 0.0431 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0433 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0708 - val_loss: 0.0501 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0701 - val_loss: 0.0437 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0690 - val_loss: 0.0435 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0690 - val_loss: 0.0427 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0674 - val_loss: 0.0429 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0689 - val_loss: 0.0425 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0677 - val_loss: 0.0424 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0679 - val_loss: 0.0422 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0673 - val_loss: 0.0422 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0684 - val_loss: 0.0452 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.0428 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0670 - val_loss: 0.0421 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0665 - val_loss: 0.0427 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0666 - val_loss: 0.0425 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0657 - val_loss: 0.0424 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0662 - val_loss: 0.0424 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0669 - val_loss: 0.0450 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0671 - val_loss: 0.0418 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0658 - val_loss: 0.0412 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0651 - val_loss: 0.0420 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0666 - val_loss: 0.0420 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0641 - val_loss: 0.0409 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0652 - val_loss: 0.0441 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0656 - val_loss: 0.0422 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0649 - val_loss: 0.0423 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0643 - val_loss: 0.0410 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0644 - val_loss: 0.0408 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0650 - val_loss: 0.0413 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0637 - val_loss: 0.0420 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0634 - val_loss: 0.0409 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0648 - val_loss: 0.0416 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0636 - val_loss: 0.0401 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0403 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0636 - val_loss: 0.0397 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0632 - val_loss: 0.0398 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0636 - val_loss: 0.0397 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - val_loss: 0.0394 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0632 - val_loss: 0.0416 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0621 - val_loss: 0.0396 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.0394 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0625 - val_loss: 0.0415 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0623 - val_loss: 0.0399 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0403 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.0412 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0617 - val_loss: 0.0393 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0618 - val_loss: 0.0390 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0616 - val_loss: 0.0393 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0391 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0627 - val_loss: 0.0411 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0623 - val_loss: 0.0391 - lr: 3.0000e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0607 - val_loss: 0.0390 - lr: 3.0000e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0616 - val_loss: 0.0393 - lr: 3.0000e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0623 - val_loss: 0.0402 - lr: 3.0000e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0612 - val_loss: 0.0395 - lr: 3.0000e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0613 - val_loss: 0.0407 - lr: 3.0000e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0621 - val_loss: 0.0410 - lr: 3.0000e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0616 - val_loss: 0.0391 - lr: 3.0000e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0616 - val_loss: 0.0414 - lr: 3.0000e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0615 - val_loss: 0.0385 - lr: 3.0000e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0603 - val_loss: 0.0405 - lr: 3.0000e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0615 - val_loss: 0.0405 - lr: 3.0000e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0623 - val_loss: 0.0388 - lr: 3.0000e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.0383 - lr: 3.0000e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0599 - val_loss: 0.0384 - lr: 3.0000e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0384 - lr: 3.0000e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.0388 - lr: 3.0000e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0601 - val_loss: 0.0397 - lr: 3.0000e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0619 - val_loss: 0.0422 - lr: 3.0000e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0596 - val_loss: 0.0383 - lr: 3.0000e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0589 - val_loss: 0.0384 - lr: 3.0000e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0388 - lr: 3.0000e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0587 - val_loss: 0.0381 - lr: 3.0000e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0587 - val_loss: 0.0395 - lr: 3.0000e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0592 - val_loss: 0.0383 - lr: 3.0000e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0586 - val_loss: 0.0386 - lr: 3.0000e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0596 - val_loss: 0.0396 - lr: 3.0000e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0594 - val_loss: 0.0379 - lr: 3.0000e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.0388 - lr: 3.0000e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0595 - val_loss: 0.0386 - lr: 3.0000e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0598 - val_loss: 0.0379 - lr: 3.0000e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0604 - val_loss: 0.0376 - lr: 3.0000e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0585 - val_loss: 0.0390 - lr: 3.0000e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0592 - val_loss: 0.0400 - lr: 3.0000e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.0394 - lr: 3.0000e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0585 - val_loss: 0.0393 - lr: 3.0000e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0589 - val_loss: 0.0379 - lr: 3.0000e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0424 - lr: 3.0000e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0586 - val_loss: 0.0378 - lr: 3.0000e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.0376 - lr: 3.0000e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0587 - val_loss: 0.0404 - lr: 3.0000e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0593 - val_loss: 0.0377 - lr: 3.0000e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0573 - val_loss: 0.0375 - lr: 3.0000e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0581 - val_loss: 0.0382 - lr: 3.0000e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0584 - val_loss: 0.0390 - lr: 3.0000e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0582 - val_loss: 0.0387 - lr: 3.0000e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0582 - val_loss: 0.0385 - lr: 3.0000e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0566 - val_loss: 0.0382 - lr: 1.5000e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0571 - val_loss: 0.0373 - lr: 1.5000e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0576 - val_loss: 0.0384 - lr: 1.5000e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0577 - val_loss: 0.0377 - lr: 1.5000e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0564 - val_loss: 0.0373 - lr: 1.5000e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0579 - val_loss: 0.0370 - lr: 1.5000e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0565 - val_loss: 0.0374 - lr: 1.5000e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0573 - val_loss: 0.0383 - lr: 1.5000e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0565 - val_loss: 0.0374 - lr: 1.5000e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0574 - val_loss: 0.0376 - lr: 1.5000e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0575 - val_loss: 0.0374 - lr: 1.5000e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0564 - val_loss: 0.0375 - lr: 1.5000e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0567 - val_loss: 0.0373 - lr: 1.5000e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0567 - val_loss: 0.0372 - lr: 1.5000e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0567 - val_loss: 0.0374 - lr: 1.5000e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0574 - val_loss: 0.0367 - lr: 1.5000e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0566 - val_loss: 0.0369 - lr: 1.5000e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0568 - val_loss: 0.0378 - lr: 1.5000e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.0368 - lr: 1.5000e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0562 - val_loss: 0.0381 - lr: 1.5000e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0570 - val_loss: 0.0368 - lr: 1.5000e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0565 - val_loss: 0.0385 - lr: 1.5000e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0559 - val_loss: 0.0375 - lr: 1.5000e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0559 - val_loss: 0.0377 - lr: 1.5000e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0566 - val_loss: 0.0367 - lr: 1.5000e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0563 - val_loss: 0.0376 - lr: 1.5000e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.0366 - lr: 1.5000e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0565 - val_loss: 0.0371 - lr: 1.5000e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0570 - val_loss: 0.0376 - lr: 1.5000e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0567 - val_loss: 0.0386 - lr: 1.5000e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0368 - lr: 1.5000e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0573 - val_loss: 0.0370 - lr: 1.5000e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.0370 - lr: 1.5000e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0567 - val_loss: 0.0370 - lr: 1.5000e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0562 - val_loss: 0.0368 - lr: 1.5000e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0559 - val_loss: 0.0366 - lr: 1.5000e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.0366 - lr: 1.5000e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0563 - val_loss: 0.0378 - lr: 1.5000e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0557 - val_loss: 0.0368 - lr: 1.5000e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0566 - val_loss: 0.0377 - lr: 1.5000e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.0365 - lr: 1.5000e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0559 - val_loss: 0.0366 - lr: 1.5000e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0551 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0556 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0558 - val_loss: 0.0371 - lr: 7.5000e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0552 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0551 - val_loss: 0.0370 - lr: 7.5000e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0559 - val_loss: 0.0367 - lr: 7.5000e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0552 - val_loss: 0.0364 - lr: 7.5000e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0546 - val_loss: 0.0363 - lr: 7.5000e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0553 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0552 - val_loss: 0.0363 - lr: 7.5000e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0556 - val_loss: 0.0362 - lr: 7.5000e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0556 - val_loss: 0.0364 - lr: 7.5000e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0559 - val_loss: 0.0366 - lr: 7.5000e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0549 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0551 - val_loss: 0.0368 - lr: 7.5000e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0546 - val_loss: 0.0364 - lr: 7.5000e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0559 - val_loss: 0.0365 - lr: 7.5000e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0551 - val_loss: 0.0369 - lr: 7.5000e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0553 - val_loss: 0.0363 - lr: 7.5000e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0562 - val_loss: 0.0364 - lr: 7.5000e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0554 - val_loss: 0.0366 - lr: 7.5000e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0554 - val_loss: 0.0368 - lr: 7.5000e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0550 - val_loss: 0.0376 - lr: 7.5000e-05\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0545 - val_loss: 0.0368 - lr: 7.5000e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0558 - val_loss: 0.0364 - lr: 7.5000e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0554 - val_loss: 0.0364 - lr: 3.7500e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0553 - val_loss: 0.0364 - lr: 3.7500e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0364 - lr: 3.7500e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0549 - val_loss: 0.0365 - lr: 3.7500e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0548 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0550 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0548 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.0365 - lr: 3.7500e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0365 - lr: 3.7500e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.0364 - lr: 3.7500e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0539 - val_loss: 0.0363 - lr: 3.7500e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0545 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0533 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.8750e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.8750e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 1.8750e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0544 - val_loss: 0.0362 - lr: 1.8750e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0542 - val_loss: 0.0364 - lr: 1.8750e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0546 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 1.8750e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0537 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0543 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 0.0364 - lr: 1.8750e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0540 - val_loss: 0.0363 - lr: 1.8750e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0551 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0535 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0544 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0551 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0541 - val_loss: 0.0363 - lr: 9.3750e-06\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0552 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0552 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 9.3750e-06\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0550 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0551 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0534 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0530 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 4.6875e-06\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0551 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0544 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0545 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0362 - lr: 2.3438e-06\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0550 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0534 - val_loss: 0.0362 - lr: 1.1719e-06\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0536 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0550 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0535 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0547 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0541 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0362 - lr: 1.0000e-06\n",
      "\n",
      "=== MLP (Coordenadas) ===\n",
      ">> LOG space\n",
      "Train: R^2=0.9524 | RMSE=0.1801 | MAE=0.1298\n",
      "Val  : R^2=0.9495 | RMSE=0.1882 | MAE=0.1360\n",
      "Test : R^2=0.9521 | RMSE=0.1833 | MAE=0.1366\n",
      ">> UF space (precio)\n",
      "Train: RMSE=1,572.76 | MAE=783.23 | MAPE=13.28%\n",
      "Val  : RMSE=1,754.49 | MAE=855.80 | MAPE=14.06%\n",
      "Test : RMSE=1,651.47 | MAE=829.88 | MAPE=13.97%\n"
     ]
    }
   ],
   "source": [
    "# ====== Entrenamiento final con mejor HP ======\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "        \"models/best_model_mlp_v2.keras\",\n",
    "        monitor=\"val_loss\", save_best_only=True\n",
    "        )\n",
    "callbacks_train = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "    ckpt_cb,\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS_FINAL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_train,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ====== Métricas ======\n",
    "def eval_all_splits(model, Xtr, ytr, Xva, yva, Xte, yte):\n",
    "    def _pred(X):\n",
    "        return np.asarray(model.predict(X, verbose=0)).reshape(-1)\n",
    "\n",
    "    ytr_pred_log = _pred(Xtr)\n",
    "    yva_pred_log = _pred(Xva)\n",
    "    yte_pred_log = _pred(Xte)\n",
    "\n",
    "    # LOG\n",
    "    r2_tr = r2_score(ytr, ytr_pred_log)\n",
    "    r2_va = r2_score(yva, yva_pred_log)\n",
    "    r2_te = r2_score(yte, yte_pred_log)\n",
    "\n",
    "    rmse_log_tr = float(np.sqrt(np.mean((ytr - ytr_pred_log) ** 2)))\n",
    "    rmse_log_va = float(np.sqrt(np.mean((yva - yva_pred_log) ** 2)))\n",
    "    rmse_log_te = float(np.sqrt(np.mean((yte - yte_pred_log) ** 2)))\n",
    "\n",
    "    mae_log_tr = mean_absolute_error(ytr, ytr_pred_log)\n",
    "    mae_log_va = mean_absolute_error(yva, yva_pred_log)\n",
    "    mae_log_te = mean_absolute_error(yte, yte_pred_log)\n",
    "\n",
    "    # UF\n",
    "    ytr_price = np.exp(ytr)\n",
    "    yva_price = np.exp(yva)\n",
    "    yte_price = np.exp(yte)\n",
    "\n",
    "    ytr_pred_price = np.exp(ytr_pred_log)\n",
    "    yva_pred_price = np.exp(yva_pred_log)\n",
    "    yte_pred_price = np.exp(yte_pred_log)\n",
    "\n",
    "    rmse_tr = root_mean_squared_error(ytr_price, ytr_pred_price)\n",
    "    rmse_va = root_mean_squared_error(yva_price, yva_pred_price)\n",
    "    rmse_te = root_mean_squared_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mae_tr  = mean_absolute_error(ytr_price, ytr_pred_price)\n",
    "    mae_va  = mean_absolute_error(yva_price, yva_pred_price)\n",
    "    mae_te  = mean_absolute_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mape_tr = float(np.mean(np.abs((ytr_price - ytr_pred_price) / np.clip(ytr_price, 1e-9, None))) * 100)\n",
    "    mape_va = float(np.mean(np.abs((yva_price - yva_pred_price) / np.clip(yva_price, 1e-9, None))) * 100)\n",
    "    mape_te = float(np.mean(np.abs((yte_price - yte_pred_price) / np.clip(yte_price, 1e-9, None))) * 100)\n",
    "\n",
    "    return {\n",
    "        \"log\": {\n",
    "            \"r2\": (r2_tr, r2_va, r2_te),\n",
    "            \"rmse\": (rmse_log_tr, rmse_log_va, rmse_log_te),\n",
    "            \"mae\": (mae_log_tr, mae_log_va, mae_log_te),\n",
    "        },\n",
    "        \"uf\": {\n",
    "            \"rmse\": (rmse_tr, rmse_va, rmse_te),\n",
    "            \"mae\": (mae_tr, mae_va, mae_te),\n",
    "            \"mape\": (mape_tr, mape_va, mape_te),\n",
    "        },\n",
    "    }\n",
    "\n",
    "metrics = eval_all_splits(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(\"\\n=== MLP (Coordenadas) ===\")\n",
    "print(\">> LOG space\")\n",
    "print(f\"Train: R^2={metrics['log']['r2'][0]:.4f} | RMSE={metrics['log']['rmse'][0]:.4f} | MAE={metrics['log']['mae'][0]:.4f}\")\n",
    "print(f\"Val  : R^2={metrics['log']['r2'][1]:.4f} | RMSE={metrics['log']['rmse'][1]:.4f} | MAE={metrics['log']['mae'][1]:.4f}\")\n",
    "print(f\"Test : R^2={metrics['log']['r2'][2]:.4f} | RMSE={metrics['log']['rmse'][2]:.4f} | MAE={metrics['log']['mae'][2]:.4f}\")\n",
    "\n",
    "print(\">> UF space (precio)\")\n",
    "print(f\"Train: RMSE={metrics['uf']['rmse'][0]:,.2f} | MAE={metrics['uf']['mae'][0]:,.2f} | MAPE={metrics['uf']['mape'][0]:.2f}%\")\n",
    "print(f\"Val  : RMSE={metrics['uf']['rmse'][1]:,.2f} | MAE={metrics['uf']['mae'][1]:,.2f} | MAPE={metrics['uf']['mape'][1]:.2f}%\")\n",
    "print(f\"Test : RMSE={metrics['uf']['rmse'][2]:,.2f} | MAE={metrics['uf']['mae'][2]:,.2f} | MAPE={metrics['uf']['mape'][2]:.2f}%\")\n",
    "\n",
    "# ====== Historial para gráficos ======\n",
    "history_mlp = {\n",
    "    \"loss\": history.history.get(\"loss\", []),\n",
    "    \"val_loss\": history.history.get(\"val_loss\", []),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5098cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: models/best_hp_mlp_v2.json\n",
      "Guardado: models/best_model_mlp_v2.keras\n",
      "Guardado: models/scaler_mlp_v2.joblib\n",
      "Guardado: models/feature_names_mlp_v2.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "with open(\"models/best_hp_mlp_v2.json\", \"w\") as f:\n",
    "    json.dump(best_hp.values, f, indent=2)\n",
    "print(\"Guardado: models/best_hp_mlp_v2.json\")\n",
    "\n",
    "model.save(\"models/best_model_mlp_v2.keras\")\n",
    "print(\"Guardado: models/best_model_mlp_v2.keras\")\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler_mlp_v2.joblib\")\n",
    "print(\"Guardado: models/scaler_mlp_v2.joblib\")\n",
    "\n",
    "feature_names = list(X_df.columns)\n",
    "with open(\"models/feature_names_mlp_v2.json\",\"w\") as f:\n",
    "    json.dump(feature_names, f, indent=2)\n",
    "print(\"Guardado: models/feature_names_mlp_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f829e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAHHCAYAAACskBIUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPtklEQVR4nO3deVwU5R8H8M8sx3JfIiwIKh4p3uZJ9suLQjS8yNu8SDPv1FI7PDOtzKs8OhSzNK/SLK/U1JTwSMUjlbRQ8AA8ArxAYZ/fH7gjK6A4u7Dj+nm/XvuKnZmd+c7D2H545pkZSQghQERERGQFNJYugIiIiMhcGGyIiIjIajDYEBERkdVgsCEiIiKrwWBDREREVoPBhoiIiKwGgw0RERFZDQYbIiIishoMNkRERGQ1GGyIqMRJkoSJEydaugzKg78TshYMNmS1lixZAkmSIEkS9uzZk2++EAKBgYGQJAkvv/yy0TxJkjBkyJCHrr9Zs2by+iVJgpeXFxo0aIDFixdDr9ebdV+oZF28eBETJ05EXFycpUuxKsuXL8fs2bMtXQZZOVtLF0BU3BwcHLB8+XI8//zzRtN37dqF8+fPQ6vVKl53QEAApk2bBgC4fPkyli5diqioKPz999+YPn26SXWT5Vy8eBGTJk1C+fLlUadOHUuXUyJu374NW9vi/UpYvnw5jh8/jhEjRhTrdujpxh4bsnqtW7fG6tWrkZ2dbTR9+fLlqFevHnQ6neJ1u7u7o2fPnujZsyfefPNNxMTEICAgAJ9//jnu3r1raulml52djTt37li6DKtz69YtS5dgMgcHh2IPNkQlgcGGrF63bt1w9epVbN26VZ52584drFmzBt27dzfrtpycnNC4cWPcvHkTly9fBpD7pXfq1ClcuXKlSOvYt28fWrduDU9PTzg7O6NWrVqYM2eOPL9Zs2Zo1qxZvs/16dMH5cuXl9+fPXsWkiRhxowZmD17NipWrAitVovDhw/D1tYWkyZNyreO+Ph4SJKEzz//HABw7do1jB49GjVr1oSLiwvc3NwQHh6OI0eOFGlfsrKy8Oabb6J06dJwdXVF27Ztcf78+QKXvXDhAvr16wdfX19otVpUr14dixcvLtJ2AOC7775DvXr14OjoCC8vL3Tt2hVJSUlGyzRr1gw1atTAiRMn0Lx5czg5OaFMmTL4+OOP5WV27tyJBg0aAAD69u0rn2pcsmSJ0ToOHjyIF154AU5OTnjnnXfk/Z0wYQIqVaoErVaLwMBAvP3228jKyjKqw3Cqc926dahRo4a8v5s3bzZa7ty5cxg0aBCqVKkCR0dHlCpVCp06dcLZs2eNljOcdt2zZw+GDRuG0qVLw8PDA6+//jru3LmDtLQ09OrVC56envD09MTbb78NIUS+mh4cY1OU38nOnTshSRJWrVqFqVOnIiAgAA4ODmjZsiXOnDlj1PYbNmzAuXPn5DbNe7ympqYiKioKvr6+cHBwQO3atfHNN98U8JsmejjGc7J65cuXR0hICL7//nuEh4cDADZt2oT09HR07doVc+fONev2/v33X9jY2MDDwwMAsH//fjRv3hwTJkx45ODMrVu34uWXX4afnx+GDx8OnU6HkydP4pdffsHw4cMV1RMdHY3MzEwMGDAAWq0Wfn5+aNq0KVatWoUJEyYYLbty5UrY2NigU6dO8r6sW7cOnTp1QlBQEFJSUvDFF1+gadOmOHHiBPz9/R+67ddeew3fffcdunfvjueeew6//fYb2rRpk2+5lJQUNG7cWP7CL126NDZt2oSoqChkZGQ88tTF1KlT8f7776Nz58547bXXcPnyZXz22Wd44YUXcPjwYfl3AQD//fcfWrVqhY4dO6Jz585Ys2YNxowZg5o1ayI8PBzBwcGYPHkyxo8fjwEDBuB///sfAOC5556T13H16lWEh4eja9eu6NmzJ3x9faHX69G2bVvs2bMHAwYMQHBwMI4dO4ZZs2bh77//xrp164xq3rNnD3788UcMGjQIrq6umDt3LiIjI5GYmIhSpUoBAA4cOIA//vgDXbt2RUBAAM6ePYsFCxagWbNmOHHiBJycnIzWOXToUOh0OkyaNAl79+7Fl19+CQ8PD/zxxx8oW7YsPvzwQ2zcuBGffPIJatSogV69ehXapo/7O5k+fTo0Gg1Gjx6N9PR0fPzxx+jRowf27dsHAHj33XeRnp6O8+fPY9asWQAAFxcXALmnwZo1a4YzZ85gyJAhCAoKwurVq9GnTx+kpaUpPvbpKSWIrFR0dLQAIA4cOCA+//xz4erqKm7duiWEEKJTp06iefPmQgghypUrJ9q0aWP0WQBi8ODBD11/06ZNRdWqVcXly5fF5cuXxcmTJ8WwYcMEABERESEvt2PHDgFATJgw4aHry87OFkFBQaJcuXLiv//+M5qn1+uNttu0adN8n+/du7coV66c/D4hIUEAEG5ubiI1NdVo2S+++EIAEMeOHTOaXq1aNdGiRQv5fWZmpsjJyTFaJiEhQWi1WjF58uSH7k9cXJwAIAYNGmQ0vXv37vnaIyoqSvj5+YkrV64YLdu1a1fh7u4u/94KcvbsWWFjYyOmTp1qNP3YsWPC1tbWaHrTpk0FALF06VJ5WlZWltDpdCIyMlKeduDAAQFAREdH59ueYR0LFy40mv7tt98KjUYjdu/ebTR94cKFAoCIiYmRpwEQ9vb24syZM/K0I0eOCADis88+k6cVtN+xsbH59sFwrIeFhRkdKyEhIUKSJDFw4EB5WnZ2tggICMh3DCn9nRiO7+DgYJGVlSUvN2fOnHzHWJs2bYyOUYPZs2cLAOK7776Tp925c0eEhIQIFxcXkZGRke8zRIXhqSh6KnTu3Bm3b9/GL7/8guvXr+OXX34xy2moU6dOoXTp0ihdujSCg4Px2WefoU2bNkbd9c2aNYMQ4pG9NYcPH0ZCQgJGjBhh1MMA5J4mUCoyMhKlS5c2mtaxY0fY2tpi5cqV8rTjx4/jxIkT6NKlizxNq9VCo8n930ROTg6uXr0KFxcXVKlSBYcOHXrodjdu3AgAGDZsmNH0B//SF0Lghx9+QEREBIQQuHLlivwKCwtDenr6Q7f1448/Qq/Xo3Pnzkaf1el0qFy5Mnbs2GG0vIuLC3r27Cm/t7e3R8OGDfHvv/8+dH/y0mq16Nu3r9G01atXIzg4GFWrVjWqo0WLFgCQr47Q0FBUrFhRfl+rVi24ubkZ1eHo6Cj/fPfuXVy9ehWVKlWCh4dHgW0SFRVldKw0atQIQghERUXJ02xsbFC/fv2H7q+S30nfvn1hb28vvzf0dBWlXTdu3AidTodu3brJ0+zs7DBs2DDcuHEDu3bteuQ6iAx4KoqeCqVLl0ZoaCiWL1+OW7duIScnB6+88orJ6y1fvjy++uorSJIEBwcHVK5cGT4+PorW9c8//wAAatSoYXJdeQUFBeWb5u3tjZYtW2LVqlWYMmUKgNzTULa2tujYsaO8nF6vx5w5czB//nwkJCQgJydHnmc4XVKYc+fOQaPRGH15A0CVKlWM3l++fBlpaWn48ssv8eWXXxa4rtTU1EK3c/r0aQghULly5QLn29nZGb0PCAjIFxQ9PT1x9OjRQrfxoDJlyhh9iRvqOHnyZL4QafDgPpQtWzbfMp6envjvv//k97dv38a0adMQHR2NCxcuGI2LSU9Pz/f5B9fp7u4OAAgMDMw3Pe92HqTkd/Lgtj09PQHgodsxOHfuHCpXriyHaIPg4GB5PlFRMdjQU6N79+7o378/kpOTER4enq9XRAlnZ2eEhoaaXtxjkCQp38BPAEahI6+8f/Xn1bVrV/Tt2xdxcXGoU6cOVq1ahZYtW8Lb21te5sMPP8T777+Pfv36YcqUKfDy8oJGo8GIESPMdq8ew3p69uyJ3r17F7hMrVq1Hvp5SZKwadMm2NjY5JtvGMdhUNAyAAps08IU1KZ6vR41a9bEzJkzC/zMg+GiKHUMHToU0dHRGDFiBEJCQuDu7g5JktC1a9cC27+wdRY0/WH7q+R3Yo52JTIHBht6anTo0AGvv/469u7da3QKRi0MPRvHjx9/aFjy9PQssHv/cf+qbd++PV5//XW5Lf7++2+MGzfOaJk1a9agefPmWLRokdH0tLQ0owBUkHLlykGv1+Off/4x6qWJj483Ws5wxVROTo6ikFixYkUIIRAUFIRnnnnmsT9fECWn/ipWrIgjR46gZcuWJp06zGvNmjXo3bs3Pv30U3laZmYm0tLSzLL+wpj6OylMYe1Srlw5HD16FHq93qjX5tSpU/J8oqLiGBt6ari4uGDBggWYOHEiIiIiSmy7Rb3c+9lnn0VQUBBmz56d74sr71+9FStWxKlTp+TLyQHgyJEjiImJeay6PDw8EBYWhlWrVmHFihWwt7dH+/btjZaxsbHJ9xf36tWrceHChUeu33AF2oNXnT1451kbGxtERkbihx9+wPHjx/OtJ+9+FqRjx46wsbHBpEmT8tUqhMDVq1cfWeuDnJ2dAeCxAkTnzp1x4cIFfPXVV/nm3b59Gzdv3nzsOgpq/88++6zQ3jlzMfV3UhhnZ+cCT6G1bt0aycnJRn9wZGdn47PPPoOLiwuaNm2qaHv0dGKPDT1VCutWL8iff/6JDz74IN/0Zs2a5buL8cMU9XJvjUaDBQsWICIiAnXq1EHfvn3h5+eHU6dO4a+//sKWLVsAAP369cPMmTMRFhaGqKgopKamYuHChahevToyMjKKXBcAdOnSBT179sT8+fMRFhaW7/Tcyy+/jMmTJ6Nv37547rnncOzYMSxbtgwVKlR45Lrr1KmDbt26Yf78+UhPT8dzzz2H7du3G93bxGD69OnYsWMHGjVqhP79+6NatWq4du0aDh06hG3btuHatWuFbqdixYr44IMPMG7cOJw9exbt27eHq6srEhISsHbtWgwYMACjR49+rHapWLEiPDw8sHDhQri6usLZ2RmNGjUqcLySwauvvopVq1Zh4MCB2LFjB5o0aYKcnBycOnUKq1atwpYtW1C/fv3HquPll1/Gt99+C3d3d1SrVg2xsbHYtm3bI8c3mYMpv5PC1KtXDytXrsTIkSPRoEEDuLi4ICIiAgMGDMAXX3yBPn364ODBgyhfvjzWrFmDmJgYzJ49G66ursWwh2StGGyICrFv3z75Hhx5TZky5bGCzeMICwvDjh07MGnSJHz66afQ6/WoWLEi+vfvLy8THByMpUuXYvz48Rg5ciSqVauGb7/9FsuXL8fOnTsfa3tt27aFo6Mjrl+/bnQ1lME777yDmzdvYvny5Vi5ciWeffZZbNiwAWPHji3S+hcvXozSpUtj2bJlWLduHVq0aIENGzbkG2/i6+uL/fv3Y/Lkyfjxxx8xf/58lCpVCtWrV8dHH330yO2MHTsWzzzzDGbNmiXfeDAwMBAvvfQS2rZtW6Ra87Kzs8M333yDcePGYeDAgcjOzkZ0dPRDg41Go8G6deswa9YsLF26FGvXroWTkxMqVKiA4cOHKzpNNmfOHNjY2GDZsmXIzMxEkyZNsG3bNoSFhT32uh6Xqb+TggwaNAhxcXGIjo7GrFmzUK5cOURERMDR0RE7d+7E2LFj8c033yAjIwNVqlRBdHQ0+vTpY94dI6snCY7sIiIiIivBMTZERERkNRhsiIiIyGow2BAREZHVYLAhIiIiq8FgQ0RERFaDwYaIiIishtXfx0av1+PixYtwdXU1223OiYiIqHgJIXD9+nX4+/vne0Dqw1h9sLl48WK+m4ERERHRkyEpKQkBAQFFXt7qg43hVtxJSUlwc3OzcDVERERUFBkZGQgMDHzsR2pYfbAxnH5yc3NjsCEiInrCPO4wEg4eJiIiIqvBYENERERWg8GGiIiIrIbVj7EhIrIGOTk5uHv3rqXLIDIbOzs72NjYmH29DDZERComhEBycjLS0tIsXQqR2Xl4eECn05n1PnMMNkREKmYINT4+PnBycuKNRskqCCFw69YtpKamAgD8/PzMtm4GGyIilcrJyZFDTalSpSxdDpFZOTo6AgBSU1Ph4+NjttNSHDxMRKRShjE1Tk5OFq6EqHgYjm1zjh9jsCEiUjmefiJrVRzHNoMNERERWQ0GGyIieiKUL18es2fPtvg6TBEfHw+dTofr169brIaCTJw4EXXq1DHrOk+cOIGAgADcvHnTrOt9FAYbIiIyK0mSHvqaOHGiovUeOHAAAwYMMG+xJWzcuHEYOnSo/GDHnTt3QpIkeHp6IjMz02jZAwcOyG2W11dffYXatWvDxcUFHh4eqFu3LqZNmybPnzhxYoHtXrVq1eLfwTyqVauGxo0bY+bMmSW6XV4VpVDarTu4kZUNVwc7uDvaWbocIiLVuHTpkvzzypUrMX78eMTHx8vTXFxc5J+FEMjJyYGt7aO/jkqXLm3eQktYYmIifvnlF3z22Wf55rm6umLt2rXo1q2bPG3RokUoW7YsEhMT5WmLFy/GiBEjMHfuXDRt2hRZWVk4evQojh8/brS+6tWrY9u2bUbTitLG5ta3b1/0798f48aNK7Hts8dGoY82x+P5j3bgmz/OWroUIiJV0el08svd3R2SJMnvT506BVdXV2zatAn16tWDVqvFnj178M8//6Bdu3bw9fWFi4sLGjRokO+L+cHTSJIk4euvv0aHDh3g5OSEypUrY/369Y9Va2JiItq1awcXFxe4ubmhc+fOSElJkecfOXIEzZs3h6urK9zc3FCvXj38+eefAIBz584hIiICnp6ecHZ2RvXq1bFx48ZCt7Vq1SrUrl0bZcqUyTevd+/eWLx4sfz+9u3bWLFiBXr37m203Pr169G5c2dERUWhUqVKqF69Orp164apU6caLWdra2v0e9DpdPD29i5yu+j1ekyePBkBAQHQarWoU6cONm/ebLTMH3/8gTp16sDBwQH169fHunXrIEkS4uLi5GVefPFFXLt2Dbt27Srytk3FYKOQoWdQCMvWQURPFyEEbt3JLvGXMPP/7MaOHYvp06fj5MmTqFWrFm7cuIHWrVtj+/btOHz4MFq1aoWIiAij3oqCTJo0CZ07d8bRo0fRunVr9OjRA9euXStSDXq9Hu3atZO/eLdu3Yp///0XXbp0kZfp0aMHAgICcODAARw8eBBjx46FnV1uL/3gwYORlZWF33//HceOHcNHH31k1Bv1oN27d6N+/foFznv11Vexe/dueX9/+OEHlC9fHs8++6zRcjqdDnv37sW5c+eKtI9KzZkzB59++ilmzJiBo0ePIiwsDG3btsXp06cBABkZGYiIiEDNmjVx6NAhTJkyBWPGjMm3Hnt7e9SpUwe7d+8u1nrz4qkohQxnPAWYbIio5Ny+m4Nq47eU+HZPTA6Dk735vjImT56MF198UX7v5eWF2rVry++nTJmCtWvXYv369RgyZEih6+nTp498+ubDDz/E3LlzsX//frRq1eqRNWzfvh3Hjh1DQkICAgMDAQBLly5F9erVceDAATRo0ACJiYl466235PEplStXlj+fmJiIyMhI1KxZEwBQoUKFh27v3LlzhQYbHx8fhIeHY8mSJRg/fjwWL16Mfv365VtuwoQJ6NixI8qXL49nnnkGISEhaN26NV555RVoNPf7Ko4dO5YvZPXs2RMLFy58ZLsAwIwZMzBmzBh07doVAPDRRx9hx44dmD17NubNm4fly5dDkiR89dVXcHBwQLVq1XDhwgX0798/37r8/f2LPYjlxR4bhdhjQ0Sk3INf8Ddu3MDo0aMRHBwMDw8PuLi44OTJk4/ssalVq5b8s7OzM9zc3OTb9D/KyZMnERgYKIcaIHfAq4eHB06ePAkAGDlyJF577TWEhoZi+vTp+Oeff+Rlhw0bhg8++ABNmjTBhAkTcPTo0Ydu7/bt23BwcCh0fr9+/bBkyRL8+++/iI2NRY8ePfIt4+fnh9jYWBw7dgzDhw9HdnY2evfujVatWkGv18vLValSBXFxcUavyZMnF6ldMjIycPHiRTRp0sRoepMmTeR2iY+PR61atYz2p2HDhgWuz9HREbdu3SrSts2BPTYKSff6bJhriKgkOdrZ4MTkMIts15ycnZ2N3o8ePRpbt27FjBkzUKlSJTg6OuKVV17BnTt3Hroew2khA0mSjL7gTTVx4kR0794dGzZswKZNmzBhwgSsWLECHTp0wGuvvYawsDBs2LABv/76K6ZNm4ZPP/0UQ4cOLXBd3t7e+O+//wrdVnh4OAYMGICoqChEREQ89DEaNWrUQI0aNTBo0CAMHDgQ//vf/7Br1y40b94cQO4poEqVKpm282Zy7do1VKxYscS2xx4bheSr79hlQ0QlSJIkONnblviruO9+HBMTgz59+qBDhw6oWbMmdDodzp49W6zbDA4ORlJSEpKSkuRpJ06cQFpaGqpVqyZPe+aZZ/Dmm2/i119/RceOHREdHS3PCwwMxMCBA/Hjjz9i1KhR+OqrrwrdXt26dXHixIlC59va2qJXr17YuXNngaehCmOo1Vz3i3Fzc4O/vz9iYmKMpsfExMjbqlKlCo4dO4asrCx5/oEDBwpc3/Hjx1G3bl2z1FYUDDYK3R9jQ0REpqpcuTJ+/PFHxMXF4ciRI+jevbtZe14KEhoaipo1a6JHjx44dOgQ9u/fj169eqFp06aoX78+bt++jSFDhmDnzp04d+4cYmJicODAAQQHBwMARowYgS1btiAhIQGHDh3Cjh075HkFCQsLQ2xsLHJycgpdZsqUKbh8+TLCwgrulXvjjTcwZcoUxMTE4Ny5c9i7dy969eqF0qVLIyQkRF4uOzsbycnJRq+8V3s9yltvvYWPPvoIK1euRHx8PMaOHYu4uDgMHz4cAOTfz4ABA3Dy5Els2bIFM2bMAGD8mISzZ8/iwoULCA0NLfK2TcVTUQoZfnHssCEiMt3MmTPRr18/PPfcc/D29saYMWOQkZFRrNuUJAk//fQThg4dihdeeAEajQatWrWS7zNjY2ODq1evolevXkhJSYG3tzc6duyISZMmAch9+vrgwYNx/vx5uLm5oVWrVpg1a1ah2wsPD4etrS22bdtWaHCxt7d/6GXZoaGhWLx4MRYsWICrV6/C29sbISEh2L59u9Gpq7/++gt+fn5Gn9VqtfluAliYYcOGIT09HaNGjUJqaiqqVauG9evXy4On3dzc8PPPP+ONN95AnTp1ULNmTYwfPx7du3c3Gnfz/fff46WXXkK5cuWKtF1zkIS5r+FTmYyMDLi7uyM9PR1ubm5mW+/E9X9hyR9nMbh5RbwVVrJ3cySip0NmZiYSEhIQFBT00EGn9OSYN28e1q9fjy1bSv7KtuK2bNky9O3bF+np6XB0dMSdO3dQuXJlLF++PN9AZIOHHeNKv7/ZY6MQr4oiIqLH9frrryMtLQ3Xr1+XH6vwpFq6dCkqVKiAMmXK4MiRIxgzZgw6d+4MR0dHALmXw7/zzjuFhpriwmCjEK+KIiKix2Vra4t3333X0mWYRXJyMsaPH4/k5GT4+fmhU6dORndArlSpkkWuzGKwUUhzr8dGzy4bIiJ6Cr399tt4++23LV1GPrwqSiGJl0URERGpDoONQvJVURaug4iIiO5jsFHo/v35GG2IiIjUgsFGKV4VRUREpDoMNgrxqigiIiL1YbBRiPexISIiUh8GG4XuXxTFZENEVByaNWuGESNGFDp/4sSJqFOnTonVU5AXXngBy5cvt2gNDzp79iwkSUJcXJxZ19u4cWP88MMPZl1ncWCwUYg9NkREBYuIiECrVq0KnLd7925IkoSjR4+WcFXmt379eqSkpKBr167ytPLly0OSJKxYsSLf8tWrV4ckSViyZIk87ciRI2jbti18fHzg4OCA8uXLo0uXLkhNTQVwP6QU9Nq7d2+x72Ne7733HsaOHVvsDyc1FYONQhKkRy9ERPQUioqKwtatW3H+/Pl886Kjo1G/fn3UqlXLApWZ19y5c9G3b19oNMZfpYGBgYiOjjaatnfvXiQnJ8PZ2VmedvnyZbRs2RJeXl7YsmULTp48iejoaPj7++PmzZtGn9+2bRsuXbpk9KpXr17x7VwBwsPDcf36dWzatKlEt/u4GGwUut9jwy4bIqK8Xn75ZZQuXdqoZwIAbty4gdWrVyMqKgpXr15Ft27dUKZMGTg5OaFmzZr4/vvvTdquXq/H5MmTERAQAK1Wizp16mDz5s3y/Dt37mDIkCHw8/ODg4MDypUrh2nTpgHI/X/5xIkTUbZsWWi1Wvj7+2PYsGGFbuvy5cv47bffEBERkW9ejx49sGvXLiQlJcnTFi9ejB49esDW9v4N/2NiYpCeno6vv/4adevWRVBQEJo3b45Zs2YhKCjIaJ2lSpWCTqczetnZ2RW5bXbt2oWGDRtCq9XCz88PY8eORXZ2tjz/+vXr6NGjB5ydneHn54dZs2blOxVoY2OD1q1bF9gbpSYMNgrxxsNEZBFCAHdulvzrMf6Is7W1Ra9evbBkyRKjP/5Wr16NnJwcdOvWDZmZmahXrx42bNiA48ePY8CAAXj11Vexf/9+xU0zZ84cfPrpp5gxYwaOHj2KsLAwtG3bFqdPnwaQ28Oyfv16rFq1CvHx8Vi2bBnKly8PAPjhhx8wa9YsfPHFFzh9+jTWrVuHmjVrFrqtPXv2wMnJCcHBwfnm+fr6IiwsDN988w0A4NatW1i5ciX69etntJxOp0N2djbWrl1brH8kX7hwAa1bt0aDBg1w5MgRLFiwAIsWLcIHH3wgLzNy5EjExMRg/fr12Lp1K3bv3o1Dhw7lW1fDhg2xe/fuYqvVHPisKIXkOw8z2RBRSbp7C/jQv+S3+85FwN750cvd069fP3zyySfYtWsXmjVrBiD3NFRkZCTc3d3h7u6O0aNHy8sPHToUW7ZswapVq9CwYUNFJc6YMQNjxoyRx7x89NFH2LFjB2bPno158+YhMTERlStXxvPPPw9JklCuXDn5s4mJidDpdAgNDYWdnR3Kli370DrOnTsHX1/ffKeh8u7/qFGj8O6772LNmjWoWLFivoHOjRs3xjvvvIPu3btj4MCBaNiwIVq0aIFevXrB19fXaNnnnnsu37Zu3LhRpHaZP38+AgMD8fnnn0OSJFStWhUXL17EmDFjMH78eNy8eRPffPMNli9fjpYtWwKAfErsQf7+/khKSoJery903y1NnVU9ASQ+BJOIqFBVq1bFc889h8WLFwMAzpw5g927dyMqKgoAkJOTgylTpqBmzZrw8vKCi4sLtmzZgsTEREXby8jIwMWLF9GkSROj6U2aNMHJkycBAH369EFcXByqVKmCYcOG4ddff5WX69SpE27fvo0KFSqgf//+WLt2rdGpmgfdvn0bDg4Ohc5v06YNbty4gd9//x2LFy/O11tjMHXqVCQnJ2PhwoWoXr06Fi5ciKpVq+LYsWNGy61cuRJxcXFGr6I6efIkQkJC5D/Igdx2uXHjBs6fP49///0Xd+/eNQpy7u7uqFKlSr51OTo6Qq/XIysrq8jbL2nssVGIN+gjIouwc8rtPbHEdh9TVFQUhg4dinnz5iE6OhoVK1ZE06ZNAQCffPIJ5syZg9mzZ6NmzZpwdnbGiBEjcOfOHXNXLnv22WeRkJCATZs2Ydu2bejcuTNCQ0OxZs0aBAYGIj4+Htu2bcPWrVsxaNAgucepoLEs3t7e+O+//wrdlq2tLV599VVMmDAB+/btw9q1awtdtlSpUujUqRM6deqEDz/8EHXr1sWMGTPkU1lA7oDkSpUqmdYAZnDt2jU4OzvD0dHR0qUUij02CvFybyKyCEnKPSVU0i/p8a8E7dy5MzQaDZYvX46lS5eiX79+cq9BTEwM2rVrh549e6J27dqoUKEC/v77b8XN4ubmBn9/f8TExBhNj4mJQbVq1YyW69KlC7766iusXLkSP/zwA65duwYgtzciIiICc+fOxc6dOxEbG5uv58Sgbt26SE5Ofmi46devH3bt2oV27drB09OzSPthb2+PihUr5rsqyhTBwcGIjY01GscTExMDV1dXBAQEoEKFCrCzs8OBAwfk+enp6QX+Po4fP466deuarbbiwB4bhe7/E2eyISIqiIuLC7p06YJx48YhIyMDffr0kedVrlwZa9aswR9//AFPT0/MnDkTKSkpRiHkcb311luYMGGCPJ4lOjoacXFxWLZsGQBg5syZ8PPzQ926daHRaLB69WrodDp4eHhgyZIlyMnJQaNGjeDk5ITvvvsOjo6ORuNw8qpbty68vb0RExODl19+ucBlgoODceXKFTg5Fdzb9csvv2DFihXo2rUrnnnmGQgh8PPPP2Pjxo35Lhe/evUqkpOTjaZ5eHg89HSYwaBBgzB79mwMHToUQ4YMQXx8PCZMmICRI0dCo9HA1dUVvXv3xltvvQUvLy/4+PhgwoQJ0Gg0RqevgNz7EL300kuP3KYlMdgoxB4bIqJHi4qKwqJFi9C6dWujwajvvfce/v33X4SFhcHJyQkDBgxA+/btkZ6ernhbw4YNQ3p6OkaNGoXU1FRUq1YN69evR+XKlQEArq6u+Pjjj3H69GnY2NigQYMG2LhxIzQaDTw8PDB9+nSMHDkSOTk5qFmzJn7++WeUKlWqwG3Z2Nigb9++WLZsWaHBBkChnweAatWqwcnJCaNGjUJSUhK0Wi0qV66Mr7/+Gq+++qrRsqGhofk+//333xvdHLAwZcqUwcaNG/HWW2+hdu3a8PLyQlRUFN577z15mZkzZ2LgwIF4+eWX4ebmhrfffhtJSUlGwenChQv4448/8N133z1ym5YkCSu/EUtGRgbc3d2Rnp4ONzc3s6133o4z+GRLPLrUD8RHrzz5N5oiIvXJzMxEQkICgoKCivSXOZWs5ORkVK9eHYcOHSq0Z+dJdfPmTZQpUwaffvqpPOB7zJgx+O+///Dll1+abTsPO8aVfn+zx8ZEfFYUEdHTSafTYdGiRUhMTHzig83hw4dx6tQpNGzYEOnp6Zg8eTIAoF27dvIyPj4+GDlypKVKLDIGG4V4KoqIiNq3b2/pEsxmxowZiI+Ph729PerVq4fdu3fD29tbnj9q1CgLVld0DDYK8XJvIiKyFnXr1sXBgwctXYZZ8HJvhdhjQ0REpD4MNgrdf1YUkw0RFS8rv8aDnmLFcWwz2Cgk8SmYRFTMDHe8vXXrloUrISoehmP7cZ5U/igcY6OQRuIYGyIqXjY2NvDw8EBqaioAwMnJKd8N04ieREII3Lp1C6mpqfDw8ICNjY3Z1s1gYyI+BJOIipNOpwMAOdwQWRMPDw/5GDcXBhuFDH81MdcQUXGSJAl+fn7w8fHB3bt3LV0OkdnY2dmZtafGgMFGIQ6xIaKSZGNjUyxfAkTWhoOHFbp/uTejDRERkVow2CjEHhsiIiL1YbBRSL4ygcmGiIhINVQTbKZPnw5JkjBixAh5WmZmJgYPHoxSpUrBxcUFkZGRSElJsVyRedzPNUw2REREaqGKYHPgwAF88cUXqFWrltH0N998Ez///DNWr16NXbt24eLFi+jYsaOFqjQmn4piriEiIlINiwebGzduoEePHvjqq6/g6ekpT09PT8eiRYswc+ZMtGjRAvXq1UN0dDT++OMP7N2714IV38PLvYmIiFTH4sFm8ODBaNOmDUJDQ42mHzx4EHfv3jWaXrVqVZQtWxaxsbGFri8rKwsZGRlGr+LAZ0URERGpj0XvY7NixQocOnQIBw4cyDcvOTkZ9vb28PDwMJru6+uL5OTkQtc5bdo0TJo0ydyl5sOnexMREamPxXpskpKSMHz4cCxbtgwODg5mW++4ceOQnp4uv5KSksy27rwk8FlRREREamOxYHPw4EGkpqbi2Wefha2tLWxtbbFr1y7MnTsXtra28PX1xZ07d5CWlmb0uZSUlIc+V0Kr1cLNzc3oVRw07LEhIiJSHYudimrZsiWOHTtmNK1v376oWrUqxowZg8DAQNjZ2WH79u2IjIwEAMTHxyMxMREhISGWKNkI7zxMRESkPhYLNq6urqhRo4bRNGdnZ5QqVUqeHhUVhZEjR8LLywtubm4YOnQoQkJC0LhxY0uUbISnooiIiNRH1Q/BnDVrFjQaDSIjI5GVlYWwsDDMnz/f0mXlYo8NERGR6qgq2OzcudPovYODA+bNm4d58+ZZpqCH4LOiiIiI1Mfi97F5Ukm8QR8REZHqMNgoxB4bIiIi9WGwUYhXRREREakPg41ChmBDRERE6sFgo5B8uTc7bIiIiFSDwUYh+VQUR9kQERGpBoONidhjQ0REpB4MNgrxcm8iIiL1YbBRyPAQTD2TDRERkWow2CjEZ0URERGpD4ONQhLv0EdERKQ6DDYK3c81TDZERERqwWCj0P07D1u2DiIiIrqPwUYxjrEhIiJSGwYbhfisKCIiIvVhsFGIY4eJiIjUh8FGId6gj4iISH0YbBRijw0REZH6MNgodP8+Now2REREasFgo9D9p3sTERGRWjDYKMQxNkREROrDYKOQ4UwUH4JJRESkHgw2CrHHhoiISH0YbBTiVVFERETqw2CjEO88TEREpD4MNgpJcp8NERERqQWDjUJ8ujcREZH6MNgodH+MDZMNERGRWjDYKMUeGyIiItVhsFHIMMaGuYaIiEg9GGwU4lVRRERE6sNgoxDvY0NERKQ+DDYKSXwKJhERkeow2CikYa4hIiJSHQYbhQwdNnwIJhERkXow2CjGh2ASERGpDYONQveH2DDZEBERqQWDjULyVVHMNURERKrBYKOQ4aooBhsiIiL1YLBRiM/2JiIiUh8GG4V452EiIiL1YbBRiM+KIiIiUh8GG4UkPt2biIhIdRhsTMTLvYmIiNSDwUYh9tgQERGpD4ONQhxjQ0REpD4MNgpp7rUcr4oiIiJSDwYbhSQ+K4qIiEh1GGwUuv+sKCIiIlILBhuF7j8ritGGiIhILRhsFGKPDRERkfow2CjGMTZERERqw2CjEJ8VRUREpD4MNgrJY2wsWgURERHlxWCjkMRBNkRERKrDYKMQe2yIiIjUh8FGIY6xISIiUh8GG4X4rCgiIiL1YbBRiE/3JiIiUh8GG4UMwUbPZENERKQaDDYKGa6KYqwhIiJSD4sGmwULFqBWrVpwc3ODm5sbQkJCsGnTJnl+ZmYmBg8ejFKlSsHFxQWRkZFISUmxYMX3Ga6KYrIhIiJSD4sGm4CAAEyfPh0HDx7En3/+iRYtWqBdu3b466+/AABvvvkmfv75Z6xevRq7du3CxYsX0bFjR0uWLLt/GxsmGyIiIrWwteTGIyIijN5PnToVCxYswN69exEQEIBFixZh+fLlaNGiBQAgOjoawcHB2Lt3Lxo3bmyJkmUSnxVFRESkOqoZY5OTk4MVK1bg5s2bCAkJwcGDB3H37l2EhobKy1StWhVly5ZFbGysBSvNxRsPExERqY9Fe2wA4NixYwgJCUFmZiZcXFywdu1aVKtWDXFxcbC3t4eHh4fR8r6+vkhOTi50fVlZWcjKypLfZ2RkFEvd8p2H2WVDRESkGhbvsalSpQri4uKwb98+vPHGG+jduzdOnDiheH3Tpk2Du7u7/AoMDDRjtXmwx4aIiEh1LB5s7O3tUalSJdSrVw/Tpk1D7dq1MWfOHOh0Oty5cwdpaWlGy6ekpECn0xW6vnHjxiE9PV1+JSUlFUvdHGNDRESkPhYPNg/S6/XIyspCvXr1YGdnh+3bt8vz4uPjkZiYiJCQkEI/r9Vq5cvHDa/iIEmPXoaIiIhKlkXH2IwbNw7h4eEoW7Ysrl+/juXLl2Pnzp3YsmUL3N3dERUVhZEjR8LLywtubm4YOnQoQkJCLH5FFJDnPjbIHWcjMekQERFZnEWDTWpqKnr16oVLly7B3d0dtWrVwpYtW/Diiy8CAGbNmgWNRoPIyEhkZWUhLCwM8+fPt2TJsrxBRgj24BAREamBJKz8sp6MjAy4u7sjPT3drKel0m7dQZ3JWwEA/3zYGjYaJhsiIiJzUfr9rboxNk8KKc/JKD4Ik4iISB0YbJTK00HDXENERKQODDYK5R1Tw+dFERERqQODjULGV0VZrAwiIiLKg8FGIV7eTUREpD4MNgqxx4aIiEh9GGwU4hgbIiIi9WGwUSjv5d7ssSEiIlIHBhuFjHtsiIiISA0YbMzAym/eTERE9MRgsFGIPTZERETqw2CjEMfYEBERqQ+DjUJGz7xksCEiIlIFBhuF8t6gjw/BJCIiUgcGG4XYYUNERKQ+DDYKGQ0eZo8NERGRKjDYKJT3VBRjDRERkTow2JgBO2yIiIjUgcHGBIZOGz4rioiISB0YbEwgn4xiriEiIlIFBhsTGMbZMNcQERGpA4ONCQw9NhxjQ0REpA4MNibgGBsiIiJ1YbAxgeF5UeyxISIiUgcGG1PIPTZERESkBgw2JjA8CFOvZ7QhIiJSAwYbE0hGT4wiIiIiS2OwMYE8eJgdNkRERKrAYGMC+XJvjrIhIiJSBQYbE8g36GOuISIiUgUGGxPc77EhIiIiNVAUbJKSknD+/Hn5/f79+zFixAh8+eWXZivsiSCPsWG0ISIiUgNFwaZ79+7YsWMHACA5ORkvvvgi9u/fj3fffReTJ082a4Fqxh4bIiIidVEUbI4fP46GDRsCAFatWoUaNWrgjz/+wLJly7BkyRJz1qdqHGNDRESkLoqCzd27d6HVagEA27ZtQ9u2bQEAVatWxaVLl8xXncpJ8m1smGyIiIjUQFGwqV69OhYuXIjdu3dj69ataNWqFQDg4sWLKFWqlFkLVDM+3ZuIiEhdFAWbjz76CF988QWaNWuGbt26oXbt2gCA9evXy6eongbyqSgL10FERES5bJV8qFmzZrhy5QoyMjLg6ekpTx8wYACcnJzMVpzasceGiIhIXRT12Ny+fRtZWVlyqDl37hxmz56N+Ph4+Pj4mLVANTP02OiZbIiIiFRBUbBp164dli5dCgBIS0tDo0aN8Omnn6J9+/ZYsGCBWQtUMz4rioiISF0UBZtDhw7hf//7HwBgzZo18PX1xblz57B06VLMnTvXrAWqGZ8VRUREpC6Kgs2tW7fg6uoKAPj111/RsWNHaDQaNG7cGOfOnTNrgWrGHhsiIiJ1URRsKlWqhHXr1iEpKQlbtmzBSy+9BABITU2Fm5ubWQtUM0nusyEiIiI1UBRsxo8fj9GjR6N8+fJo2LAhQkJCAOT23tStW9esBaoZe2yIiIjURdHl3q+88gqef/55XLp0Sb6HDQC0bNkSHTp0MFtxascxNkREROqiKNgAgE6ng06nk5/yHRAQ8FTdnA/gs6KIiIjURtGpKL1ej8mTJ8Pd3R3lypVDuXLl4OHhgSlTpkCv15u7RtVjriEiIlIHRT027777LhYtWoTp06ejSZMmAIA9e/Zg4sSJyMzMxNSpU81apFrdH2PDaENERKQGioLNN998g6+//lp+qjcA1KpVC2XKlMGgQYOevmBj2TKIiIjoHkWnoq5du4aqVavmm161alVcu3bN5KKeFIbLvdlhQ0REpA6Kgk3t2rXx+eef55v++eefo1atWiYX9aTQyLexYbIhIiJSA0Wnoj7++GO0adMG27Ztk+9hExsbi6SkJGzcuNGsBarZ/YdgWrgQIiIiAqCwx6Zp06b4+++/0aFDB6SlpSEtLQ0dO3bEX3/9hW+//dbcNaqWfB8bBhsiIiJVUHwfG39//3yDhI8cOYJFixbhyy+/NLmwJwKviiIiIlIVRT02lOv+nYeJiIhIDRhsTMA7DxMREakLg40J+KwoIiIidXmsMTYdO3Z86Py0tDRTanniSDwXRUREpCqPFWzc3d0fOb9Xr14mFfQkkW/QZ+E6iIiIKNdjBZvo6OjiquOJdP9ZUZatg4iIiHJxjI0ZcIwNERGROjDYmIBXRREREamLRYPNtGnT0KBBA7i6usLHxwft27dHfHy80TKZmZkYPHgwSpUqBRcXF0RGRiIlJcVCFRvj2GEiIiJ1sWiw2bVrFwYPHoy9e/di69atuHv3Ll566SXcvHlTXubNN9/Ezz//jNWrV2PXrl24ePHiI6/OKimae62nZ5cNERGRKih+pII5bN682ej9kiVL4OPjg4MHD+KFF15Aeno6Fi1ahOXLl6NFixYAcgcwBwcHY+/evWjcuLElypZJ8jMVLFoGERER3aOqMTbp6ekAAC8vLwDAwYMHcffuXYSGhsrLVK1aFWXLlkVsbGyB68jKykJGRobRq7jIV0Ux2RAREamCaoKNXq/HiBEj0KRJE9SoUQMAkJycDHt7e3h4eBgt6+vri+Tk5ALXM23aNLi7u8uvwMDAYquZT/cmIiJSF9UEm8GDB+P48eNYsWKFSesZN24c0tPT5VdSUpKZKiwAr4oiIiJSFYuOsTEYMmQIfvnlF/z+++8ICAiQp+t0Oty5cwdpaWlGvTYpKSnQ6XQFrkur1UKr1RZ3yQB4VRQREZHaWLTHRgiBIUOGYO3atfjtt98QFBRkNL9evXqws7PD9u3b5Wnx8fFITExESEhISZebz/07DzPaEBERqYFFe2wGDx6M5cuX46effoKrq6s8bsbd3R2Ojo5wd3dHVFQURo4cCS8vL7i5uWHo0KEICQmx+BVRAHtsiIiI1MaiwWbBggUAgGbNmhlNj46ORp8+fQAAs2bNgkajQWRkJLKyshAWFob58+eXcKUF452HiYiI1MWiwaYop3AcHBwwb948zJs3rwQqejyS/BOTDRERkRqo5qqoJxGf7k1ERKQuDDYmMNx5mLmGiIhIHRhsTMEeGyIiIlVhsDGB5l6w4UMwiYiI1IHBxgQ8FUVERKQuDDYm4A36iIiI1IXBxgSS9OhliIiIqOQw2JhAPhXFDhsiIiJVYLAxgXwqiqNsiIiIVIHBxgzYY0NERKQODDYm4LOiiIiI1IXBxgR8ujcREZG6MNiYgJd7ExERqQuDjQnYY0NERKQuDDYmkO5fFkVEREQqwGBjAg0v9yYiIlIVBhuT5CYbPXMNERGRKjDYmOD+4GHL1kFERES5GGxMcH/wMJMNERGRGjDYmIA9NkREROrCYGMC+SGYFq6DiIiIcjHYmECSz0Ux2hAREakBg40JeBsbIiIidWGwMYF8KorJhoiISBUYbEzBZ0URERGpCoONCfisKCIiInVhsDGB4VlR7LAhIiJSBwYbE7DHhoiISF0YbEyg4RgbIiIiVWGwMQFPRREREakLg40J+KwoIiIidWGwMQWfFUVERKQqDDYm4LOiiIiI1IXBxgR8ujcREZG6MNiYgGNsiIiI1IXBxgTssSEiIlIXBhsTSHKfDREREakBg40JJN6gj4iISFUYbEzAU1FERETqwmBjEl7uTUREpCYMNiZgjw0REZG6MNiYwPAQTD2TDRERkSow2JiAdx4mIiJSFwYbE0jyHfoYbYiIiNSAwcYE9+88TERERGrAYGMC6V6XDTtsiIiI1IHBxgz4rCgiIiJ1YLAxAS/3JiIiUhcGGxPwqigiIiJ1YbAxAXtsiIiI1IXBxgT3r4pisiEiIlIDBhsTSLzem4iISFUYbEwgX+5t4TqIiIgoF4ONCe7feJjRhoiISA0YbExg6LHRM9cQERGpAoONCXhVFBERkbow2Cj1+yfoc7QXutr8xquiiIiIVILBRqmMi/C9FQ8fpLHHhoiISCUYbJTS2AIAbKVsCxdCREREBgw2ShmCDfS8KoqIiEglGGyUuhdsbJDDETZEREQqYdFg8/vvvyMiIgL+/v6QJAnr1q0zmi+EwPjx4+Hn5wdHR0eEhobi9OnTlin2QUY9NhauhYiIiABYONjcvHkTtWvXxrx58wqc//HHH2Pu3LlYuHAh9u3bB2dnZ4SFhSEzM7OEKy2AHGyyeVUUERGRSthacuPh4eEIDw8vcJ4QArNnz8Z7772Hdu3aAQCWLl0KX19frFu3Dl27di3JUvNjjw0REZHqqHaMTUJCApKTkxEaGipPc3d3R6NGjRAbG2vByu6x4RgbIiIitbFoj83DJCcnAwB8fX2Npvv6+srzCpKVlYWsrCz5fUZGRvEUKF/uzR4bIiIitVBtj41S06ZNg7u7u/wKDAwsng3lGWPD53sTERGpg2qDjU6nAwCkpKQYTU9JSZHnFWTcuHFIT0+XX0lJScVTYJ4xNnp98WyCiIiIHo9qg01QUBB0Oh22b98uT8vIyMC+ffsQEhJS6Oe0Wi3c3NyMXsXC6D427LEhIiJSA4uOsblx4wbOnDkjv09ISEBcXBy8vLxQtmxZjBgxAh988AEqV66MoKAgvP/++/D390f79u0tV7QBr4oiIiJSHYsGmz///BPNmzeX348cORIA0Lt3byxZsgRvv/02bt68iQEDBiAtLQ3PP/88Nm/eDAcHB0uVfJ/RfWyIiIhIDSwabJo1a/bQ5yxJkoTJkydj8uTJJVhVEcmnothjQ0REpBaqHWOjejaGHhuOsSEiIlILBhulDD02kp5XexMREakEg41S94KNHcfYEBERqQaDjVIaOwCGMTaMNkRERGrAYKOUxgaAYYwNERERqQGDjVK8KoqIiEh1GGyU4hgbIiIi1WGwUcrm/hgbPbtsiIiIVIHBRinDGBsph5d7ExERqQSDjVJ5x9gw2RAREakCg41SeZ8VxVxDRESkCgw2St27jw2f7k1ERKQeDDZK3RtjY8NnRREREakGg41S8qko9tgQERGpBYONUnnH2Fi4FCIiIsrFYKOUDcfYEBERqQ2DjVL3emw0koAkcixcDBEREQEMNsrdGzwMgMGGiIhIJRhslLrXYwMAGpFtwUKIiIjIgMFGqXv3sQEADXtsiIiIVIHBRqk8PTbQM9gQERGpAYONUhoNBKTcH8FgQ0REpAYMNiYQUu4AYo3+roUrISIiIoDBxiT6e+NsbNhjQ0REpAoMNiaQe2w4eJiIiEgVGGxMcD/Y8HJvIiIiNWCwMYHecPdh9tgQERGpAoONCYTEYENERKQmDDYmEPceqyDxVBQREZEqMNiYwNBjY8MeGyIiIlVgsDGB4BgbIiIiVWGwMQEv9yYiIlIXBhsTyIOHwTE2REREasBgYwLD4GH22BAREakDg40JDI9U4A36iIiI1IHBxhQcY0NERKQqDDYm4FVRRERE6sJgYwLDVVF8ujcREZE6MNiYwNBjY8MxNkRERKrAYGMC+VQU9BauhIiIiAAGG5PwBn1ERETqwmBjAp6KIiIiUhcGG1MYHoLJwcNERESqwGBjAl7uTUREpC4MNibgIxWIiIjUhcHGBDY2uY9UgP6uZQshIiIiAAw2JrGztwcA3L3LYENERKQGDDYmsLfLDTbZ2XchhLBwNURERMRgYwL7ez02GpGDG1m85JuIiMjSGGxMYHuvx8YOOUi/zdNRRERElsZgYwJJc/8+Ngw2RERElsdgY4p7wcaWwYaIiEgVGGxMce8+NjbQI/0Wgw0REZGlMdiY4t59bOwk9tgQERGpAYONKTjGhoiISFUYbEyRZ4xNGoMNERGRxTHYmCLvGBsGGyIiIotjsDGF5t4YG56KIiIiUgUGG1PkGWOTwWBDRERkcQw2psg7xoaXexMREVkcg40pOMaGiIhIVRhsTHHvPja2vI8NERGRKjwRwWbevHkoX748HBwc0KhRI+zfv9/SJeXKcyoqI/Mu9Hph4YKIiIiebqoPNitXrsTIkSMxYcIEHDp0CLVr10ZYWBhSU1MtXZrR4GEhgEsZmRCC4YaIiMhSJKHyb+JGjRqhQYMG+PzzzwEAer0egYGBGDp0KMaOHfvIz2dkZMDd3R3p6elwc3Mzb3FntgHfRSJDOGFhdgQy4IS7kgMkO0fYae2htbOBRtJAkjTQaACNpIFGI0GSJGgkCZJGAw0kaGxy32skDSSNBJt78yTJ8LMEG8N7jQRJ0sBGAiSNBgK565MAQJIASPf+kztd5M6BJGkgL4LcdSDv53JnALj/syR/tuDdvz/deHnDJHnbD35OU3ieloxXYTwvz5TCahKSZLzcQ9f/wFyp4DmFbeuh8x6oo8BFHjZPyt0XJZ81WkmBny3Spwvf0uN8HEDe/8E85kfzfDD3eDZFUfdbFLBcwZsu2voer70L+LwJHzdty6pYgWqYePhZvQB/f/h4e5t1nUq/v23NWoWZ3blzBwcPHsS4cePkaRqNBqGhoYiNjS3wM1lZWcjKypLfZ2RkFF+BvjUAZx+43UzF23Yr708XADLvvYiIiKzcvurj4dNplKXLAKDyYHPlyhXk5OTA19fXaLqvry9OnTpV4GemTZuGSZMmlUR5gKsOGHYYOPQNcPEwsrNuITvrFvR3bkGffRc5er18air3vyL3v/LPAJD7PvfHB37OOw8iz7Tc9wICkmEd95aR7k0TACQIeZ4kf97wN1Sez4g8yxQo/3SjZcXDllOwPlOZsRPywbpMWfPj/8FXMp2p5mz7h67Lgn3DRd3HoreFqju6iUqcg9bO0iXIVB1slBg3bhxGjhwpv8/IyEBgYGDxbVDrAoQMBpDbmFbXoERERI9Q29IF5KHq72Fvb2/Y2NggJSXFaHpKSgp0Ol2Bn9FqtdBqtSVRHhEREamMqq+Ksre3R7169bB9+3Z5ml6vx/bt2xESEmLByoiIiEiNVN1jAwAjR45E7969Ub9+fTRs2BCzZ8/GzZs30bdvX0uXRkRERCqj+mDTpUsXXL58GePHj0dycjLq1KmDzZs35xtQTERERKT6+9iYqljvY0NERETFQun3t6rH2BARERE9DgYbIiIishoMNkRERGQ1GGyIiIjIajDYEBERkdVgsCEiIiKrwWBDREREVoPBhoiIiKwGgw0RERFZDdU/UsFUhhsrZ2RkWLgSIiIiKirD9/bjPiDB6oPN9evXAQCBgYEWroSIiIge1/Xr1+Hu7l7k5a3+WVF6vR4XL16Eq6srJEky23ozMjIQGBiIpKSkp/4ZVGyLXGyHXGyH+9gWudgOudgO9xWlLYQQuH79Ovz9/aHRFH3kjNX32Gg0GgQEBBTb+t3c3J76A9SAbZGL7ZCL7XAf2yIX2yEX2+G+R7XF4/TUGHDwMBEREVkNBhsiIiKyGgw2Cmm1WkyYMAFardbSpVgc2yIX2yEX2+E+tkUutkMutsN9xdkWVj94mIiIiJ4e7LEhIiIiq8FgQ0RERFaDwYaIiIisBoMNERERWQ0GG4XmzZuH8uXLw8HBAY0aNcL+/fstXVKxmjhxIiRJMnpVrVpVnp+ZmYnBgwejVKlScHFxQWRkJFJSUixYsXn8/vvviIiIgL+/PyRJwrp164zmCyEwfvx4+Pn5wdHREaGhoTh9+rTRMteuXUOPHj3g5uYGDw8PREVF4caNGyW4F+bxqLbo06dPvmOkVatWRstYQ1tMmzYNDRo0gKurK3x8fNC+fXvEx8cbLVOUfw+JiYlo06YNnJyc4OPjg7feegvZ2dkluSsmKUo7NGvWLN8xMXDgQKNlnvR2WLBgAWrVqiXfaC4kJASbNm2S5z8Nx4LBo9qixI4HQY9txYoVwt7eXixevFj89ddfon///sLDw0OkpKRYurRiM2HCBFG9enVx6dIl+XX58mV5/sCBA0VgYKDYvn27+PPPP0Xjxo3Fc889Z8GKzWPjxo3i3XffFT/++KMAINauXWs0f/r06cLd3V2sW7dOHDlyRLRt21YEBQWJ27dvy8u0atVK1K5dW+zdu1fs3r1bVKpUSXTr1q2E98R0j2qL3r17i1atWhkdI9euXTNaxhraIiwsTERHR4vjx4+LuLg40bp1a1G2bFlx48YNeZlH/XvIzs4WNWrUEKGhoeLw4cNi48aNwtvbW4wbN84Su6RIUdqhadOmon///kbHRHp6ujzfGtph/fr1YsOGDeLvv/8W8fHx4p133hF2dnbi+PHjQoin41gweFRblNTxwGCjQMOGDcXgwYPl9zk5OcLf319MmzbNglUVrwkTJojatWsXOC8tLU3Y2dmJ1atXy9NOnjwpAIjY2NgSqrD4PfhlrtfrhU6nE5988ok8LS0tTWi1WvH9998LIYQ4ceKEACAOHDggL7Np0yYhSZK4cOFCidVuboUFm3bt2hX6GWtti9TUVAFA7Nq1SwhRtH8PGzduFBqNRiQnJ8vLLFiwQLi5uYmsrKyS3QEzebAdhMj9Ihs+fHihn7HGdhBCCE9PT/H1118/tcdCXoa2EKLkjgeeinpMd+7cwcGDBxEaGipP02g0CA0NRWxsrAUrK36nT5+Gv78/KlSogB49eiAxMREAcPDgQdy9e9eoTapWrYqyZctadZskJCQgOTnZaL/d3d3RqFEjeb9jY2Ph4eGB+vXry8uEhoZCo9Fg3759JV5zcdu5cyd8fHxQpUoVvPHGG7h69ao8z1rbIj09HQDg5eUFoGj/HmJjY1GzZk34+vrKy4SFhSEjIwN//fVXCVZvPg+2g8GyZcvg7e2NGjVqYNy4cbh165Y8z9raIScnBytWrMDNmzcREhLy1B4LQP62MCiJ48HqH4JpbleuXEFOTo5RwwOAr68vTp06ZaGqil+jRo2wZMkSVKlSBZcuXcKkSZPwv//9D8ePH0dycjLs7e3h4eFh9BlfX18kJydbpuASYNi3go4Fw7zk5GT4+PgYzbe1tYWXl5fVtU2rVq3QsWNHBAUF4Z9//sE777yD8PBwxMbGwsbGxirbQq/XY8SIEWjSpAlq1KgBAEX695CcnFzgcWOY96QpqB0AoHv37ihXrhz8/f1x9OhRjBkzBvHx8fjxxx8BWE87HDt2DCEhIcjMzISLiwvWrl2LatWqIS4u7qk7FgprC6DkjgcGGyqS8PBw+edatWqhUaNGKFeuHFatWgVHR0cLVkZq0bVrV/nnmjVrolatWqhYsSJ27tyJli1bWrCy4jN48GAcP34ce/bssXQpFlVYOwwYMED+uWbNmvDz80PLli3xzz//oGLFiiVdZrGpUqUK4uLikJ6ejjVr1qB3797YtWuXpcuyiMLaolq1aiV2PPBU1GPy9vaGjY1NvlHtKSkp0Ol0Fqqq5Hl4eOCZZ57BmTNnoNPpcOfOHaSlpRktY+1tYti3hx0LOp0OqampRvOzs7Nx7do1q24bAKhQoQK8vb1x5swZANbXFkOGDMEvv/yCHTt2ICAgQJ5elH8POp2uwOPGMO9JUlg7FKRRo0YAYHRMWEM72Nvbo1KlSqhXrx6mTZuG2rVrY86cOU/dsQAU3hYFKa7jgcHmMdnb26NevXrYvn27PE2v12P79u1G5xGt3Y0bN/DPP//Az88P9erVg52dnVGbxMfHIzEx0arbJCgoCDqdzmi/MzIysG/fPnm/Q0JCkJaWhoMHD8rL/Pbbb9Dr9fI/amt1/vx5XL16FX5+fgCspy2EEBgyZAjWrl2L3377DUFBQUbzi/LvISQkBMeOHTMKelu3boWbm5vcba92j2qHgsTFxQGA0THxpLdDQfR6PbKysp6aY+FhDG1RkGI7HhQOdH6qrVixQmi1WrFkyRJx4sQJMWDAAOHh4WE0ktvajBo1SuzcuVMkJCSImJgYERoaKry9vUVqaqoQIveSxrJly4rffvtN/PnnnyIkJESEhIRYuGrTXb9+XRw+fFgcPnxYABAzZ84Uhw8fFufOnRNC5F7u7eHhIX766Sdx9OhR0a5duwIv965bt67Yt2+f2LNnj6hcufITd4mzEA9vi+vXr4vRo0eL2NhYkZCQILZt2yaeffZZUblyZZGZmSmvwxra4o033hDu7u5i586dRpet3rp1S17mUf8eDJe1vvTSSyIuLk5s3rxZlC5d+om6xPdR7XDmzBkxefJk8eeff4qEhATx008/iQoVKogXXnhBXoc1tMPYsWPFrl27REJCgjh69KgYO3askCRJ/Prrr0KIp+NYMHhYW5Tk8cBgo9Bnn30mypYtK+zt7UXDhg3F3r17LV1SserSpYvw8/MT9vb2okyZMqJLly7izJkz8vzbt2+LQYMGCU9PT+Hk5CQ6dOggLl26ZMGKzWPHjh0CQL5X7969hRC5l3y///77wtfXV2i1WtGyZUsRHx9vtI6rV6+Kbt26CRcXF+Hm5ib69u0rrl+/boG9Mc3D2uLWrVvipZdeEqVLlxZ2dnaiXLlyon///vnCvjW0RUFtAEBER0fLyxTl38PZs2dFeHi4cHR0FN7e3mLUqFHi7t27Jbw3yj2qHRITE8ULL7wgvLy8hFarFZUqVRJvvfWW0X1LhHjy26Ffv36iXLlywt7eXpQuXVq0bNlSDjVCPB3HgsHD2qIkjwdJCCGK3r9DREREpF4cY0NERERWg8GGiIiIrAaDDREREVkNBhsiIiKyGgw2REREZDUYbIiIiMhqMNgQERGR1WCwIaKnjiRJWLdunaXLIKJiwGBDRCWqT58+kCQp36tVq1aWLo2IrICtpQsgoqdPq1atEB0dbTRNq9VaqBoisibssSGiEqfVaqHT6Yxenp6eAHJPEy1YsADh4eFwdHREhQoVsGbNGqPPHzt2DC1atICjoyNKlSqFAQMG4MaNG0bLLF68GNWrV4dWq4Wfnx+GDBliNP/KlSvo0KEDnJycULlyZaxfv754d5qISgSDDRGpzvvvv4/IyEgcOXIEPXr0QNeuXXHy5EkAwM2bNxEWFgZPT08cOHAAq1evxrZt24yCy4IFCzB48GAMGDAAx44dw/r161GpUiWjbUyaNAmdO3fG0aNH0bp1a/To0QPXrl0r0f0komJgpod6EhEVSe/evYWNjY1wdnY2ek2dOlUIkfvU6IEDBxp9plGjRuKNN94QQgjx5ZdfCk9PT3Hjxg15/oYNG4RGo5GfJu7v7y/efffdQmsAIN577z35/Y0bNwQAsWnTJrPtJxFZBsfYEFGJa968ORYsWGA0zcvLS/45JCTEaF5ISAji4uIAACdPnkTt2rXh7Owsz2/SpAn0ej3i4+MhSRIuXryIli1bPrSGWrVqyT87OzvDzc0NqampSneJiFSCwYaISpyzs3O+U0Pm4ujoWKTl7OzsjN5LkgS9Xl8cJRFRCeIYGyJSnb179+Z7HxwcDAAIDg7GkSNHcPPmTXl+TEwMNBoNqlSpAldXV5QvXx7bt28v0ZqJSB3YY0NEJS4rKwvJyclG02xtbeHt7Q0AWL16NerXr4/nn38ey5Ytw/79+7Fo0SIAQI8ePTBhwgT07t0bEydOxOXLlzF06FC8+uqr8PX1BQBMnDgRAwcOhI+PD8LDw3H9+nXExMRg6NChJbujRFTiGGyIqMRt3rwZfn5+RtOqVKmCU6dOAci9YmnFihUYNGgQ/Pz88P3336NatWoAACcnJ2zZsgXDhw9HgwYN4OTkhMjISMycOVNeV+/evZGZmYlZs2Zh9OjR8Pb2xiuvvFJyO0hEFiMJIYSliyAiMpAkCWvXrkX79u0tXQoRPYE4xoaIiIisBoMNERERWQ2OsSEiVeHZcSIyBXtsiIiIyGow2BAREZHVYLAhIiIiq8FgQ0RERFaDwYaIiIisBoMNERERWQ0GGyIiIrIaDDZERERkNRhsiIiIyGr8H39JOa+LQMZDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_mlp[\"loss\"], label=\"Train loss (MSE log)\")\n",
    "plt.plot(history_mlp[\"val_loss\"], label=\"Val loss (MSE log)\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP: curva de entrenamiento\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa77ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional y recomendable entre datasets)\n",
    "del tuner  # libera memoria de trials\n",
    "gc.collect()\n",
    "del model\n",
    "reset_tf(SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8d0ea",
   "metadata": {},
   "source": [
    "### Tercer modelo MLP --> Con coordenadas y VCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e10dc43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25211.000000\n",
       "mean         8.395828\n",
       "std          0.830310\n",
       "min          5.950643\n",
       "25%          7.740664\n",
       "50%          8.242756\n",
       "75%          8.984694\n",
       "max         10.915088\n",
       "Name: log_monto, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vcr_e = pd.read_csv('dataset_vcr_expanded.csv')\n",
    "df_vcr_e = df_vcr_e[df_vcr_e['monto'] < 56000].copy()\n",
    "df_vcr_e['log_monto']=np.log(df_vcr_e['monto'])\n",
    "df_vcr_e['log_monto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "099e21a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 181 columns):\n",
      " #    Column                        Dtype  \n",
      "---   ------                        -----  \n",
      " 0    monto                         int64  \n",
      " 1    superficie_t                  float64\n",
      " 2    dormitorios                   int64  \n",
      " 3    dormitorios_faltante          int64  \n",
      " 4    banos                         int64  \n",
      " 5    banos_faltante                int64  \n",
      " 6    antiguedad                    int64  \n",
      " 7    antiguedad_faltante           int64  \n",
      " 8    Or_N                          int64  \n",
      " 9    Or_S                          int64  \n",
      " 10   Or_E                          int64  \n",
      " 11   Or_O                          int64  \n",
      " 12   Or_Faltante                   int64  \n",
      " 13   terraza                       float64\n",
      " 14   estacionamiento               int64  \n",
      " 15   bodegas                       int64  \n",
      " 16   flag_Departamento             int64  \n",
      " 17   flag_Multinivel               int64  \n",
      " 18   flag_Semipiso                 int64  \n",
      " 19   flag_Premium                  int64  \n",
      " 20   flag_Monoambiente             int64  \n",
      " 21   flag_Loft                     int64  \n",
      " 22   latitud                       float64\n",
      " 23   longitud                      float64\n",
      " 24   sport_and_leisure_dim00       float64\n",
      " 25   sport_and_leisure_dim01       float64\n",
      " 26   sport_and_leisure_dim02       float64\n",
      " 27   sport_and_leisure_dim03       float64\n",
      " 28   sport_and_leisure_dim04       float64\n",
      " 29   sport_and_leisure_dim05       float64\n",
      " 30   sport_and_leisure_dim06       float64\n",
      " 31   sport_and_leisure_dim07       float64\n",
      " 32   sport_and_leisure_dim08       float64\n",
      " 33   sport_and_leisure_dim09       float64\n",
      " 34   sport_and_leisure_dim10       float64\n",
      " 35   sport_and_leisure_dim11       float64\n",
      " 36   medical_dim00                 float64\n",
      " 37   medical_dim01                 float64\n",
      " 38   medical_dim02                 float64\n",
      " 39   medical_dim03                 float64\n",
      " 40   medical_dim04                 float64\n",
      " 41   medical_dim05                 float64\n",
      " 42   medical_dim06                 float64\n",
      " 43   medical_dim07                 float64\n",
      " 44   medical_dim08                 float64\n",
      " 45   medical_dim09                 float64\n",
      " 46   medical_dim10                 float64\n",
      " 47   medical_dim11                 float64\n",
      " 48   education_prim_dim00          float64\n",
      " 49   education_prim_dim01          float64\n",
      " 50   education_prim_dim02          float64\n",
      " 51   education_prim_dim03          float64\n",
      " 52   education_prim_dim04          float64\n",
      " 53   education_prim_dim05          float64\n",
      " 54   education_prim_dim06          float64\n",
      " 55   education_prim_dim07          float64\n",
      " 56   education_prim_dim08          float64\n",
      " 57   education_prim_dim09          float64\n",
      " 58   education_prim_dim10          float64\n",
      " 59   education_prim_dim11          float64\n",
      " 60   veterinary_dim00              float64\n",
      " 61   veterinary_dim01              float64\n",
      " 62   veterinary_dim02              float64\n",
      " 63   veterinary_dim03              float64\n",
      " 64   veterinary_dim04              float64\n",
      " 65   veterinary_dim05              float64\n",
      " 66   veterinary_dim06              float64\n",
      " 67   veterinary_dim07              float64\n",
      " 68   veterinary_dim08              float64\n",
      " 69   veterinary_dim09              float64\n",
      " 70   veterinary_dim10              float64\n",
      " 71   veterinary_dim11              float64\n",
      " 72   food_and_drink_stores_dim00   float64\n",
      " 73   food_and_drink_stores_dim01   float64\n",
      " 74   food_and_drink_stores_dim02   float64\n",
      " 75   food_and_drink_stores_dim03   float64\n",
      " 76   food_and_drink_stores_dim04   float64\n",
      " 77   food_and_drink_stores_dim05   float64\n",
      " 78   food_and_drink_stores_dim06   float64\n",
      " 79   food_and_drink_stores_dim07   float64\n",
      " 80   food_and_drink_stores_dim08   float64\n",
      " 81   food_and_drink_stores_dim09   float64\n",
      " 82   food_and_drink_stores_dim10   float64\n",
      " 83   food_and_drink_stores_dim11   float64\n",
      " 84   arts_and_entertainment_dim00  float64\n",
      " 85   arts_and_entertainment_dim01  float64\n",
      " 86   arts_and_entertainment_dim02  float64\n",
      " 87   arts_and_entertainment_dim03  float64\n",
      " 88   arts_and_entertainment_dim04  float64\n",
      " 89   arts_and_entertainment_dim05  float64\n",
      " 90   arts_and_entertainment_dim06  float64\n",
      " 91   arts_and_entertainment_dim07  float64\n",
      " 92   arts_and_entertainment_dim08  float64\n",
      " 93   arts_and_entertainment_dim09  float64\n",
      " 94   arts_and_entertainment_dim10  float64\n",
      " 95   arts_and_entertainment_dim11  float64\n",
      " 96   food_and_drink_dim00          float64\n",
      " 97   food_and_drink_dim01          float64\n",
      " 98   food_and_drink_dim02          float64\n",
      " 99   food_and_drink_dim03          float64\n",
      " 100  food_and_drink_dim04          float64\n",
      " 101  food_and_drink_dim05          float64\n",
      " 102  food_and_drink_dim06          float64\n",
      " 103  food_and_drink_dim07          float64\n",
      " 104  food_and_drink_dim08          float64\n",
      " 105  food_and_drink_dim09          float64\n",
      " 106  food_and_drink_dim10          float64\n",
      " 107  food_and_drink_dim11          float64\n",
      " 108  park_like_dim00               float64\n",
      " 109  park_like_dim01               float64\n",
      " 110  park_like_dim02               float64\n",
      " 111  park_like_dim03               float64\n",
      " 112  park_like_dim04               float64\n",
      " 113  park_like_dim05               float64\n",
      " 114  park_like_dim06               float64\n",
      " 115  park_like_dim07               float64\n",
      " 116  park_like_dim08               float64\n",
      " 117  park_like_dim09               float64\n",
      " 118  park_like_dim10               float64\n",
      " 119  park_like_dim11               float64\n",
      " 120  security_dim00                float64\n",
      " 121  security_dim01                float64\n",
      " 122  security_dim02                float64\n",
      " 123  security_dim03                float64\n",
      " 124  security_dim04                float64\n",
      " 125  security_dim05                float64\n",
      " 126  security_dim06                float64\n",
      " 127  security_dim07                float64\n",
      " 128  security_dim08                float64\n",
      " 129  security_dim09                float64\n",
      " 130  security_dim10                float64\n",
      " 131  security_dim11                float64\n",
      " 132  religion_dim00                float64\n",
      " 133  religion_dim01                float64\n",
      " 134  religion_dim02                float64\n",
      " 135  religion_dim03                float64\n",
      " 136  religion_dim04                float64\n",
      " 137  religion_dim05                float64\n",
      " 138  religion_dim06                float64\n",
      " 139  religion_dim07                float64\n",
      " 140  religion_dim08                float64\n",
      " 141  religion_dim09                float64\n",
      " 142  religion_dim10                float64\n",
      " 143  religion_dim11                float64\n",
      " 144  education_sup_dim00           float64\n",
      " 145  education_sup_dim01           float64\n",
      " 146  education_sup_dim02           float64\n",
      " 147  education_sup_dim03           float64\n",
      " 148  education_sup_dim04           float64\n",
      " 149  education_sup_dim05           float64\n",
      " 150  education_sup_dim06           float64\n",
      " 151  education_sup_dim07           float64\n",
      " 152  education_sup_dim08           float64\n",
      " 153  education_sup_dim09           float64\n",
      " 154  education_sup_dim10           float64\n",
      " 155  education_sup_dim11           float64\n",
      " 156  metro_dim00                   float64\n",
      " 157  metro_dim01                   float64\n",
      " 158  metro_dim02                   float64\n",
      " 159  metro_dim03                   float64\n",
      " 160  metro_dim04                   float64\n",
      " 161  metro_dim05                   float64\n",
      " 162  metro_dim06                   float64\n",
      " 163  metro_dim07                   float64\n",
      " 164  metro_dim08                   float64\n",
      " 165  metro_dim09                   float64\n",
      " 166  metro_dim10                   float64\n",
      " 167  metro_dim11                   float64\n",
      " 168  bus_dim00                     float64\n",
      " 169  bus_dim01                     float64\n",
      " 170  bus_dim02                     float64\n",
      " 171  bus_dim03                     float64\n",
      " 172  bus_dim04                     float64\n",
      " 173  bus_dim05                     float64\n",
      " 174  bus_dim06                     float64\n",
      " 175  bus_dim07                     float64\n",
      " 176  bus_dim08                     float64\n",
      " 177  bus_dim09                     float64\n",
      " 178  bus_dim10                     float64\n",
      " 179  bus_dim11                     float64\n",
      " 180  log_monto                     float64\n",
      "dtypes: float64(161), int64(20)\n",
      "memory usage: 35.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_vcr =df_vcr_e.copy()\n",
    "obj_cols = df_vcr.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols)\n",
    "cols_to_drop.append(\"id\")\n",
    "df_vcr = df_vcr.drop(columns=cols_to_drop)\n",
    "df_vcr.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aba5ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputación VCR completada. NaNs antes: 246,228 -> después: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Columns: 194 entries, monto to has_bus\n",
      "dtypes: float64(161), int64(33)\n",
      "memory usage: 37.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Imputación datos faltantes en VCR\n",
    "import re\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "# Configuración (\n",
    "# Dimensiones (1..12) \n",
    "DIMS_MAP = {\n",
    "    1: \"count_pois\",\n",
    "    2: \"mean_distance\",\n",
    "    3: \"min_distance\",\n",
    "    4: \"max_distance\",\n",
    "    5: \"median_distance\",\n",
    "    6: \"std_distance\",\n",
    "    7: \"mean_inverse_distance\",\n",
    "    8: \"max_inverse_distance\",\n",
    "    9: \"sum_inverse_distance\",\n",
    "    10: \"ratio_within_near_radius\",\n",
    "    11: \"ratio_within_mid_radius\",\n",
    "    12: \"ratio_within_far_radius\",\n",
    "}\n",
    "\n",
    "# Rol por dimensión (para decidir la imputación semántica)\n",
    "DIM_ROLE = {\n",
    "    1: \"count\",                # -> 0\n",
    "    2: \"distance\",             # -> R3\n",
    "    3: \"distance\",             # -> R3\n",
    "    4: \"distance\",             # -> R3\n",
    "    5: \"distance\",             # -> R3\n",
    "    6: \"std\",                  # -> 0\n",
    "    7: \"inverse\",              # -> 0\n",
    "    8: \"inverse\",              # -> 0\n",
    "    9: \"inverse\",              # -> 0\n",
    "    10: \"ratio\",               # -> 0\n",
    "    11: \"ratio\",               # -> 0\n",
    "    12: \"ratio\",               # -> 0\n",
    "}\n",
    "\n",
    "# R3 por tipo de clase\n",
    "R3_DEFAULT = 2400.0  # clases generales\n",
    "R3_METRO = 1600.0\n",
    "R3_BUS = 800.0\n",
    "\n",
    "# Funciones\n",
    "def _class_and_dim(col: str) -> Optional[Tuple[str, int]]:\n",
    "    \"\"\"Extrae (clase, índice de dimensión) de columnas tipo '<clase>_dimXX'.\"\"\"\n",
    "    m = re.match(r\"^(?P<klass>.+)_dim(?P<idx>\\d{1,2})$\", col)\n",
    "    if not m:\n",
    "        return None\n",
    "    return m.group(\"klass\"), int(m.group(\"idx\"))\n",
    "\n",
    "\n",
    "def _r3_for_class(klass: str) -> float:\n",
    "    k = klass.lower()\n",
    "    if \"metro\" in k:\n",
    "        return R3_METRO\n",
    "    if \"bus\" in k:\n",
    "        return R3_BUS\n",
    "    return R3_DEFAULT\n",
    "\n",
    "\n",
    "def impute_vcr_semantic(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Imputa VCR por semántica de ausencia: distancias=R3, inversas/ratios=0, count=0, std=0.\n",
    "    Además agrega flags `has_<clase>` indicando presencia de POIs por clase.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Agrupar columnas por clase\n",
    "    groups: Dict[str, Dict[int, str]] = {}\n",
    "    vcr_cols = []\n",
    "    for c in out.columns:\n",
    "        parsed = _class_and_dim(c)\n",
    "        if parsed is None:\n",
    "            continue\n",
    "        klass, idx = parsed\n",
    "        groups.setdefault(klass, {})[idx] = c\n",
    "        vcr_cols.append(c)\n",
    "\n",
    "    if not groups:\n",
    "        # Nada que imputar\n",
    "        return out\n",
    "\n",
    "    # Flags de presencia por clase (antes de imputar)\n",
    "    for klass, dim_map in groups.items():\n",
    "        cols = list(dim_map.values())\n",
    "        has_series = out[cols].notna().any(axis=1).astype(\"int64\")\n",
    "        out[f\"has_{klass}\"] = has_series  # por qué: distingue ausencia real vs lejanía\n",
    "\n",
    "    # Imputación por clase/dim\n",
    "    n_total_nans = int(out[vcr_cols].isna().sum().sum())\n",
    "    for klass, dim_map in groups.items():\n",
    "        r3 = _r3_for_class(klass)\n",
    "        for idx, col in dim_map.items():\n",
    "            role = DIM_ROLE.get(idx)\n",
    "            if role == \"distance\":\n",
    "                fill_value = r3\n",
    "            elif role in {\"inverse\", \"ratio\", \"std\", \"count\"}:\n",
    "                fill_value = 0.0\n",
    "            else:\n",
    "                # Si hay una dimensión desconocida, ser conservador con 0.0\n",
    "                fill_value = 0.0\n",
    "            out[col] = out[col].fillna(fill_value)\n",
    "\n",
    "    n_after_nans = int(out[vcr_cols].isna().sum().sum())\n",
    "    print(f\"Imputación VCR completada. NaNs antes: {n_total_nans:,d} -> después: {n_after_nans:,d}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "df_vcr_imp = impute_vcr_semantic(df_vcr)\n",
    "df_vcr_imp.info()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84bc8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 192\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_vcr_imp.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_vcr_imp[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47666ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"mlp_v2\"\n",
    "reset_tf(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f95057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_train_batch_end` time: 0.0088s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0078s). Check your callbacks.\n",
      "Tuning terminado en 1720.29 s | trials: 1\n"
     ]
    }
   ],
   "source": [
    "# ====== Tuning ======\n",
    "callbacks_tuner = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "]\n",
    "DATASET_TAG = \"ds3\"  \n",
    "RUN_TAG = f\"{PROJECT_NAME}_{DATASET_TAG}_{int(time.time())}\"\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "    max_epochs=MAX_EPOCHS_TUNER,\n",
    "    factor=3,\n",
    "    seed=SEED,\n",
    "    directory=\"kt_logs\", \n",
    "    project_name=PROJECT_NAME,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=MAX_EPOCHS_TUNER,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_tuner,\n",
    "    verbose=0,\n",
    ")\n",
    "tuning_time = time.perf_counter() - start\n",
    "print(f\"Tuning terminado en {tuning_time:.2f} s | trials: {len(tuner.get_best_hyperparameters())}\")\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36037a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0464 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0469 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0469 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0471 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0462 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0465 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0456 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0462 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0463 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0466 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0464 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0471 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0463 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0462 - val_loss: 0.0347 - lr: 1.0000e-06\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0461 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0472 - val_loss: 0.0346 - lr: 1.0000e-06\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0470 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0467 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0463 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0453 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0467 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0467 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0458 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0464 - val_loss: 0.0347 - lr: 1.0000e-06\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0470 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0469 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0480 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0461 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0466 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0472 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0473 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0476 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0467 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0473 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0459 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0465 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0465 - val_loss: 0.0346 - lr: 1.0000e-06\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0468 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0459 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0463 - val_loss: 0.0346 - lr: 1.0000e-06\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0468 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0470 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0458 - val_loss: 0.0345 - lr: 1.0000e-06\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0464 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0472 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0464 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0466 - val_loss: 0.0343 - lr: 1.0000e-06\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0461 - val_loss: 0.0344 - lr: 1.0000e-06\n",
      "\n",
      "=== MLP (Keras Tuner) ===\n",
      ">> LOG space\n",
      "Train: R^2=0.9693 | RMSE=0.1447 | MAE=0.1058\n",
      "Val  : R^2=0.9521 | RMSE=0.1832 | MAE=0.1310\n",
      "Test : R^2=0.9533 | RMSE=0.1810 | MAE=0.1303\n",
      ">> UF space (precio)\n",
      "Train: RMSE=1,276.94 | MAE=645.60 | MAPE=10.86%\n",
      "Val  : RMSE=1,616.27 | MAE=832.89 | MAPE=13.88%\n",
      "Test : RMSE=1,668.45 | MAE=808.53 | MAPE=13.92%\n"
     ]
    }
   ],
   "source": [
    "# ====== Entrenamiento final con mejor HP ======\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "        \"models/best_model_mlp_v3.keras\",\n",
    "        monitor=\"val_loss\", save_best_only=True\n",
    "        )\n",
    "callbacks_train = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=RLROP_FACTOR, patience=RLROP_PATIENCE, min_lr=MIN_LR),\n",
    "    ckpt_cb,\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS_FINAL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_train,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ====== Métricas ======\n",
    "def eval_all_splits(model, Xtr, ytr, Xva, yva, Xte, yte):\n",
    "    def _pred(X):\n",
    "        return np.asarray(model.predict(X, verbose=0)).reshape(-1)\n",
    "\n",
    "    ytr_pred_log = _pred(Xtr)\n",
    "    yva_pred_log = _pred(Xva)\n",
    "    yte_pred_log = _pred(Xte)\n",
    "\n",
    "    # LOG\n",
    "    r2_tr = r2_score(ytr, ytr_pred_log)\n",
    "    r2_va = r2_score(yva, yva_pred_log)\n",
    "    r2_te = r2_score(yte, yte_pred_log)\n",
    "\n",
    "    rmse_log_tr = float(np.sqrt(np.mean((ytr - ytr_pred_log) ** 2)))\n",
    "    rmse_log_va = float(np.sqrt(np.mean((yva - yva_pred_log) ** 2)))\n",
    "    rmse_log_te = float(np.sqrt(np.mean((yte - yte_pred_log) ** 2)))\n",
    "\n",
    "    mae_log_tr = mean_absolute_error(ytr, ytr_pred_log)\n",
    "    mae_log_va = mean_absolute_error(yva, yva_pred_log)\n",
    "    mae_log_te = mean_absolute_error(yte, yte_pred_log)\n",
    "\n",
    "    # UF\n",
    "    ytr_price = np.exp(ytr)\n",
    "    yva_price = np.exp(yva)\n",
    "    yte_price = np.exp(yte)\n",
    "\n",
    "    ytr_pred_price = np.exp(ytr_pred_log)\n",
    "    yva_pred_price = np.exp(yva_pred_log)\n",
    "    yte_pred_price = np.exp(yte_pred_log)\n",
    "\n",
    "    rmse_tr = root_mean_squared_error(ytr_price, ytr_pred_price)\n",
    "    rmse_va = root_mean_squared_error(yva_price, yva_pred_price)\n",
    "    rmse_te = root_mean_squared_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mae_tr  = mean_absolute_error(ytr_price, ytr_pred_price)\n",
    "    mae_va  = mean_absolute_error(yva_price, yva_pred_price)\n",
    "    mae_te  = mean_absolute_error(yte_price, yte_pred_price)\n",
    "\n",
    "    mape_tr = float(np.mean(np.abs((ytr_price - ytr_pred_price) / np.clip(ytr_price, 1e-9, None))) * 100)\n",
    "    mape_va = float(np.mean(np.abs((yva_price - yva_pred_price) / np.clip(yva_price, 1e-9, None))) * 100)\n",
    "    mape_te = float(np.mean(np.abs((yte_price - yte_pred_price) / np.clip(yte_price, 1e-9, None))) * 100)\n",
    "\n",
    "    return {\n",
    "        \"log\": {\n",
    "            \"r2\": (r2_tr, r2_va, r2_te),\n",
    "            \"rmse\": (rmse_log_tr, rmse_log_va, rmse_log_te),\n",
    "            \"mae\": (mae_log_tr, mae_log_va, mae_log_te),\n",
    "        },\n",
    "        \"uf\": {\n",
    "            \"rmse\": (rmse_tr, rmse_va, rmse_te),\n",
    "            \"mae\": (mae_tr, mae_va, mae_te),\n",
    "            \"mape\": (mape_tr, mape_va, mape_te),\n",
    "        },\n",
    "    }\n",
    "\n",
    "metrics = eval_all_splits(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(\"\\n=== MLP (Keras Tuner) ===\")\n",
    "print(\">> LOG space\")\n",
    "print(f\"Train: R^2={metrics['log']['r2'][0]:.4f} | RMSE={metrics['log']['rmse'][0]:.4f} | MAE={metrics['log']['mae'][0]:.4f}\")\n",
    "print(f\"Val  : R^2={metrics['log']['r2'][1]:.4f} | RMSE={metrics['log']['rmse'][1]:.4f} | MAE={metrics['log']['mae'][1]:.4f}\")\n",
    "print(f\"Test : R^2={metrics['log']['r2'][2]:.4f} | RMSE={metrics['log']['rmse'][2]:.4f} | MAE={metrics['log']['mae'][2]:.4f}\")\n",
    "\n",
    "print(\">> UF space (precio)\")\n",
    "print(f\"Train: RMSE={metrics['uf']['rmse'][0]:,.2f} | MAE={metrics['uf']['mae'][0]:,.2f} | MAPE={metrics['uf']['mape'][0]:.2f}%\")\n",
    "print(f\"Val  : RMSE={metrics['uf']['rmse'][1]:,.2f} | MAE={metrics['uf']['mae'][1]:,.2f} | MAPE={metrics['uf']['mape'][1]:.2f}%\")\n",
    "print(f\"Test : RMSE={metrics['uf']['rmse'][2]:,.2f} | MAE={metrics['uf']['mae'][2]:,.2f} | MAPE={metrics['uf']['mape'][2]:.2f}%\")\n",
    "\n",
    "# ====== Historial para gráficos ======\n",
    "history_mlp = {\n",
    "    \"loss\": history.history.get(\"loss\", []),\n",
    "    \"val_loss\": history.history.get(\"val_loss\", []),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117b326",
   "metadata": {},
   "source": [
    "#### Nota sobre los últimos resultados:\n",
    "Estos resultados difieren de los reportados en el informe. Esta discrepancia surge de un reordenamiento de este archivo posterior a la realización del reporte.\n",
    "\n",
    "Los resultados reportados en las celdas inferiores son los consistentes con el informe.\n",
    "\n",
    "Los residuos de los modelos y análisis SHAP se realizaron de acuerdo a los resultados reportados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0d070dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: models/best_hp_mlp_v3.json\n",
      "Guardado: models/best_model_mlp_v3.keras\n",
      "Guardado: models/scaler_mlp_v3.joblib\n",
      "Guardado: models/feature_names_mlp_v3.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "with open(\"models/best_hp_mlp_v3.json\", \"w\") as f:\n",
    "    json.dump(best_hp.values, f, indent=2)\n",
    "print(\"Guardado: models/best_hp_mlp_v3.json\")\n",
    "\n",
    "model.save(\"models/best_model_mlp_v3.keras\")\n",
    "print(\"Guardado: models/best_model_mlp_v3.keras\")\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler_mlp_v3.joblib\")\n",
    "print(\"Guardado: models/scaler_mlp_v3.joblib\")\n",
    "\n",
    "feature_names = list(X_df.columns)\n",
    "with open(\"models/feature_names_mlp_v3.json\",\"w\") as f:\n",
    "    json.dump(feature_names, f, indent=2)\n",
    "print(\"Guardado: models/feature_names_mlp_v3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce337822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_mlp[\"loss\"], label=\"Train loss (MSE log)\")\n",
    "plt.plot(history_mlp[\"val_loss\"], label=\"Val loss (MSE log)\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP: curva de entrenamiento\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8546377",
   "metadata": {},
   "source": [
    "Comparación de resultados en MLP\n",
    "\n",
    "El modelo basado en perceptrón multicapa (MLP) muestra un patrón de mejora consistente conforme se incorporan variables georreferenciales. El modelo de control, que utiliza únicamente atributos estructurales de las viviendas, alcanza un R² de 0.90 en el espacio logarítmico y un MAPE cercano al 20%, un desempeño comparable al obtenido por el FT-Transformer en su configuración base. La inclusión de las coordenadas de latitud y longitud produce una mejora significativa, elevando el R² a 0.95 y reduciendo el MAPE a 13.97%, lo que evidencia la alta sensibilidad del MLP para capturar las relaciones espaciales básicas a través de variables continuas. Al añadir los vectores de características de referencia (VCR), que describen el contexto urbano y la presencia de distintos puntos de interés en el entorno, el modelo logra su mejor desempeño con un R² de 0.95 y un MAPE de 13.63%. Sin embargo, la mejora respecto al modelo con solo coordenadas es marginal y se acompaña de una leve brecha entre los errores de entrenamiento y validación, lo que sugiere un ligero sobreajuste asociado al aumento de dimensionalidad del dataset. En conjunto, los resultados indican que el MLP aprovecha eficazmente la información espacial directa, mientras que los VCR aportan beneficios limitados frente a su complejidad adicional, reforzando la idea de que gran parte del valor predictivo del contexto geográfico ya está contenido en las coordenadas mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448231d",
   "metadata": {},
   "source": [
    "#### Resultados MLP (con optimización de hiperparámetros)\n",
    "\n",
    "| Modelo                  | Conjunto | R² (log) | RMSE_log | MAE_log | RMSE ($) | MAE ($) | MAPE (%) |\n",
    "|--------------------------|----------|:--------:|---------:|--------:|---------:|--------:|---------:|\n",
    "| **1) MLP (solo estructural)** | Train    | 0.9073 | 0.2515 | 0.1886 | 1,946.36 | 1,085.75 | 19.61 |\n",
    "|                          | Val      | 0.9072 | 0.2552 | 0.1932 | 2,167.17 | 1,174.19 | 20.17 |\n",
    "|                          | **Test** | **0.9046** | **0.2588** | **0.1951** | **2,103.72** | **1,150.57** | **20.39** |\n",
    "| **2) MLP + lat/lon**     | Train    | 0.9524 | 0.1801 | 0.1298 | 1,572.76 | 783.23 | 13.28 |\n",
    "|                          | Val      | 0.9495 | 0.1882 | 0.1360 | 1,754.49 | 855.80 | 14.06 |\n",
    "|                          | **Test** | **0.9521** | **0.1833** | **0.1366** | **1,651.47** | **829.88** | **13.97** |\n",
    "| **3) MLP + VCR completos** | Train    | 0.9729 | 0.1359 | 0.0993 | 1,213.44 | 605.37 | 10.12 |\n",
    "|                          | Val      | 0.9512 | 0.1851 | 0.1302 | 1,633.06 | 820.14 | 13.67 |\n",
    "|                          | **Test** | **0.9540** | **0.1796** | **0.1283** | **1,642.30** | **791.70** | **13.63** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cfc4f",
   "metadata": {},
   "source": [
    "#### Resultados del modelo MLP\n",
    "\n",
    "| Modelo                                   | R² (log) | RMSE_log | MAE_log | RMSE (UF) | MAE (UF) | MAPE (%) |\n",
    "|------------------------------------------|:--------:|:--------:|:-------:|----------:|---------:|---------:|\n",
    "| **1) MLP (solo estructural)**            | 0.9046 | 0.2588 | 0.1951 | 2,103.72 | 1,150.57 | 20.39 |\n",
    "| **2) MLP + latitud/longitud**            | 0.9521 | 0.1833 | 0.1366 | 1,651.47 | 829.88 | 13.97 |\n",
    "| **3) MLP + latitud/longitud + VCR**      | 0.9540 | 0.1796 | 0.1283 | 1,642.30 | 791.70 | 13.63 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef65af",
   "metadata": {},
   "source": [
    "Análisis de resultados del MLP\n",
    "\n",
    "En el caso del modelo MLP, los resultados reflejan una progresión coherente con la tendencia general observada en los demás algoritmos, aunque con ciertas particularidades. El modelo base, entrenado únicamente con variables estructurales, logra un desempeño moderado con un R² de 0.90 y un MAPE cercano al 20%, lo que evidencia una capacidad predictiva razonable, pero aún limitada por la ausencia de información espacial. La incorporación de las coordenadas geográficas de latitud y longitud genera una mejora sustancial en la precisión del modelo, elevando el R² a 0.95 y reduciendo el MAPE a alrededor de 14%, con una clara reducción en los errores absolutos. Esta versión no solo ofrece un rendimiento competitivo, sino que además muestra un equilibrio adecuado entre ajuste y generalización, sin signos apreciables de sobreajuste entre los conjuntos de entrenamiento, validación y prueba.\n",
    "\n",
    "Por el contrario, al integrar los vectores de características de referencia (VCR), si bien se obtiene un R² ligeramente superior (0.954) y una leve mejora en los errores relativos, el modelo presenta indicios de sobreajuste: el rendimiento en entrenamiento mejora de forma marcada (R² = 0.97, MAPE = 10.1%), pero esta ganancia no se traduce proporcionalmente en los conjuntos de validación y prueba. Esto sugiere que el MLP logra capturar patrones locales en los datos enriquecidos con VCR, pero a costa de una menor capacidad de generalización. En consecuencia, puede concluirse que el modelo basado únicamente en coordenadas constituye la opción más equilibrada dentro de esta arquitectura: alcanza un rendimiento casi idéntico al del modelo con VCR, con menor complejidad, menor riesgo de sobreajuste y un coste computacional considerablemente inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92097e17",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
