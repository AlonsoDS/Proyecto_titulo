{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0266d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, math, random, re\n",
    "from typing import Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8599cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Hiperparámetros\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "SEED = 42\n",
    "N_TRIALS_FTT = 50          # presupuesto de búsqueda\n",
    "EPOCHS_TUNER = 20          # épocas por trial (rápido)\n",
    "ES_PATIENCE_TUNER = 6      # early stopping por trial\n",
    "MIN_DELTA_RMSE = 1e-4      # mejora mínima en RMSE_log\n",
    "SAVE_DIR = \"models_FTT\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c7eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dataset mínimo ----\n",
    "class NpDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "# ---- Modelo ----\n",
    "class NumericTokenizer(nn.Module):\n",
    "    def __init__(self, n_features: int, d_token: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(n_features, d_token))\n",
    "        self.bias = nn.Parameter(torch.zeros(n_features, d_token))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.unsqueeze(-1) * self.weight + self.bias\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, n_features: int, d_token: int, n_layers: int, n_head: int, ff_mult: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.tokenizer = NumericTokenizer(n_features, d_token)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_token))\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=d_token * ff_mult,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_token),\n",
    "            nn.Linear(d_token, d_token),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_token, 1),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B = x.size(0)\n",
    "        tokens = self.tokenizer(x)\n",
    "        cls = self.cls_token.expand(B, 1, -1)\n",
    "        x_tok = torch.cat([cls, tokens], dim=1)\n",
    "        x_enc = self.encoder(x_tok)\n",
    "        cls_out = x_enc[:, 0, :]\n",
    "        return self.head(cls_out).squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260b73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Objective Optuna (minimiza RMSE_log val) ----\n",
    "\n",
    "def objective_ftt(trial: optuna.Trial) -> float:\n",
    "    assert torch.cuda.is_available(), \"Se requiere GPU (CUDA).\"\n",
    "    device = torch.device(\"cuda\")\n",
    "    set_seed(SEED)\n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    d_token = trial.suggest_categorical(\"d_token\", [64, 96, 128, 192, 256])\n",
    "    # n_head debe dividir a d_token\n",
    "    valid_heads = [h for h in [4, 8] if d_token % h == 0]\n",
    "    n_head = trial.suggest_categorical(\"n_head\", valid_heads)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
    "    ff_mult  = trial.suggest_categorical(\"ff_mult\", [2, 4])\n",
    "    dropout  = trial.suggest_float(\"dropout\", 0.0, 0.3, step=0.1)\n",
    "\n",
    "    lr           = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size   = trial.suggest_categorical(\"batch_size\", [256, 512])# Retiro 1024 por limitacion de hardware\n",
    "\n",
    "    train_dl = DataLoader(NpDataset(X_train, y_train), batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_dl   = DataLoader(NpDataset(X_val,   y_val),   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    model = FTTransformer(n_features, d_token, n_layers, n_head, ff_mult, dropout).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_rmse = float(\"inf\")\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS_TUNER + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "        # validación (RMSE_log)\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dl:\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                pred = model(xb)\n",
    "                y_true.append(yb.numpy())\n",
    "                y_pred.append(pred.detach().cpu().numpy())\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        rmse_log = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "        trial.report(rmse_log, epoch)\n",
    "        if rmse_log + MIN_DELTA_RMSE < best_rmse:\n",
    "            best_rmse = rmse_log\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        if no_improve >= ES_PATIENCE_TUNER:\n",
    "            break\n",
    "\n",
    "    return best_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931cdff",
   "metadata": {},
   "source": [
    "### Hiperparametros para modelo FTT - base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb55f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_TAG = \"v1\"         # cambiar a v2/v3 según dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389407c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25211.000000\n",
       "mean         8.395828\n",
       "std          0.830310\n",
       "min          5.950643\n",
       "25%          7.740664\n",
       "50%          8.242756\n",
       "75%          8.984694\n",
       "max         10.915088\n",
       "Name: log_monto, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración básica del dataset\n",
    "df_vcr_c = pd.read_csv('dataset_vcr_compact.csv')\n",
    "df_vcr_c = df_vcr_c[df_vcr_c['monto'] < 56000].copy()\n",
    "df_vcr_c['log_monto']=np.log(df_vcr_c['monto'])\n",
    "df_vcr_c['log_monto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77b4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   monto                 25211 non-null  int64  \n",
      " 1   superficie_t          25211 non-null  float64\n",
      " 2   dormitorios           25211 non-null  int64  \n",
      " 3   dormitorios_faltante  25211 non-null  int64  \n",
      " 4   banos                 25211 non-null  int64  \n",
      " 5   banos_faltante        25211 non-null  int64  \n",
      " 6   antiguedad            25211 non-null  int64  \n",
      " 7   antiguedad_faltante   25211 non-null  int64  \n",
      " 8   Or_N                  25211 non-null  int64  \n",
      " 9   Or_S                  25211 non-null  int64  \n",
      " 10  Or_E                  25211 non-null  int64  \n",
      " 11  Or_O                  25211 non-null  int64  \n",
      " 12  Or_Faltante           25211 non-null  int64  \n",
      " 13  terraza               25211 non-null  float64\n",
      " 14  estacionamiento       25211 non-null  int64  \n",
      " 15  bodegas               25211 non-null  int64  \n",
      " 16  flag_Departamento     25211 non-null  int64  \n",
      " 17  flag_Multinivel       25211 non-null  int64  \n",
      " 18  flag_Semipiso         25211 non-null  int64  \n",
      " 19  flag_Premium          25211 non-null  int64  \n",
      " 20  flag_Monoambiente     25211 non-null  int64  \n",
      " 21  flag_Loft             25211 non-null  int64  \n",
      " 22  log_monto             25211 non-null  float64\n",
      "dtypes: float64(3), int64(20)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "#Configuración específica del modelo\n",
    "df_base =df_vcr_c.copy()\n",
    "obj_cols = df_base.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols) + [\"id\", \"latitud\", \"longitud\"]\n",
    "df_base = df_base.drop(columns=cols_to_drop)\n",
    "df_base.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10acbbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 21\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_base.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_base[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train) #(x - mean)/std. --> mean = 0, std = 1\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88b183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 20:51:28,517] A new study created in memory with name: no-name-358f83c3-47e3-40f8-85cc-20fb1069cacf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna FTT: iniciando búsqueda...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2818bea1ecf4ff3a4dcac5e8026879a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 20:52:05,482] Trial 0 finished with value: 0.26771169900894165 and parameters: {'d_token': 96, 'n_head': 4, 'n_layers': 4, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.002708160864249967, 'weight_decay': 0.0003142880890840109, 'batch_size': 256}. Best is trial 0 with value: 0.26771169900894165.\n",
      "[I 2025-10-08 20:52:28,702] Trial 1 finished with value: 0.3959355652332306 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.3, 'lr': 0.00019721610970574026, 'weight_decay': 3.489018845491386e-05, 'batch_size': 256}. Best is trial 0 with value: 0.26771169900894165.\n",
      "[I 2025-10-08 20:52:52,818] Trial 2 finished with value: 0.27249932289123535 and parameters: {'d_token': 256, 'n_head': 4, 'n_layers': 1, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.0005388108577817234, 'weight_decay': 1.2681352169084602e-06, 'batch_size': 256}. Best is trial 0 with value: 0.26771169900894165.\n",
      "[I 2025-10-08 20:53:20,566] Trial 3 finished with value: 0.41972628235816956 and parameters: {'d_token': 64, 'n_head': 4, 'n_layers': 4, 'ff_mult': 2, 'dropout': 0.3, 'lr': 0.00013511829476450826, 'weight_decay': 3.87211803217458e-06, 'batch_size': 512}. Best is trial 0 with value: 0.26771169900894165.\n",
      "[I 2025-10-08 20:54:05,183] Trial 4 finished with value: 0.29785841703414917 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 4, 'ff_mult': 4, 'dropout': 0.3, 'lr': 0.00019657448966046135, 'weight_decay': 1.0388823104027941e-06, 'batch_size': 256}. Best is trial 0 with value: 0.26771169900894165.\n",
      "[I 2025-10-08 20:54:10,619] Trial 5 pruned. \n",
      "[I 2025-10-08 20:54:48,889] Trial 6 finished with value: 0.262133926153183 and parameters: {'d_token': 256, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.00087107459004924, 'weight_decay': 8.771380343280564e-06, 'batch_size': 512}. Best is trial 6 with value: 0.262133926153183.\n",
      "[I 2025-10-08 20:55:17,658] Trial 7 finished with value: 0.29846513271331787 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 4, 'ff_mult': 2, 'dropout': 0.3, 'lr': 0.0015385836272714033, 'weight_decay': 3.6283583803549183e-06, 'batch_size': 256}. Best is trial 6 with value: 0.262133926153183.\n",
      "[I 2025-10-08 20:55:19,627] Trial 8 pruned. \n",
      "[I 2025-10-08 20:55:25,906] Trial 9 pruned. \n",
      "[I 2025-10-08 20:55:26,916] Trial 10 pruned. \n",
      "[I 2025-10-08 20:55:29,946] Trial 11 pruned. \n",
      "[I 2025-10-08 20:55:36,209] Trial 12 pruned. \n",
      "[I 2025-10-08 20:55:44,688] Trial 13 pruned. \n",
      "[I 2025-10-08 20:55:46,150] Trial 14 pruned. \n",
      "[I 2025-10-08 20:55:51,712] Trial 15 pruned. \n",
      "[I 2025-10-08 20:56:16,363] Trial 16 finished with value: 0.26682621240615845 and parameters: {'d_token': 96, 'n_head': 8, 'n_layers': 1, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0008888871876310568, 'weight_decay': 0.0008607021623812326, 'batch_size': 256}. Best is trial 6 with value: 0.262133926153183.\n",
      "[I 2025-10-08 20:56:17,603] Trial 17 pruned. \n",
      "[I 2025-10-08 20:56:19,013] Trial 18 pruned. \n",
      "[I 2025-10-08 20:56:20,078] Trial 19 pruned. \n",
      "[I 2025-10-08 20:56:21,717] Trial 20 pruned. \n",
      "[I 2025-10-08 20:56:27,502] Trial 21 pruned. \n",
      "[I 2025-10-08 20:57:04,808] Trial 22 finished with value: 0.2658722698688507 and parameters: {'d_token': 96, 'n_head': 8, 'n_layers': 3, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0019745627668684104, 'weight_decay': 0.0004192324803088369, 'batch_size': 256}. Best is trial 6 with value: 0.262133926153183.\n",
      "[I 2025-10-08 20:57:06,710] Trial 23 pruned. \n",
      "[I 2025-10-08 20:57:08,559] Trial 24 pruned. \n",
      "[I 2025-10-08 20:57:11,354] Trial 25 pruned. \n",
      "[I 2025-10-08 20:57:12,778] Trial 26 pruned. \n",
      "[I 2025-10-08 20:57:14,632] Trial 27 pruned. \n",
      "[I 2025-10-08 20:57:16,638] Trial 28 pruned. \n",
      "[I 2025-10-08 20:57:18,661] Trial 29 pruned. \n",
      "[I 2025-10-08 20:57:51,999] Trial 30 finished with value: 0.26073914766311646 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0023421523553817177, 'weight_decay': 0.00020418867207987754, 'batch_size': 256}. Best is trial 30 with value: 0.26073914766311646.\n",
      "[I 2025-10-08 20:58:22,278] Trial 31 finished with value: 0.26073604822158813 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0023542304052727426, 'weight_decay': 0.00019863185063660383, 'batch_size': 256}. Best is trial 31 with value: 0.26073604822158813.\n",
      "[I 2025-10-08 20:58:52,134] Trial 32 finished with value: 0.26075246930122375 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0023557522471542337, 'weight_decay': 0.0001854542255958905, 'batch_size': 256}. Best is trial 31 with value: 0.26073604822158813.\n",
      "[I 2025-10-08 20:59:25,400] Trial 33 finished with value: 0.2602390646934509 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.002447175334832958, 'weight_decay': 0.00015112885335772627, 'batch_size': 256}. Best is trial 33 with value: 0.2602390646934509.\n",
      "[I 2025-10-08 20:59:58,251] Trial 34 finished with value: 0.2598692774772644 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0024754952364052308, 'weight_decay': 0.00016707671253778666, 'batch_size': 256}. Best is trial 34 with value: 0.2598692774772644.\n",
      "[I 2025-10-08 21:00:01,320] Trial 35 pruned. \n",
      "[I 2025-10-08 21:00:02,826] Trial 36 pruned. \n",
      "[I 2025-10-08 21:00:04,202] Trial 37 pruned. \n",
      "[I 2025-10-08 21:00:05,662] Trial 38 pruned. \n",
      "[I 2025-10-08 21:00:07,011] Trial 39 pruned. \n",
      "[I 2025-10-08 21:00:38,310] Trial 40 finished with value: 0.2597314417362213 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.002508396992707987, 'weight_decay': 0.00015100751184240444, 'batch_size': 256}. Best is trial 40 with value: 0.2597314417362213.\n",
      "[I 2025-10-08 21:01:07,952] Trial 41 finished with value: 0.26021668314933777 and parameters: {'d_token': 64, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.0024028044276387375, 'weight_decay': 0.00012780246537350695, 'batch_size': 256}. Best is trial 40 with value: 0.2597314417362213.\n",
      "[I 2025-10-08 21:01:15,795] Trial 42 pruned. \n",
      "[I 2025-10-08 21:01:22,326] Trial 43 pruned. \n",
      "[I 2025-10-08 21:01:30,199] Trial 44 pruned. \n",
      "[I 2025-10-08 21:01:31,878] Trial 45 pruned. \n",
      "[I 2025-10-08 21:01:33,555] Trial 46 pruned. \n",
      "[I 2025-10-08 21:01:35,626] Trial 47 pruned. \n",
      "[I 2025-10-08 21:01:40,274] Trial 48 pruned. \n",
      "[I 2025-10-08 21:01:42,120] Trial 49 pruned. \n",
      "\n",
      "Mejores HP FTT Base (val RMSE_log ↓):\n",
      " {\n",
      "  \"d_token\": 64,\n",
      "  \"n_head\": 8,\n",
      "  \"n_layers\": 2,\n",
      "  \"ff_mult\": 4,\n",
      "  \"dropout\": 0.0,\n",
      "  \"lr\": 0.002508396992707987,\n",
      "  \"weight_decay\": 0.00015100751184240444,\n",
      "  \"batch_size\": 256\n",
      "}\n",
      "Guardado: models_FTT\\best_params_FTT_v1.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Ejecutar estudio y exportar HP ----\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED), pruner=MedianPruner(n_startup_trials=5))\n",
    "print(\"Optuna FTT: iniciando búsqueda...\")\n",
    "study.optimize(objective_ftt, n_trials=N_TRIALS_FTT, show_progress_bar=True)\n",
    "\n",
    "best = study.best_trial\n",
    "best_params_FTT = {\n",
    "    \"d_token\": best.params[\"d_token\"],\n",
    "    \"n_head\": best.params[\"n_head\"],\n",
    "    \"n_layers\": best.params[\"n_layers\"],\n",
    "    \"ff_mult\": best.params[\"ff_mult\"],\n",
    "    \"dropout\": best.params[\"dropout\"],\n",
    "    \"lr\": best.params[\"lr\"],\n",
    "    \"weight_decay\": best.params[\"weight_decay\"],\n",
    "    \"batch_size\": best.params[\"batch_size\"],\n",
    "}\n",
    "print(\"\\nMejores HP FTT Base (val RMSE_log ↓):\\n\", json.dumps(best_params_FTT, indent=2))\n",
    "\n",
    "hp_path = os.path.join(SAVE_DIR, f\"best_params_FTT_{VERSION_TAG}.json\")\n",
    "with open(hp_path, \"w\") as f:\n",
    "    json.dump(best_params_FTT, f, indent=2)\n",
    "print(f\"Guardado: {hp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8401c8f",
   "metadata": {},
   "source": [
    "### Hiperparametros para modelo FTT - Coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269a4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_TAG = \"v2\"         # cambiar a v2/v3 según dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf17b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   monto                 25211 non-null  int64  \n",
      " 1   superficie_t          25211 non-null  float64\n",
      " 2   dormitorios           25211 non-null  int64  \n",
      " 3   dormitorios_faltante  25211 non-null  int64  \n",
      " 4   banos                 25211 non-null  int64  \n",
      " 5   banos_faltante        25211 non-null  int64  \n",
      " 6   antiguedad            25211 non-null  int64  \n",
      " 7   antiguedad_faltante   25211 non-null  int64  \n",
      " 8   Or_N                  25211 non-null  int64  \n",
      " 9   Or_S                  25211 non-null  int64  \n",
      " 10  Or_E                  25211 non-null  int64  \n",
      " 11  Or_O                  25211 non-null  int64  \n",
      " 12  Or_Faltante           25211 non-null  int64  \n",
      " 13  terraza               25211 non-null  float64\n",
      " 14  estacionamiento       25211 non-null  int64  \n",
      " 15  bodegas               25211 non-null  int64  \n",
      " 16  flag_Departamento     25211 non-null  int64  \n",
      " 17  flag_Multinivel       25211 non-null  int64  \n",
      " 18  flag_Semipiso         25211 non-null  int64  \n",
      " 19  flag_Premium          25211 non-null  int64  \n",
      " 20  flag_Monoambiente     25211 non-null  int64  \n",
      " 21  flag_Loft             25211 non-null  int64  \n",
      " 22  latitud               25211 non-null  float64\n",
      " 23  longitud              25211 non-null  float64\n",
      " 24  log_monto             25211 non-null  float64\n",
      "dtypes: float64(5), int64(20)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "#Configuración específica del modelo\n",
    "df_coord =df_vcr_c.copy()\n",
    "obj_cols = df_coord.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols)\n",
    "cols_to_drop.append(\"id\")\n",
    "df_coord = df_coord.drop(columns=cols_to_drop)\n",
    "df_coord.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61782008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 23\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_coord.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_coord[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train) #(x - mean)/std. --> mean = 0, std = 1\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02bf1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 21:02:31,147] A new study created in memory with name: no-name-8b6a1155-ad00-4f1e-b399-b2d302fb4a3d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna FTT: iniciando búsqueda...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae008edab5724623947cf69695970a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 21:03:07,992] Trial 0 finished with value: 0.19666080176830292 and parameters: {'d_token': 96, 'n_head': 4, 'n_layers': 4, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.002708160864249967, 'weight_decay': 0.0003142880890840109, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:03:32,549] Trial 1 finished with value: 0.43681782484054565 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.3, 'lr': 0.00019721610970574026, 'weight_decay': 3.489018845491386e-05, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:03:57,465] Trial 2 finished with value: 0.20989729464054108 and parameters: {'d_token': 256, 'n_head': 4, 'n_layers': 1, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.0005388108577817234, 'weight_decay': 1.2681352169084602e-06, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:04:27,109] Trial 3 finished with value: 0.34386202692985535 and parameters: {'d_token': 64, 'n_head': 4, 'n_layers': 4, 'ff_mult': 2, 'dropout': 0.3, 'lr': 0.00013511829476450826, 'weight_decay': 3.87211803217458e-06, 'batch_size': 512}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:05:17,086] Trial 4 finished with value: 0.2568340599536896 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 4, 'ff_mult': 4, 'dropout': 0.3, 'lr': 0.00019657448966046135, 'weight_decay': 1.0388823104027941e-06, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:05:32,918] Trial 5 finished with value: 0.2697054147720337 and parameters: {'d_token': 96, 'n_head': 4, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.1, 'lr': 0.001195960383019184, 'weight_decay': 8.178476574339548e-05, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:06:08,787] Trial 6 finished with value: 0.2100711464881897 and parameters: {'d_token': 256, 'n_head': 8, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.00087107459004924, 'weight_decay': 8.771380343280564e-06, 'batch_size': 512}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:06:46,579] Trial 7 finished with value: 0.22837847471237183 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 4, 'ff_mult': 2, 'dropout': 0.3, 'lr': 0.0015385836272714033, 'weight_decay': 3.6283583803549183e-06, 'batch_size': 256}. Best is trial 0 with value: 0.19666080176830292.\n",
      "[I 2025-10-08 21:06:48,348] Trial 8 pruned. \n",
      "[I 2025-10-08 21:06:55,740] Trial 9 pruned. \n",
      "[I 2025-10-08 21:07:07,797] Trial 10 pruned. \n",
      "[I 2025-10-08 21:07:08,724] Trial 11 pruned. \n",
      "[I 2025-10-08 21:07:13,635] Trial 12 pruned. \n",
      "[I 2025-10-08 21:08:02,073] Trial 13 finished with value: 0.1954887956380844 and parameters: {'d_token': 192, 'n_head': 4, 'n_layers': 3, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.00047246527645281505, 'weight_decay': 0.0009956055660659028, 'batch_size': 256}. Best is trial 13 with value: 0.1954887956380844.\n",
      "[I 2025-10-08 21:08:08,283] Trial 14 pruned. \n",
      "[I 2025-10-08 21:08:59,089] Trial 15 finished with value: 0.21490441262722015 and parameters: {'d_token': 192, 'n_head': 4, 'n_layers': 3, 'ff_mult': 2, 'dropout': 0.1, 'lr': 0.00037035354010418097, 'weight_decay': 0.0003299955216027679, 'batch_size': 256}. Best is trial 13 with value: 0.1954887956380844.\n",
      "[I 2025-10-08 21:09:01,030] Trial 16 pruned. \n",
      "[I 2025-10-08 21:09:07,495] Trial 17 pruned. \n",
      "[I 2025-10-08 21:09:09,371] Trial 18 pruned. \n",
      "[I 2025-10-08 21:09:15,925] Trial 19 pruned. \n",
      "[I 2025-10-08 21:09:17,936] Trial 20 pruned. \n",
      "[I 2025-10-08 21:09:28,483] Trial 21 pruned. \n",
      "[I 2025-10-08 21:09:58,618] Trial 22 finished with value: 0.20887218415737152 and parameters: {'d_token': 256, 'n_head': 4, 'n_layers': 2, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.0006636020410087645, 'weight_decay': 1.9067594876368443e-05, 'batch_size': 256}. Best is trial 13 with value: 0.1954887956380844.\n",
      "[I 2025-10-08 21:10:01,494] Trial 23 pruned. \n",
      "[I 2025-10-08 21:10:31,438] Trial 24 finished with value: 0.21418489515781403 and parameters: {'d_token': 256, 'n_head': 4, 'n_layers': 2, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.0011883834866827832, 'weight_decay': 4.8091559431113986e-05, 'batch_size': 256}. Best is trial 13 with value: 0.1954887956380844.\n",
      "[I 2025-10-08 21:10:34,932] Trial 25 pruned. \n",
      "[I 2025-10-08 21:10:36,474] Trial 26 pruned. \n",
      "[I 2025-10-08 21:10:38,314] Trial 27 pruned. \n",
      "[I 2025-10-08 21:10:41,568] Trial 28 pruned. \n",
      "[I 2025-10-08 21:10:43,079] Trial 29 pruned. \n",
      "[I 2025-10-08 21:10:48,735] Trial 30 pruned. \n",
      "[I 2025-10-08 21:10:53,902] Trial 31 pruned. \n",
      "[I 2025-10-08 21:11:02,870] Trial 32 pruned. \n",
      "[I 2025-10-08 21:11:07,924] Trial 33 pruned. \n",
      "[I 2025-10-08 21:11:10,121] Trial 34 pruned. \n",
      "[I 2025-10-08 21:11:11,203] Trial 35 pruned. \n",
      "[I 2025-10-08 21:11:12,640] Trial 36 pruned. \n",
      "[I 2025-10-08 21:11:20,136] Trial 37 pruned. \n",
      "[I 2025-10-08 21:11:21,218] Trial 38 pruned. \n",
      "[I 2025-10-08 21:11:22,707] Trial 39 pruned. \n",
      "[I 2025-10-08 21:11:24,910] Trial 40 pruned. \n",
      "[I 2025-10-08 21:11:27,418] Trial 41 pruned. \n",
      "[I 2025-10-08 21:11:31,965] Trial 42 pruned. \n",
      "[I 2025-10-08 21:11:33,640] Trial 43 pruned. \n",
      "[I 2025-10-08 21:11:37,913] Trial 44 pruned. \n",
      "[I 2025-10-08 21:11:40,229] Trial 45 pruned. \n",
      "[I 2025-10-08 21:11:41,007] Trial 46 pruned. \n",
      "[I 2025-10-08 21:11:45,555] Trial 47 pruned. \n",
      "[I 2025-10-08 21:12:32,296] Trial 48 finished with value: 0.213859423995018 and parameters: {'d_token': 192, 'n_head': 8, 'n_layers': 3, 'ff_mult': 2, 'dropout': 0.1, 'lr': 0.00025103184613780465, 'weight_decay': 6.351487284008714e-05, 'batch_size': 256}. Best is trial 13 with value: 0.1954887956380844.\n",
      "[I 2025-10-08 21:12:34,160] Trial 49 pruned. \n",
      "\n",
      "Mejores HP FTT Coordenadas (val RMSE_log ↓):\n",
      " {\n",
      "  \"d_token\": 192,\n",
      "  \"n_head\": 4,\n",
      "  \"n_layers\": 3,\n",
      "  \"ff_mult\": 2,\n",
      "  \"dropout\": 0.0,\n",
      "  \"lr\": 0.00047246527645281505,\n",
      "  \"weight_decay\": 0.0009956055660659028,\n",
      "  \"batch_size\": 256\n",
      "}\n",
      "Guardado: models_FTT\\best_params_FTT_v2.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Ejecutar estudio y exportar HP ----\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED), pruner=MedianPruner(n_startup_trials=5))\n",
    "print(\"Optuna FTT: iniciando búsqueda...\")\n",
    "study.optimize(objective_ftt, n_trials=N_TRIALS_FTT, show_progress_bar=True)\n",
    "\n",
    "best = study.best_trial\n",
    "best_params_FTT = {\n",
    "    \"d_token\": best.params[\"d_token\"],\n",
    "    \"n_head\": best.params[\"n_head\"],\n",
    "    \"n_layers\": best.params[\"n_layers\"],\n",
    "    \"ff_mult\": best.params[\"ff_mult\"],\n",
    "    \"dropout\": best.params[\"dropout\"],\n",
    "    \"lr\": best.params[\"lr\"],\n",
    "    \"weight_decay\": best.params[\"weight_decay\"],\n",
    "    \"batch_size\": best.params[\"batch_size\"],\n",
    "}\n",
    "print(\"\\nMejores HP FTT Coordenadas (val RMSE_log ↓):\\n\", json.dumps(best_params_FTT, indent=2))\n",
    "\n",
    "hp_path = os.path.join(SAVE_DIR, f\"best_params_FTT_{VERSION_TAG}.json\")\n",
    "with open(hp_path, \"w\") as f:\n",
    "    json.dump(best_params_FTT, f, indent=2)\n",
    "print(f\"Guardado: {hp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb77d7",
   "metadata": {},
   "source": [
    "### Hiperparametros para modelo FTT - Coordenadas y VCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c35be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_TAG = \"v3\"         # cambiar a v2/v3 según dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6bd61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25211.000000\n",
       "mean         8.395828\n",
       "std          0.830310\n",
       "min          5.950643\n",
       "25%          7.740664\n",
       "50%          8.242756\n",
       "75%          8.984694\n",
       "max         10.915088\n",
       "Name: log_monto, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vcr_e = pd.read_csv('dataset_vcr_expanded.csv')\n",
    "df_vcr_e = df_vcr_e[df_vcr_e['monto'] < 56000].copy()\n",
    "df_vcr_e['log_monto']=np.log(df_vcr_e['monto'])\n",
    "df_vcr_e['log_monto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c4b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Data columns (total 181 columns):\n",
      " #    Column                        Dtype  \n",
      "---   ------                        -----  \n",
      " 0    monto                         int64  \n",
      " 1    superficie_t                  float64\n",
      " 2    dormitorios                   int64  \n",
      " 3    dormitorios_faltante          int64  \n",
      " 4    banos                         int64  \n",
      " 5    banos_faltante                int64  \n",
      " 6    antiguedad                    int64  \n",
      " 7    antiguedad_faltante           int64  \n",
      " 8    Or_N                          int64  \n",
      " 9    Or_S                          int64  \n",
      " 10   Or_E                          int64  \n",
      " 11   Or_O                          int64  \n",
      " 12   Or_Faltante                   int64  \n",
      " 13   terraza                       float64\n",
      " 14   estacionamiento               int64  \n",
      " 15   bodegas                       int64  \n",
      " 16   flag_Departamento             int64  \n",
      " 17   flag_Multinivel               int64  \n",
      " 18   flag_Semipiso                 int64  \n",
      " 19   flag_Premium                  int64  \n",
      " 20   flag_Monoambiente             int64  \n",
      " 21   flag_Loft                     int64  \n",
      " 22   latitud                       float64\n",
      " 23   longitud                      float64\n",
      " 24   sport_and_leisure_dim00       float64\n",
      " 25   sport_and_leisure_dim01       float64\n",
      " 26   sport_and_leisure_dim02       float64\n",
      " 27   sport_and_leisure_dim03       float64\n",
      " 28   sport_and_leisure_dim04       float64\n",
      " 29   sport_and_leisure_dim05       float64\n",
      " 30   sport_and_leisure_dim06       float64\n",
      " 31   sport_and_leisure_dim07       float64\n",
      " 32   sport_and_leisure_dim08       float64\n",
      " 33   sport_and_leisure_dim09       float64\n",
      " 34   sport_and_leisure_dim10       float64\n",
      " 35   sport_and_leisure_dim11       float64\n",
      " 36   medical_dim00                 float64\n",
      " 37   medical_dim01                 float64\n",
      " 38   medical_dim02                 float64\n",
      " 39   medical_dim03                 float64\n",
      " 40   medical_dim04                 float64\n",
      " 41   medical_dim05                 float64\n",
      " 42   medical_dim06                 float64\n",
      " 43   medical_dim07                 float64\n",
      " 44   medical_dim08                 float64\n",
      " 45   medical_dim09                 float64\n",
      " 46   medical_dim10                 float64\n",
      " 47   medical_dim11                 float64\n",
      " 48   education_prim_dim00          float64\n",
      " 49   education_prim_dim01          float64\n",
      " 50   education_prim_dim02          float64\n",
      " 51   education_prim_dim03          float64\n",
      " 52   education_prim_dim04          float64\n",
      " 53   education_prim_dim05          float64\n",
      " 54   education_prim_dim06          float64\n",
      " 55   education_prim_dim07          float64\n",
      " 56   education_prim_dim08          float64\n",
      " 57   education_prim_dim09          float64\n",
      " 58   education_prim_dim10          float64\n",
      " 59   education_prim_dim11          float64\n",
      " 60   veterinary_dim00              float64\n",
      " 61   veterinary_dim01              float64\n",
      " 62   veterinary_dim02              float64\n",
      " 63   veterinary_dim03              float64\n",
      " 64   veterinary_dim04              float64\n",
      " 65   veterinary_dim05              float64\n",
      " 66   veterinary_dim06              float64\n",
      " 67   veterinary_dim07              float64\n",
      " 68   veterinary_dim08              float64\n",
      " 69   veterinary_dim09              float64\n",
      " 70   veterinary_dim10              float64\n",
      " 71   veterinary_dim11              float64\n",
      " 72   food_and_drink_stores_dim00   float64\n",
      " 73   food_and_drink_stores_dim01   float64\n",
      " 74   food_and_drink_stores_dim02   float64\n",
      " 75   food_and_drink_stores_dim03   float64\n",
      " 76   food_and_drink_stores_dim04   float64\n",
      " 77   food_and_drink_stores_dim05   float64\n",
      " 78   food_and_drink_stores_dim06   float64\n",
      " 79   food_and_drink_stores_dim07   float64\n",
      " 80   food_and_drink_stores_dim08   float64\n",
      " 81   food_and_drink_stores_dim09   float64\n",
      " 82   food_and_drink_stores_dim10   float64\n",
      " 83   food_and_drink_stores_dim11   float64\n",
      " 84   arts_and_entertainment_dim00  float64\n",
      " 85   arts_and_entertainment_dim01  float64\n",
      " 86   arts_and_entertainment_dim02  float64\n",
      " 87   arts_and_entertainment_dim03  float64\n",
      " 88   arts_and_entertainment_dim04  float64\n",
      " 89   arts_and_entertainment_dim05  float64\n",
      " 90   arts_and_entertainment_dim06  float64\n",
      " 91   arts_and_entertainment_dim07  float64\n",
      " 92   arts_and_entertainment_dim08  float64\n",
      " 93   arts_and_entertainment_dim09  float64\n",
      " 94   arts_and_entertainment_dim10  float64\n",
      " 95   arts_and_entertainment_dim11  float64\n",
      " 96   food_and_drink_dim00          float64\n",
      " 97   food_and_drink_dim01          float64\n",
      " 98   food_and_drink_dim02          float64\n",
      " 99   food_and_drink_dim03          float64\n",
      " 100  food_and_drink_dim04          float64\n",
      " 101  food_and_drink_dim05          float64\n",
      " 102  food_and_drink_dim06          float64\n",
      " 103  food_and_drink_dim07          float64\n",
      " 104  food_and_drink_dim08          float64\n",
      " 105  food_and_drink_dim09          float64\n",
      " 106  food_and_drink_dim10          float64\n",
      " 107  food_and_drink_dim11          float64\n",
      " 108  park_like_dim00               float64\n",
      " 109  park_like_dim01               float64\n",
      " 110  park_like_dim02               float64\n",
      " 111  park_like_dim03               float64\n",
      " 112  park_like_dim04               float64\n",
      " 113  park_like_dim05               float64\n",
      " 114  park_like_dim06               float64\n",
      " 115  park_like_dim07               float64\n",
      " 116  park_like_dim08               float64\n",
      " 117  park_like_dim09               float64\n",
      " 118  park_like_dim10               float64\n",
      " 119  park_like_dim11               float64\n",
      " 120  security_dim00                float64\n",
      " 121  security_dim01                float64\n",
      " 122  security_dim02                float64\n",
      " 123  security_dim03                float64\n",
      " 124  security_dim04                float64\n",
      " 125  security_dim05                float64\n",
      " 126  security_dim06                float64\n",
      " 127  security_dim07                float64\n",
      " 128  security_dim08                float64\n",
      " 129  security_dim09                float64\n",
      " 130  security_dim10                float64\n",
      " 131  security_dim11                float64\n",
      " 132  religion_dim00                float64\n",
      " 133  religion_dim01                float64\n",
      " 134  religion_dim02                float64\n",
      " 135  religion_dim03                float64\n",
      " 136  religion_dim04                float64\n",
      " 137  religion_dim05                float64\n",
      " 138  religion_dim06                float64\n",
      " 139  religion_dim07                float64\n",
      " 140  religion_dim08                float64\n",
      " 141  religion_dim09                float64\n",
      " 142  religion_dim10                float64\n",
      " 143  religion_dim11                float64\n",
      " 144  education_sup_dim00           float64\n",
      " 145  education_sup_dim01           float64\n",
      " 146  education_sup_dim02           float64\n",
      " 147  education_sup_dim03           float64\n",
      " 148  education_sup_dim04           float64\n",
      " 149  education_sup_dim05           float64\n",
      " 150  education_sup_dim06           float64\n",
      " 151  education_sup_dim07           float64\n",
      " 152  education_sup_dim08           float64\n",
      " 153  education_sup_dim09           float64\n",
      " 154  education_sup_dim10           float64\n",
      " 155  education_sup_dim11           float64\n",
      " 156  metro_dim00                   float64\n",
      " 157  metro_dim01                   float64\n",
      " 158  metro_dim02                   float64\n",
      " 159  metro_dim03                   float64\n",
      " 160  metro_dim04                   float64\n",
      " 161  metro_dim05                   float64\n",
      " 162  metro_dim06                   float64\n",
      " 163  metro_dim07                   float64\n",
      " 164  metro_dim08                   float64\n",
      " 165  metro_dim09                   float64\n",
      " 166  metro_dim10                   float64\n",
      " 167  metro_dim11                   float64\n",
      " 168  bus_dim00                     float64\n",
      " 169  bus_dim01                     float64\n",
      " 170  bus_dim02                     float64\n",
      " 171  bus_dim03                     float64\n",
      " 172  bus_dim04                     float64\n",
      " 173  bus_dim05                     float64\n",
      " 174  bus_dim06                     float64\n",
      " 175  bus_dim07                     float64\n",
      " 176  bus_dim08                     float64\n",
      " 177  bus_dim09                     float64\n",
      " 178  bus_dim10                     float64\n",
      " 179  bus_dim11                     float64\n",
      " 180  log_monto                     float64\n",
      "dtypes: float64(161), int64(20)\n",
      "memory usage: 35.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_vcr =df_vcr_e.copy()\n",
    "obj_cols = df_vcr.select_dtypes(include=[\"object\"]).columns\n",
    "cols_to_drop = list(obj_cols)\n",
    "cols_to_drop.append(\"id\")\n",
    "df_vcr = df_vcr.drop(columns=cols_to_drop)\n",
    "df_vcr.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d162efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputación VCR completada. NaNs antes: 246,228 -> después: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25211 entries, 0 to 25214\n",
      "Columns: 194 entries, monto to has_bus\n",
      "dtypes: float64(161), int64(33)\n",
      "memory usage: 37.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Imputación datos faltantes en VCR\n",
    "# Dimensiones (1..12) \n",
    "DIMS_MAP = {\n",
    "    1: \"count_pois\",\n",
    "    2: \"mean_distance\",\n",
    "    3: \"min_distance\",\n",
    "    4: \"max_distance\",\n",
    "    5: \"median_distance\",\n",
    "    6: \"std_distance\",\n",
    "    7: \"mean_inverse_distance\",\n",
    "    8: \"max_inverse_distance\",\n",
    "    9: \"sum_inverse_distance\",\n",
    "    10: \"ratio_within_near_radius\",\n",
    "    11: \"ratio_within_mid_radius\",\n",
    "    12: \"ratio_within_far_radius\",\n",
    "}\n",
    "\n",
    "# Rol por dimensión (para decidir la imputación semántica)\n",
    "DIM_ROLE = {\n",
    "    1: \"count\",                # -> 0\n",
    "    2: \"distance\",             # -> R3\n",
    "    3: \"distance\",             # -> R3\n",
    "    4: \"distance\",             # -> R3\n",
    "    5: \"distance\",             # -> R3\n",
    "    6: \"std\",                  # -> 0\n",
    "    7: \"inverse\",              # -> 0\n",
    "    8: \"inverse\",              # -> 0\n",
    "    9: \"inverse\",              # -> 0\n",
    "    10: \"ratio\",               # -> 0\n",
    "    11: \"ratio\",               # -> 0\n",
    "    12: \"ratio\",               # -> 0\n",
    "}\n",
    "\n",
    "# R3 por tipo de clase\n",
    "R3_DEFAULT = 2400.0  # clases generales\n",
    "R3_METRO = 1600.0\n",
    "R3_BUS = 800.0\n",
    "\n",
    "# Funciones\n",
    "def _class_and_dim(col: str) -> Optional[Tuple[str, int]]:\n",
    "    \"\"\"Extrae (clase, índice de dimensión) de columnas tipo '<clase>_dimXX'.\"\"\"\n",
    "    m = re.match(r\"^(?P<klass>.+)_dim(?P<idx>\\d{1,2})$\", col)\n",
    "    if not m:\n",
    "        return None\n",
    "    return m.group(\"klass\"), int(m.group(\"idx\"))\n",
    "\n",
    "\n",
    "def _r3_for_class(klass: str) -> float:\n",
    "    k = klass.lower()\n",
    "    if \"metro\" in k:\n",
    "        return R3_METRO\n",
    "    if \"bus\" in k:\n",
    "        return R3_BUS\n",
    "    return R3_DEFAULT\n",
    "\n",
    "\n",
    "def impute_vcr_semantic(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Imputa VCR por semántica de ausencia: distancias=R3, inversas/ratios=0, count=0, std=0.\n",
    "    Además agrega flags `has_<clase>` indicando presencia de POIs por clase.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Agrupar columnas por clase\n",
    "    groups: Dict[str, Dict[int, str]] = {}\n",
    "    vcr_cols = []\n",
    "    for c in out.columns:\n",
    "        parsed = _class_and_dim(c)\n",
    "        if parsed is None:\n",
    "            continue\n",
    "        klass, idx = parsed\n",
    "        groups.setdefault(klass, {})[idx] = c\n",
    "        vcr_cols.append(c)\n",
    "\n",
    "    if not groups:\n",
    "        # Nada que imputar\n",
    "        return out\n",
    "\n",
    "    # Flags de presencia por clase (antes de imputar)\n",
    "    for klass, dim_map in groups.items():\n",
    "        cols = list(dim_map.values())\n",
    "        has_series = out[cols].notna().any(axis=1).astype(\"int64\")\n",
    "        out[f\"has_{klass}\"] = has_series  # por qué: distingue ausencia real vs lejanía\n",
    "\n",
    "    # Imputación por clase/dim\n",
    "    n_total_nans = int(out[vcr_cols].isna().sum().sum())\n",
    "    for klass, dim_map in groups.items():\n",
    "        r3 = _r3_for_class(klass)\n",
    "        for idx, col in dim_map.items():\n",
    "            role = DIM_ROLE.get(idx)\n",
    "            if role == \"distance\":\n",
    "                fill_value = r3\n",
    "            elif role in {\"inverse\", \"ratio\", \"std\", \"count\"}:\n",
    "                fill_value = 0.0\n",
    "            else:\n",
    "                # Si hay una dimensión desconocida, ser conservador con 0.0\n",
    "                fill_value = 0.0\n",
    "            out[col] = out[col].fillna(fill_value)\n",
    "\n",
    "    n_after_nans = int(out[vcr_cols].isna().sum().sum())\n",
    "    print(f\"Imputación VCR completada. NaNs antes: {n_total_nans:,d} -> después: {n_after_nans:,d}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "df_vcr_imp = impute_vcr_semantic(df_vcr)\n",
    "df_vcr_imp.info()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df258e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 192\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_df = df_vcr_imp.drop(columns=[\"monto\", \"log_monto\"]).copy()\n",
    "y = df_vcr_imp[\"log_monto\"].values.astype(np.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train).astype(np.float32)\n",
    "X_val = scaler.transform(X_val).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"n_features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed8dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:39:34,493] A new study created in memory with name: no-name-b3677ee5-d1a1-4452-a87c-94ffc7ae4a94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna FTT: iniciando búsqueda...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d415ef5abc40d7bc6ae833bcf64597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:43:07,553] Trial 0 finished with value: 0.18795368075370789 and parameters: {'d_token': 96, 'n_head': 4, 'n_layers': 4, 'ff_mult': 4, 'dropout': 0.0, 'lr': 0.002708160864249967, 'weight_decay': 0.0003142880890840109, 'batch_size': 256}. Best is trial 0 with value: 0.18795368075370789.\n",
      "[I 2025-10-09 16:45:27,241] Trial 1 finished with value: 0.3773398697376251 and parameters: {'d_token': 128, 'n_head': 4, 'n_layers': 2, 'ff_mult': 4, 'dropout': 0.3, 'lr': 0.00019721610970574026, 'weight_decay': 3.489018845491386e-05, 'batch_size': 256}. Best is trial 0 with value: 0.18795368075370789.\n",
      "[W 2025-10-09 16:46:15,033] Trial 2 failed with parameters: {'d_token': 256, 'n_head': 4, 'n_layers': 1, 'ff_mult': 2, 'dropout': 0.0, 'lr': 0.0005388108577817234, 'weight_decay': 1.2681352169084602e-06, 'batch_size': 256} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Pc-ADS\\AppData\\Local\\Temp\\ipykernel_19124\\285784970.py\", line 42, in objective_ftt\n",
      "    scaler.step(opt)\n",
      "  File \"c:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 341, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"c:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 287, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"c:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\", line 287, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-09 16:46:15,043] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mSEED), pruner\u001b[38;5;241m=\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptuna FTT: iniciando búsqueda...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_ftt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS_FTT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m best \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[0;32m      7\u001b[0m best_params_FTT \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: best\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_token\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: best\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: best\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     16\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m, in \u001b[0;36mobjective_ftt\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     40\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, yb)\n\u001b[0;32m     41\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 42\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# validación (RMSE_log)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:341\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 341\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    343\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:287\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    286\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    288\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\Pc-ADS\\.conda\\envs\\tf\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:287\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    286\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    288\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---- Ejecutar estudio y exportar HP ----\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED), pruner=MedianPruner(n_startup_trials=5))\n",
    "print(\"Optuna FTT: iniciando búsqueda...\")\n",
    "study.optimize(objective_ftt, n_trials=N_TRIALS_FTT, show_progress_bar=True)\n",
    "\n",
    "best = study.best_trial\n",
    "best_params_FTT = {\n",
    "    \"d_token\": best.params[\"d_token\"],\n",
    "    \"n_head\": best.params[\"n_head\"],\n",
    "    \"n_layers\": best.params[\"n_layers\"],\n",
    "    \"ff_mult\": best.params[\"ff_mult\"],\n",
    "    \"dropout\": best.params[\"dropout\"],\n",
    "    \"lr\": best.params[\"lr\"],\n",
    "    \"weight_decay\": best.params[\"weight_decay\"],\n",
    "    \"batch_size\": best.params[\"batch_size\"],\n",
    "}\n",
    "print(\"\\nMejores HP FTT Completo (val RMSE_log ↓):\\n\", json.dumps(best_params_FTT, indent=2))\n",
    "\n",
    "hp_path = os.path.join(SAVE_DIR, f\"best_params_FTT_{VERSION_TAG}.json\")\n",
    "with open(hp_path, \"w\") as f:\n",
    "    json.dump(best_params_FTT, f, indent=2)\n",
    "print(f\"Guardado: {hp_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005e55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
